{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science for Cognitive Neuroscience Midterm Exam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this data analysis part of the midterm exam you will be exploring some BOLD fMRI data. You will be using the tools and concepts learned in class.\n",
    "\n",
    "Before starting run the cells below that will import the libraries that you need for the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel\n",
    "import cortex\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell downloads the data necessary for this midterm. Run it before working on the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "data_filename = \"/home/jovyan/s01_categories_all_z.nii\"\n",
    "categories_filename = \"/home/jovyan/catloc_experimental_conditions.npy\"\n",
    "\n",
    "if (not os.path.exists(data_filename) or\n",
    "    not os.path.exists(categories_filename)):\n",
    "    \n",
    "    zname = \"/home/jovyan/midterm_data.zip\"\n",
    "    if not os.path.exists(zname):\n",
    "        print(\"Downloading\")\n",
    "        zname, _ = urllib.request.urlretrieve(\n",
    "            \"https://berkeley.box.com/shared/static/hcu0khw2spowgd1winlfi4f3si7lk1ua.zip\", zname)\n",
    "    print(\"Unzipping\")\n",
    "    zfile = zipfile.ZipFile(zname)\n",
    "    zfile.extractall(\"/home/jovyan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it. \n",
    "# The result will give you directions about how to log in to the submission system, called OK.\n",
    "# Once you're logged in, you can run this cell again, but it won't ask you who you are because\n",
    "# it remembers you. However, you will need to log in once per assignment.\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('midterm.ok')\n",
    "_ = ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** **Loading and plotting the data.** \n",
    "\n",
    "**a)** [3pts] Use `nibabel` to  load the nifti file containing the data for this exam. The name `data_filename` below contains the filename to use. Load the nifti file into the name `img`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filename = '/home/jovyan/s01_categories_all_z.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a)\n",
    "# Use nibabel to load the file into the name `img`.\n",
    "# img = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"qm_1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** [3pts] Store its **transposed** data into the name `data`. Print its shape. It should be (360, 30, 100, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b)\n",
    "# Store its transposed data in the name `data`\n",
    "# data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"qm_1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** [3pts] Store the 6th volume in the name `sixth_volume`. Make sure you choose the correct index for this (recall where indexing starts!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"qm_1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** [6pts] You will create a panel of 5 rows and 6 columns of subplots (using `plt.subplot`) in which you will display all the slices of the sixth volume (using `plt.imshow`). \n",
    "\n",
    "Create a figure with `figsize=(12, 10)` and name it `fig_sixth_volume`.  Next, write a for loop ranging from 0 to 30 to index the axial slices. In this loop you should: \n",
    "* (i) store the i-th axial slice in the name `axial_slice` \n",
    "* (ii) select a subplot location using `plt.subplot()` (arguments are number of rows, number of columns, **plot index starting at 1 (not 0)**) \n",
    "* (iii) plot the image using `plt.imshow` with a gray colormap \n",
    "* (iv) remove the axis ticks, for example using `plt.axis('off')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (d)\n",
    "# use subplots and imshow to show the slices of the sixth volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"qm_1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2\\.** The nifti file loaded in question \\#1 contains 360 brain volumes from a scan during which different types of images were viewed by the subject. In this question you will load a numpy array file (.npy) which contains a 1D array that indicates the type of image that was presented during each timepoint of the scan. Then you will make some masks for two specific image categories.\n",
    "\n",
    "**a)** [3pts] Use `np.load` to load the categories file, using the filename stored in the name `categories_filename`, defined below. This file contains a 1D array. Store this array into the name `category_labels`. Print its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_filename = \"/home/jovyan/catloc_experimental_conditions.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a)\n",
    "# Use np.load to load the file into the name category_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"qm_2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** [3pts] Create a mask for this 1D data that indicates the TRs where the category label is \"`faces`\" (stored as True) and `False` everywhere else. Use the `==` operator along with the label `'faces'` to do this. Store this binary array mask in the name `mask_faces`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b)\n",
    "# create an array with True wherever there is a 'faces' label in category_labels and False wherever there isn't.\n",
    "# Store it in the name mask_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"qm_2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** [3pts] In the same way, create the array `mask_places` indicating whenever the category label `'places'` is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c)\n",
    "# In the same way, create mask_places to indicate where in the category_labels array the label \"places\" appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"qm_2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** [3pts] Create a figure named `fig_time_masks`. Into this figure, plot both of these masks as two separate 1D timeseries by calling `plt.plot` once for each mask. Since you are plotting two timeseries in one plot, you need to add a legend to label the two timeseries, labeling the faces timeseries `faces` and the places timeseries `places`. Also add an `xlabel` saying `\"Time (TRs)\"` and a `ylabel` saying `\"Presence of concept\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"qm_2d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** In this exercise you will create a simple version of a contrast image between brain activity for faces and brain activity for places. A contrast image shows where one type of stimulus (or any experimental condition) has higher activity than a second type of stimulus. Usually they are created after a statistical analysis, but here we'll just create a simple version by subtracting BOLD signal activity in two stimulus conditions. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## If you had troubles creating the arrays mask_faces and mask_places, you can activate this cell (type ESC then y), \n",
    "## uncomment the code below and execute this cell to create arrays that will do the job.\n",
    "## However, these arrays are not going to be useful to check your previous results, as they will\n",
    "## not be the same! Please only use this cell if you were not able to create mask_faces or mask_places\n",
    "\n",
    "# mask_faces = np.concatenate([range(i, i + 10) for i in (0, 70)])\n",
    "# mask_places = np.concatenate([range(i, i + 10) for i in (40, 100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** [3pts] Use the mask called `mask_faces` that you created in question \\#2 to extract the 60 volumes where a face stimulus was shown during the experiment from the 4-D scan array called `data`. You need to use **masking** to do this. Note that this requires masking in *time*, not the 3 *spatial* dimensions we've used masking for in lecture. Store the 60 volumes into the name `faces_volumes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a)\n",
    "# Extract the 60 volumes corresponding to faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"qm_3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** [3pts] Use the mask called `mask_places` that you created in question \\#2 to extract the 60 volumes where a place stimulus was shown during the experiment from the 4-D scan array called `data`. Store the 60 volumes into the name `places_volumes`.\n",
    "\n",
    "**Note:** The resulting shape of both of the arrays from **(a)** and **(b)** should be (60, 30, 100, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b)\n",
    "# Extract the 60 volumes corresponding to places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"qm_3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** [3pts] Create the mean volume from the 60 volumes stored in `faces_volumes`, and store it in a name called `faces_mean_volume`. You can use `np.mean` to do this, remembering that you need to specify the axis across which you want to take the mean (in this case: the time dimension). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c)\n",
    "# Compute the mean image for faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"qm_3c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** [3pts] In the same way create `places_mean_volume` from `places_volumes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (d)\n",
    "# Compute the mean image for places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"qm_3d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** [3pts] Create a contrast volume that shows the extent to which activity from looking at faces is greater than that for places. To do this, subtract `places_mean_volume` from `faces_mean_volume` and store the result in `contrast_volume`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (e)\n",
    "# Compute contrast volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"qm_3e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f)** [6pts] Use `cortex.quickshow` to plot `contrast_volume` to a flatmap. Remember: To do this, you need to create a `cortex.Volume` and provide data, subject id, and transformation.Subject id is `'s01'`, and transformation is `'catloc'`.  Call this volume `pycortex_contrast_volume`. Then create a figure named `fig_contrast` before calling `cortex.quickshow`.\n",
    "\n",
    "**Note:** We have found some face-selective areas (in red), including the **fusiform face area (FFA)** and some place-selective areas (in blue), including the **parahippocampal place area (PPA)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (f)\n",
    "# Create a pycortex volume from contrast_volume, using subject s01 and transform catloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"qm_3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** In this exercise you will compare the voxel time series of two voxels from face and place selective regions of the brain with the face and place time series that indicate when those stimuli were shown to the subject.\n",
    "\n",
    "**a)** [3pts] Extract the timeseries of the voxel with (Z,Y,X) coordinates: `(6, 57, 37)` from `data` and store it in  a name called `ts_face_voxel`. This voxel exists in a part of the brain that is face selective (meaning it responds to faces more than other types of stimuli) called the **FFA**, so we expect to see activity that goes up when a face is viewed, and down when a face is not viewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a)\n",
    "# Extract face timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"qm_4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** [3pts] Now you will plot this timeseries and compare it to the time series indicating presence of faces. Remember, the actual value of the voxel is in arbitrary units and of less interest than the change we observe in it over time. To perform a comparison, it is easiest to first subtract the mean voxel value. To do this, compute the mean of `ts_face_voxel` and store it in `mean_ts_face_voxel`. \n",
    "\n",
    "Now subtract this mean from `ts_face_voxel` and store it in `centered_ts_face_voxel`. \n",
    "\n",
    "Create a figure named `fig_ts_face_voxel`. Using the type of plot most appropriate for 1-D voxel time series arrays, plot `centered_ts_face_voxel`. In the same figure also plot `mask_faces` as a time series in the same way. \n",
    "\n",
    "Observe the similarities between the voxel timeseries and the mask timeseries. And just for your own edification (no need to answer in the notebook), do you see what you would expect from a voxel in a face selective region?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b)\n",
    "# Plot face timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"qm_4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** [3pts] Extract the timeseries of the voxel with (Z,Y,X) coordinates: `(10, 62, 40)` from `data` and call it `ts_place_voxel`. This voxel exists in a part of the brain that is place selective called the **PPA**, so we expect to see activity that goes up when a place is viewed, and down when a place is not viewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c)\n",
    "# Extract place timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"qm_4c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** [3pts] Compute the mean of `ts_place_voxel` and store it in `mean_ts_place_voxel`. Then subtract the mean from `ts_place_voxel` and store the result in `centered_ts_place_voxel`. Create a figure `fig_ts_place_voxel` and plot `ts_place_voxel` as a timeseries together with `mask_places`, also as a timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (d)\n",
    "# Plot face timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"qm_4d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to submit your midterm for grading to OKPy using the cell below!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
