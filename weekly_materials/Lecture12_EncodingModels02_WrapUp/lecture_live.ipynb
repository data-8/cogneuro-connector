{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Overview\n",
    "In the last lecture of the class, we will discuss how to apply the modeling techniques we have studied to more complex stimuli than those that we have used so far. \n",
    "\n",
    "# Goals\n",
    "We will model responses to a new data set from an experiment with a less structured design. This experiment has no pre-specified *conditions*; it shows a number of words, paired with pictures. Our goal will be to formally specify what *about* the words elicits responses in the brain. We will:\n",
    "\n",
    "* Generate hypotheses about what features or aspects of the words are related to brain responses\n",
    "* Fit a model based on a hypothesis to the data from the new experiment\n",
    "* Use that model to predict responses to novel stimuli\n",
    "\n",
    "This approach is called the *encoding model* approach. \n",
    "\n",
    "- Neuroscience concepts\n",
    "    - Using feature spaces to represent the properties of complex stimulus\n",
    "    - Modeling brain responses as a function of stimulus features\n",
    "- Coding concepts\n",
    "    - Implementation of cross validation\n",
    "- Datascience concepts\n",
    "    - Predicting held out data\n",
    "    - Testing and training sets\n",
    "    - Testing model performance (using correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Blackboard: Recap of \"What do experiments do?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First: update neurods (new functions for computing OLS)\n",
    "import neurods\n",
    "_, _, version = [int(x) for x in neurods.__version__.split('.')]\n",
    "if version <= 1:\n",
    "    neurods.io.update_neurods()\n",
    "# Restart your kernel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import neurods\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel\n",
    "import cortex\n",
    "# Configure defaults for plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.aspect'] = 'auto'\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'retina' # optional\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Complex Stimuli\n",
    "\n",
    "The approach we have studied so far allows us to estimate responses to different categories of stimuli that have been shown in an experiment. We can compare responses between different conditions to test whether the brain reliably responds more to one condition compared to another, and we can predict the response of each voxel to new examples of the specific categories of stimuli that appear in our experiment. \n",
    "\n",
    "... But what if we are interested in more than responses to faces, bodies, places, and objects? What if we are interested in responses to more complex stimuli? For example, How might the brain respond when we speak, read, or listen to a variety of words? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To explore this question, we will use freely available data from an influential paper (Mitchell et al. 2008, *Science*): https://www.cs.cmu.edu/afs/cs/project/theo-73/www/science2008/data.html\n",
    "\n",
    "The experiment consists of subjects looking at a variety of words and accompanying line drawings of those words, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url=\"http://www.cs.cmu.edu/~lwehbe/files/science.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, a stimulus was presented every 10 seconds. Each stimulus was repeated 6 times. To generate the data we have downloaded, for each repeat of each word/picture, the activity between 4 and 8 seconds after the onset of the word/picture was averaged, resulting in one brain image (an event-related average) for each word/picture. \n",
    "\n",
    "This means that the hemodynamic response is *already accounted for*, because we are not dealing with raw TRs any more for this data set! Thus, no convolution of our design matrix will be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Experiment directory\n",
    "basedir = os.path.join(neurods.io.data_list['fmri'], 'word_picture')\n",
    "\n",
    "# Load the mask\n",
    "mask_file = os.path.join(basedir,'s03_mask.nii')\n",
    "mask = neurods.io.load_fmri_data(mask_file, do_zscore=False).astype(np.bool)\n",
    "\n",
    "# Load the fMRI data\n",
    "data_file = os.path.join(basedir,'s03.nii.gz')\n",
    "data = neurods.io.load_fmri_data(data_file, do_zscore=True, mask=mask)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load description of data (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Here we load a variable that contains information about the stimulus, \n",
    "# including the 60 words that comprise our stimuli\n",
    "feature_data = np.load(os.path.join(basedir, 'features.npz'))\n",
    "words = feature_data['words']\n",
    "\n",
    "print(\"Here are the stimulus words: \\n\")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_num = 1 # change the word number\n",
    "\n",
    "sample_image = np.zeros(mask.shape)\n",
    "sample_image[mask==True] = data[word_num]\n",
    "h = cortex.mosaic(sample_image, vmin=-3, vmax=3)\n",
    "plt.colorbar()\n",
    "plt.title(words[word_num], size=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display data, with description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.imshow(data)\n",
    "y_idx = np.arange(0, 60, 10)\n",
    "plt.yticks(y_idx, [words[yi] for yi in y_idx], fontsize=12)\n",
    "plt.grid(axis='y', color='w', lw=2)\n",
    "plt.ylabel('Word/Image', fontsize=14);\n",
    "plt.xlabel('Voxel', fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Blackboard: Differences in the data in this experiment vs. previous experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we treat each spearate word as a condition, this is too many conditions! How can we *summarize* the data in this experiment, aside from contrasting one condition with another?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Breakout session 1:\n",
    "Working together with the whole class on the google doc, put the words into groups! Give each group a title (e.g. \"Furniture\"), and make a python list of strings for each group, like this:\n",
    "\n",
    "    # Words that start with S (this is not a good reason to group words, it's just an example)\n",
    "    group_1 = ['saw', 'screwdriver', 'shirt', 'skirt', 'spoon']\n",
    "    \n",
    ">Try to use *most* of the words in at least one group. These groups should have something in common that you think might affect responses in the brain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill in your groups!\n",
    "group_1 = []\n",
    "group_2 = []\n",
    "# add as many groups as you want, up to ~5\n",
    "groups = [group_1, group_2, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function will convert your groups into an array that we can use to model the brain data from this experiment!\n",
    "def group_to_design(*groups, words=words):\n",
    "    \"\"\"Convert lists of words in different groups into a design matrix\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    groups : lists\n",
    "        any number of lists of strings can be input as the first argument. Each element\n",
    "        of each group must be a word in the `words` list. \n",
    "    words : list\n",
    "        The list of words to be divided into groups. \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    design : array\n",
    "        2D array of (time [images] x group label [features])\n",
    "    \"\"\"\n",
    "    design = np.zeros((len(words), len(groups)))\n",
    "    for igrp, grp in enumerate(groups):\n",
    "        for grp_word in grp: \n",
    "            if not grp_word in words:\n",
    "                raise Exception('{} is not in list!'.format(grp_word))\n",
    "        design[:, igrp] = np.array([w in grp for w in words])\n",
    "    return design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ... and it can also be used to see what words you haven't yet categorized:\n",
    "design = group_to_design(*groups)\n",
    "print(words[~design.any(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show feature assignments to each word\n",
    "_ = plt.imshow(design)\n",
    "plt.xticks(range(design.shape[1]))\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Word/Image\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditions/Categories vs Features\n",
    "\n",
    "We have created a category label model that *summarizes* over the different conditions (different words/images) in our experiment. This is OK, but it still may be hard to predict how the brain would respond to words that aren't in our original data set. (How would the brain respond to \"goat\"? To \"pen\"? To \"book\"?) Also, every word/image doesn't fit equally well into its category. We can do better.\n",
    "\n",
    "We can make use of the fact that new words have some features in common with the set of words in this experiment. What if we could learn the responses to specific *features* or *properties* of words (e.g. whether or not they are animate, whether or not they are edible etc.)? Then we could predict the activity of a new word as a combination of the activities associated with its features. For example, we can learn how the brain responds to objects that are manmade, inanimate, made of wood and that are used as tools. The degree to which a noun is manmade, inanimate, or made of wood can be considered *features* of that noun. We can estimate the brain response to any word (e.g. \"goat\", \"pen\", or \"book\") as a weighted combination of feature values. We will use multivariate regression to estimate the weights for each feature for each voxel in the brain.\n",
    "\n",
    "First, we need an annotation of the features or properties (e.g. degree of animacy, etc.) of these words. From looking at the list of words, it's clear that there are many properties that different sets of words share. (we used some of these properties to define our groups). \n",
    "\n",
    "A better way to do this is to use labels for the degree to which each word has a certain property. We have access to a set of 218 questions for which every word has been labeled by multiple users on Amazon Mechanical Turk (Sudre et al., Neuroimage, 2012). These questions were designed to capture the semantic properties of these objects. Additionally, 11 features describing the visual properties of the line drawings are also provided.\n",
    "\n",
    "The scale of the features is 1-5 with,\n",
    " - 1 being a 100% not having a given property (e.g. not animate), and \n",
    " - 5 being 100% yes of having a property (e.g. animate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_names = feature_data['feature_names']\n",
    "features = feature_data['features']\n",
    "print(\"We have {} features that describe the stimulus.\\n\".format(len(feature_names)))\n",
    "print(\"Each word is described by ratings on each of these features\\n\")\n",
    "\n",
    "word_index = 0 # Play with this number\n",
    "n_features = 20\n",
    "print(\"First {} features for {}:\\n\".format(n_features, words[word_index]))\n",
    "for feature_index in range(n_features):\n",
    "    print(feature_names[feature_index], features[word_index, feature_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, to describe the whole stimulus, we have an array that is much more complicated than our previous experimental design matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Label the axes on this plot!\n",
    "plt.imshow(feature_data['features'])\n",
    "print(feature_data['features'].shape)\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For simplicity, we will only use the visual features for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = feature_data['features']\n",
    "feature_names = feature_data['feature_names']\n",
    "vis_features = features[:, 218:]\n",
    "vis_feature_names = feature_names[218:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (Same labels)\n",
    "_ = plt.imshow(vis_features)\n",
    "print(vis_features.shape)\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There are several new functions in neurods.stats that we have used the last few weeks.\n",
    "from neurods import stats as nds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILDING A PREDICTIVE MODEL\n",
    "\n",
    "### IT IS VERY IMPORTANT NOT TO USE TEST DATA IN TRAINING!!\n",
    "\n",
    "To test whether a model has learned a general relationship between stimulus features and brain responses, we need test it on data that was not included in the model training data set. \n",
    "\n",
    "Imagine you have a small dataset with voxel responses to features, and some of the voxels have some noise that is correlated to one of the features. The probability of such an event becomes smaller as the dataset size increases, but at low sample sizes there is a good chance of finding spurious correlations. \n",
    "\n",
    "Such a correlation would allow you to build a model that predicts brain activity from the features, but only in that dataset, since the noise is independent of the data and will not repeat in the same way in other datasets. However, for the voxels that show a real and strong enough response to the features, you will be able to learn a model that predicts brain activity from the features, and that model should generalize to new data.\n",
    "\n",
    "This is why we always test a model on held out data that was not used in training. This allows us to judge whether the model is really predicting brain activity and not just fitted to noise in the sample.\n",
    "\n",
    "Here we separate for you the words into a test and a train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_index = [0, 1, 2, 3, 4, 6, 7, 8, 10, 13, 20, 23]\n",
    "train_index = list(set(range(60)) - set(test_index))\n",
    "\n",
    "train_x = zscore(design[train_index, :])\n",
    "train_y = zscore(data[train_index, :])\n",
    "print (\"Shape of training features: {0}\\nShape of training fMRI data: {1}\".format(train_x.shape, train_y.shape))\n",
    "\n",
    "test_x = zscore(design[test_index, :])\n",
    "test_y = zscore(data[test_index, :])\n",
    "print (\"Shape of testing features: {0}\\nShape of testing fMRI data: {1}\".format(test_x.shape, test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Survey 1: pycortex review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight estimation and data prediction\n",
    "\n",
    "We want to learn a function that predicts the activity for any word in terms of its features. \n",
    "\n",
    "\n",
    "> Breakout session\n",
    "\n",
    "- Use the `nds.ols()` function to estimate the brain response to the various features for every voxel.\n",
    "- Use the estimated weights to predict the activity for the held-out words, using `test_X`.\n",
    "- Use the `nds.compute_correlation()` function to compute the correlation of your predicted activity and the real activity `test_Y`\n",
    "- Plot a flatmap of the prediction performance. Which regions are well predicted, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: for pycortex plotting, this subject has been normalized to a standard template brain\n",
    "# Thus, use a the template brain (\"MNI\" = Montreal Neurological Institute template) and standard atlas alignment\n",
    "sub, xfm = 'MNI', 'atlas336'\n",
    "# V = cortex.Volume(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation\n",
    "... the easy way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "n_splits = 3\n",
    "n_voxels = mask.sum()\n",
    "# Pre-allocate \n",
    "r_cv = np.zeros((n_splits, n_voxels))\n",
    "kf = KFold(n_splits=n_splits)\n",
    "for icv, (trn, val) in enumerate(kf.split(range(12))):\n",
    "    print(\"\\n===Split {}===\\n\".format(icv))\n",
    "    print(\"Training index:\")\n",
    "    print(trn)\n",
    "    print(\"Validation index:\")\n",
    "    print(val)\n",
    "    # Fit / predict the model here:\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparison\n",
    "OK, so we have a somewhat general model; now, we would like to addres a few more questions / issues: \n",
    "\n",
    "* Our selection of a training set was arbitrary; we would like to predict ALL of our data using cross validation!\n",
    "* Is our model better than a dumb model? (Are there bad ways to group the words?)\n",
    "* Is our model better than the feature model that describes the visual features of each word/images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will use these groups as a null hypothesis (since it's not terribly likely that the brain cares about\n",
    "# the alphabetic grouping of these words...)\n",
    "dummy_groups = [['airplane', 'ant', 'apartment', 'arch', 'arm', 'barn', 'bear', 'bed', 'bee', 'beetle', \n",
    "                 'bell', 'bicycle', 'bottle', 'butterfly'],\n",
    "                ['car', 'carrot', 'cat', 'celery', 'chair', 'chimney', 'chisel', 'church', 'closet', \n",
    "                 'coat', 'corn', 'cow', 'cup', 'desk', 'dog', 'door', 'dress', 'dresser'],\n",
    "                ['eye', 'fly', 'foot', 'glass', 'hammer', 'hand', 'horse', 'house', 'igloo', 'key', 'knife',\n",
    "                 'leg', 'lettuce','pants', 'pliers'],\n",
    "                ['refrigerator', 'saw', 'screwdriver', 'shirt', 'skirt', 'spoon', 'table', \n",
    "                 'telephone', 'tomato', 'train', 'truck', 'watch', 'window']]\n",
    "dummy_design = group_to_design(*dummy_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(dummy_design)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... And we will compute cross-validated predictions for each of our 3 models. There is a problem with this \"dummy\" model, though: It's going to be difficult to cross-validate! how can we account for the fact that different 1/3s of this array will have different category labels present? \n",
    "\n",
    "> Breakout session: Solve this problem! And formalize cross validation code as a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ... but better to do it this way:\n",
    "def ols_pred_cv():\n",
    "    pass\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit all three models w/ cross validation\n",
    "r_category = ols_pred_cv(data, design, ri=ri)\n",
    "r_dummy = ols_pred_cv(data, dummy_design, ri=ri)\n",
    "r_feature = ols_pred_cv(data, vis_features, ri=ri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare models!\n",
    "Each model makes a prediction at each voxel. Thus, the most straightforward (qualitative) way to compare models is to plot how well each model predicts each voxel in a scatterplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.scatter(r_dummy.mean(0), r_category.mean(0), color='gray', alpha=0.1)\n",
    "plt.plot([-0.6,0.85], [-0.6,0.85], 'k--')\n",
    "plt.xlim([-0.6,0.85])\n",
    "plt.ylim([-0.6,0.85]);\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Survey 2: what are the axis labels here? What does each dot mean? (Add labels!) What is the graph telling you??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.scatter(r_feature.mean(0), r_category.mean(0), color='gray', alpha=0.1)\n",
    "plt.plot([-0.6,0.85], [-0.6,0.85], 'k--')\n",
    "plt.xlim([-0.6,0.85])\n",
    "plt.ylim([-0.6,0.85])\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Discussion: How could we go about statistically determining which model is BETTER?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show where in the brain each model does better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V = cortex.Volume(r_feature.mean(0)-r_dummy.mean(0), sub, xfm, cmap='RdBu_r', vmin=-1, vmax=1, mask=mask)\n",
    "_ = cortex.quickflat.make_figure(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model interpretation\n",
    "Finally, we can examine the weights (for the categories or features) that summarize across the stimulus words / images. Further analysis will be required to determine if differences between weights for categories or features are reliable; this is just a qualitative analysis for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub, xfm = 'MNI', 'atlas336'\n",
    "for b in B:\n",
    "    V = cortex.Volume(b, sub, xfm, cmap='RdBu_r', vmin=-3.0, vmax=3.0, mask=mask)\n",
    "    cortex.quickflat.make_figure(V)\n",
    "    # Add a title to each condition!\n",
    "    plt.suptitle('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(Do these plots maybe need a little fixing?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
