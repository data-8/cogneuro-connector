{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview \n",
    "\n",
    "In the first ~1/3 of this lecture, we will review homework, programming, and fMRI concepts\n",
    "\n",
    "In the second ~1/3 of this lecture, we will introduce data normalization and logical indexing\n",
    "\n",
    "In the last ~1/3 of this lecture we will introduce software to display fMRI data on a 3D representation of the cortical surface.\n",
    "\n",
    "# Goals\n",
    "* Understand the way pycortex represents a volumetric data set\n",
    "* Create pycortex Volume objects from 3D data, masked data, and time series data\n",
    "* Display data on the cortical surface\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating resources in your server home directory\n",
    "(Run the cells in this section once, then restart your kernel, reload the web page, and skip this section the next time through!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Updating functions\n",
    "import neurods\n",
    "import cortex as cx\n",
    "# Add figures to notebook\n",
    "dropbox_link = 'https://www.dropbox.com/s/dkibicpvc13ng27/Archive.zip'\n",
    "fname = 'figures/'\n",
    "basedir = '~/cogneuro-connector/weekly_materials/Lecture04_Normalization_Masking_pycortex/'\n",
    "neurods.io.download_file(dropbox_link, fname, basedir, zipfile=True)\n",
    "# Update neurods package\n",
    "neurods.io.update_neurods()\n",
    "# Update pycortex configuration file\n",
    "cx.config.set('basic', 'filestore', '/data/shared/cogneuro88/pycortex_store/')\n",
    "with open(cx.options.usercfg, 'w') as fid:\n",
    "    cx.config.write(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1:  Writing reusable functions\n",
    "& misc. code / efficiency tips!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load some necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set plotting defaults\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created the following functions to make plots of slices of fMRI volumes. In some code libraries, these are called light table or mosaic plots, because in the (literally) dark old days of film photography, photographers used to lay out their film negatives on light tables in a format similar to this to see them.\n",
    "\n",
    "We will want to make plots like this many times throughout the course, so we would like to formalize these functions a little more to make them more readily reusable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_any_slice(volume, slice_number, dimension):\n",
    "    \"\"\"Given an integer and a 3D volume, this function returns the data of \n",
    "    that horizontal slice \"\"\" \n",
    "    if dimension == 0:\n",
    "        img = volume[slice_number, :, :]\n",
    "    elif dimension == 1:\n",
    "        img = volume[:, slice_number, :]\n",
    "    elif dimension == 2:\n",
    "        img = volume[:, :, slice_number]\n",
    "    return img\n",
    "\n",
    "def plot_any_slice_v2(volume, slice_number, dimension, cmap = 'viridis', vmin=0, vmax=2000,\n",
    "                     origin = 'lower', interpolation='nearest', aspect='equal'):\n",
    "    img = get_any_slice( volume, slice_number, dimension)\n",
    "    _ = plt.imshow(img, cmap = cmap, vmin= vmin, vmax = vmax, origin = origin, interpolation = interpolation,\n",
    "                  aspect = aspect)\n",
    "    _ = plt.axis('off')\n",
    "    \n",
    "def plot_all_slices(volume, slice_dimension, nrows, ncols , cmap = 'viridis', vmin=0, vmax=2000,\n",
    "                     origin = 'lower', interpolation='nearest', aspect='equal' ):\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    n_slices = first_volume.shape[slice_dimension]\n",
    "    for s in range(n_slices):\n",
    "        ax = fig.add_subplot(nrows, ncols, s+1)\n",
    "        plot_any_slice_v2(first_volume, s, slice_dimension, cmap = cmap, vmin= vmin, vmax = vmax, \n",
    "                          origin = origin, interpolation = interpolation,aspect = aspect)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will modify the final function to be more production-ready below. Follow along...\n",
    "\n",
    "* One major addition we need to make is a ***docstring***. See [here](https://github.com/numpy/numpy/blob/master/doc/HOWTO_DOCUMENT.rst.txt#docstring-standard) for a general description of writing docstrings according to the numpy format, and [here](https://github.com/numpy/numpy/blob/master/doc/example.py) for clear examples.\n",
    "* We will use the `**kwargs` syntax to pass keyword arguments from function to function\n",
    "* We will modify argument names to be more similar to arguments in similar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import neurods\n",
    "neurods.viz.slice_3d_array?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey 1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Teacher info\n",
    "https://docs.google.com/a/berkeley.edu/forms/d/e/1FAIpQLSfzF7dZ3z2GI8TzrnImXeXf0qIyDmUof8XuB97j0aZ1UyK-mg/viewform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "Today, we will load data from a common neuroimaging data format ([NIfTI](https://nifti.nimh.nih.gov/nifti-1/) format). If you find open source neuroimaging data online, it will most likely be in this format. To load this data, we need to use a neuroimaging code library called nibabel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nibabel\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a nifti (nii) proxy object\n",
    "fbase = '/Users/mark/Dropbox/data8/' #'/data/shared/cogneuro88'\n",
    "fname = os.path.join(fbase,'fMRI/categories/s01_categories_01.nii.gz')\n",
    "nii = nibabel.load(fname) \n",
    "\n",
    "# This object stores the infomation *about* the fMRI data stored in the file. \n",
    "# This meta-data can be accessed via attributes of the `nii` object.\n",
    "print('nii.in_memory :', nii.in_memory)\n",
    "print('nii.shape :', nii.shape)\n",
    "print('voxel sizes :', nii.header.get_zooms())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also information stored about how the brain was oriented in space as it was scanned, but that is beyond the scope of what we will go into here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieve actual data as an array\n",
    "data = nii.get_data().T\n",
    "print('nii.in_memory : ', nii.in_memory)\n",
    "print('data shape : ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot a few voxels\n",
    "_ = plt.plot(data[:,22:, 45, 45])\n",
    "_ = plt.xlabel('Time (TRs)')\n",
    "_ = plt.ylabel('BOLD signal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW Recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot an image of the first 10 time points for all voxels in one horizontal slice\n",
    "slice_3d_array(data[:10,5], 0, 2, 5, slice_prefix='Time = {}', figsize=(10,4), vmin=0, vmax=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BREAKOUT SESSION\n",
    "Make an image plot of all the voxels in one horizonatal slice. \n",
    "\n",
    "1. Select all time points for one horizontal slice\n",
    "2. Use np.reshape make a 2D array that is (time x voxels) \n",
    "3. Use `plt.imshow` to show that 2D array\n",
    "4. Make the plot pretty! (label axes, set an appropriate color scale, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot you make should show clearly that the problem is that there's more variability across voxels than there is across time (Some voxels *always* show higher signal than others). This scaling issue complicates some kinds of visualization and analysis. To look at this issue a slightly different way, let's look at histograms of the timecourses for two voxels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(250, 650, 31)\n",
    "voxel_a = data[:, 5, 50, 43]\n",
    "voxel_b = data[:, 5, 50, 53]\n",
    "_ = plt.hist(voxel_a, bins, label='Voxel A')\n",
    "_ = plt.hist(voxel_b, bins, label='Voxel B')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey 2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minmax_norm(data):\n",
    "    \"\"\"Normalize data to range of 0-1 by subtracting min, dividing by range\"\"\"\n",
    "    data_norm = (data-data.min()) / (data.max()-data.min())\n",
    "    return data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins01 = np.linspace(0,1,31)\n",
    "voxel_a_n = minmax_norm(voxel_a)\n",
    "voxel_b_n = minmax_norm(voxel_b)\n",
    "_ = plt.hist(voxel_a_n, bins01, label='Voxel A')\n",
    "_ = plt.hist(voxel_b_n, bins01, label='Voxel B')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks sensible. However, a problem with this normalization method shows up when you have outlying values. What would happen if Voxel A, at one time point, had a (spuriously) very large value? Let's see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aside: a cautionary tale. Python memory is weird.\n",
    "a = np.arange(10)\n",
    "b = a\n",
    "b[3] = 63\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can avoid changing a variable by using the copy package\n",
    "import copy\n",
    "a = np.arange(10)\n",
    "b = copy.copy(a)\n",
    "b[3] = 63\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a variable called voxel_a_wonky and add an outlier to it\n",
    "voxel_a_wonky = copy.copy(voxel_a)\n",
    "voxel_a_wonky[5] = voxel_a_wonky.max()*1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See what that outlier does to histogram plots created after our first normalization method!\n",
    "_ = plt.hist(minmax_norm(voxel_a_wonky), bins01, label='Voxel A (w/ outlier)')\n",
    "_ = plt.hist(minmax_norm(voxel_b), bins01, label='Voxel B')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not put the data from both voxels into a similar range, because the max value is not stable (it can change a lot depending on only one data point). In general, (linear) data normalization set you need to *center* it (by subtracting off some value) and to *scale* it (by dividing by some value or performing some nonlinear operation). \n",
    "A more robust, stable way to normalize data is to subtract the *mean* of the data instead of the min, and to divide by the *standard deviation* instead of the range. \n",
    "\n",
    "The *standard deviation* is a measure of the variability of the data, derived from the whole data set (rather than the two points - the min and the max - that we used before.)\n",
    "\n",
    "This process converts the data to *standard scores* or *z scores*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You can compute the standard deviation of voxel A and voxel B using \n",
    "print(np.std(voxel_a), ',', np.std(voxel_b))\n",
    "# or: \n",
    "print(voxel_a.std(), ',', voxel_b.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can look at the standard deviation of the data by slice\n",
    "slice_3d_array(data.std(axis=0), 0, 5, 6)\n",
    "#slice_3d_array(data.std(axis=0), 0, 5, 6, vmin=0, vmax=200, figsize=(6*2,5*2))\n",
    "#_ = neurods.viz.slice_3d_array(data.std(axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout session\n",
    "Perform normalization of Voxel A and Voxel B by (1) subtracting off the mean (**`array.mean()`** or **`np.mean(array)`**) and (2) dividing by the standard deviation (**`array.std()`** or **`np.std(array)`**)\n",
    "\n",
    "Then repeat the plots we created above (making histograms of the timecourses for Voxel A, with and without an outlier, and for Voxel B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "z normalization can be performed easily on multi-dimensional arrays using the `zscore` function in scipy.stats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "zscore?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_z = zscore(data, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can repeat a few of the plots we made above, to show that we now see more variation across time than across voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot time x voxels\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(data_z[:, 5].reshape(120, 100*100), aspect='auto', vmin=-3, vmax=3)\n",
    "plt.xlabel('Voxels')\n",
    "plt.ylabel('Time (TRs)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot \n",
    "slice_3d_array(data_z[:10,5], 0, 2, 5, slice_prefix='Time = {}', figsize=(10,4), vmin=-3, vmax=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 3: Cortical surface extraction\n",
    "\n",
    "fMRI studies often focus on the cerebral cortex (the outermost layer of the brain). Consequently, it is common to display the results of statistical analyses of fMRI data on inflated and flattened representations of the cerebral cortex. Such cortical surface maps provide a way to examine all cortical fMRI data at once, with the anatomical location of the functional data made clear. \n",
    "\n",
    "The cortical surface must be computationally extracted from high spatial resolution anatomical MRI scans, and often manually edited (*NOTE: Manual editing to create a good corical surface can take days or weeks of effort! This data is not free!*)\n",
    "\n",
    "<img src=\"figures/MPRAGE.png\" align='left' style=\"height: 200px;\">\n",
    "\n",
    "<img src=\"figures/MPRAGE_wcortex.png\" align='left' style=\"height: 200px;\">\n",
    "\n",
    "<img src=\"figures/cortex_3views.png\" align='left' style=\"height: 200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Remember our histogram of values for data, which show a ton of voxels with zero values (from outside the brain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(0,2000,31)\n",
    "_ = plt.hist(data.flatten(), bins)\n",
    "# xlabel?\n",
    "# ylabel?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So: how can we extract the data that is only from the region of the scan that contains the brain? We could try to write down an index for each data point in the data that contains a brain voxel (e.g. [25, 33, 33], [25, 33, 34]), but you can see how such a list would get quite long (tens of thousands) and would be difficult to construct. \n",
    "\n",
    "One simple way to find data that is in or near the brain is to threshold the data to find only the voxels where the signal is greater than zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here, consider only the first volume\n",
    "brain_voxels = data[0] > 0\n",
    "print(brain_voxels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What do each of these quantities mean?\n",
    "print('dtype of `brain_voxels`: ', brain_voxels.dtype)\n",
    "print('Sum of of `brain_voxels`: ', brain_voxels.sum())\n",
    "print('Mean of of `brain_voxels`: ', brain_voxels.mean())\n",
    "print('Shape of `brain_voxels`: ', brain_voxels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout session\n",
    "Display the `brain_voxels` variable in some sensible way. What does the array LOOK like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an array of True/False values (a boolean array). This array can be directly used to INDEX our data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Logical indices are fun!\n",
    "a = np.arange(10)\n",
    "b = np.array([True, False, True, False, True, False, True, False, True, False])\n",
    "a[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This works in multiple dimensions, too!\n",
    "a = np.arange(20).reshape(10,2)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(a[b,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# or even for brain data!\n",
    "brain_data = data[:, brain_voxels]\n",
    "print(brain_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BREAKOUT SESSION\n",
    "Make a histogram of `brain_data`. Z-score it, and plot it as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Student answer\n",
    "plt.hist(brain_data.flatten(), bins)\n",
    "plt.xlabel('Raw BOLD response')\n",
    "plt.ylabel('TRs (count)')\n",
    "plt.figure()\n",
    "plt.imshow(zscore(brain_data, axis=0), aspect='auto')\n",
    "plt.xlabel(\"Voxels\")\n",
    "plt.ylabel(\"Time (TRs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onward to 3D data visualizations! \n",
    "\n",
    "We will use a python module called **`pycortex`** to show data in 3D on the brain. This module was developed here at UC Berkeley in the Gallant lab, mostly by James Gao, with help from Alex Huth, Mark Lescroart, and other lab members. The code is freely available online [here](https://github.com/gallantlab/pycortex), and a paper summarizing the code can be found [here](http://journal.frontiersin.org/article/10.3389/fninf.2015.00023/full). \n",
    "\n",
    "To map the functional data onto the cortex, pycortex requires at least two things:\n",
    "\n",
    "1. The cortical surface of the subject. \n",
    "    * pycortex stores cortical surface files (and several other files) for each subject in a reliably structured directory of files. Because of this reliable directory structure, all we need to provide to the code is a subject ID string, and the code will be able to find and load the relevant cortical surface files. \n",
    "2. The functional to anatomical aligmnent of this data to that cortical surface\n",
    "    * Alignment of functional data to anatomical data proceeds by an *affine transform*. How this transformation works is beyond the scope of this class, but you can look it up on [wikipedia](https://en.wikipedia.org/wiki/Affine_transformation) or in your favorite linear algebra textbook if you're curious. The practical upshot is that a 4x4 matrix of numbers is sufficient to store the 3 rotations (around the x, y, and z axes) and 3 the transformations (in the x, y and z dimensions) that will transform the functional data in space such that they are aligned with the anatomical data (with the cortical surface). In the pycortex code (and in other neuroimaging software), \"transform\" is abbreviated in variable names as `xfm`. Just as with the cortical surface, we only need to specify a name for a transform, and the code will know where to find the file that contains the affine transformation matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (1) subject (specifies the cortical surface of the brain)\n",
    "subject = 'S2' \n",
    "# (2) transform = functional-to-anatomical alignment\n",
    "transform = 'S2_category_auto' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a volume\n",
    "data_volume = cortex.Volume(data[0], subject, transform) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show the volume in a 3D brain (ooooh)\n",
    "cortex.webgl.show(data_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cortex.quickflat.make_figure(data_volume)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
