{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Overview\n",
    "\n",
    "## Lab 4: Writing functions, Data normalization\n",
    "\n",
    "In class, we talked about writing re-usable functions. Specifically, we wrote a plot function that was eventually incorporated into the visualization sub-module of `neurods` (`neurods.viz`). We also talked about data normalization, and introduced pycortex, our library for visualizing brain data on the cortical surface. For the first homework question, we will write a function to load data from NIfTI (.nii.gz) files; for the second homework question, we will use pycortex to show some data. First, a quick review of how to load data and plot data in pycortex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import cortex\n",
    "import neurods\n",
    "import nibabel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False: # Skip example cell to save memory\n",
    "    # Load data (as we did in class)\n",
    "    base_dir = '/data/shared/cogneuro88/fMRI/'\n",
    "    experiment = 'categories'\n",
    "    run = 's01_categories_01.nii.gz'\n",
    "    fpath = os.path.join(base_dir, experiment, run)\n",
    "    nii = nibabel.load(fpath)\n",
    "    data = nii.get_data() # Note that data was not transposed in this example cell...\n",
    "    print('Data shape:') # ... and that this was pointed out in the next two lines!\n",
    "    print('(X, Y, Z, Time)') \n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False: # Skip example cell\n",
    "    # Show data pycortex\n",
    "    sub = 's01' # Specifies subject (i.e., which surface in the pycortex database to use)\n",
    "    xfm = 'catloc' # Specifies transform from functional data space to the cortical surface\n",
    "    cmap = 'Reds' # Pick a good colormap here. `Reds` will do...\n",
    "    data_volume = cortex.Volume(data.T[0], sub, xfm, cmap=cmap, vmin=0, vmax=1500)\n",
    "    _ = cortex.quickflat.make_figure(data_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `1`. (6 points) Write a function to load data. \n",
    "There are a few things we will want to do to the data as we load it (for example, maybe normalize it, and maybe concatenate a few different files' worth of data together into one big array). The intent is that this will be the function we use to load data for the rest of the semester! (something like this will be incorporated into `neurods`)\n",
    "* [1 pt] Name the function `load_data()`. It should take a file name as input and return an array as output. \n",
    "* [1 pt] It should have a docstring!\n",
    "* [2 pts] It should *optionally* normalize the data by z-scoring it (i.e., whether or not the data returned by the function is z-normalized should be determined by an input argument). \n",
    "* [2 pts] If the function is given multiple files as input, it should concatenate all the files together in the time dimension and return a single array. It is up to you to determine how you should go about providing multiple files as input! (Note that the data directory (`/data/shared/cogneuro88/fMRI/categories/`) contains three runs of the same experiment: \n",
    "`s01_categories_01.nii.gz`, `s01_categories_02.nii.gz` and `s01_categories_03.nii.gz`. Make sure your code can (optionally) load and concatenate all three of these files!)\n",
    "   \n",
    "Hints: use `if` statements! and look up `np.vstack` and `np.concatenate`. You should think carefully about the order in which you perform normalization and concatenation (or concatenation and normalization?) of the data. Also remember that you should include some kind of demonstration that your code works as intended!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "\n",
    "# An OK implementation of load_data:\n",
    "from scipy.stats import zscore\n",
    "def load_data_ok(files, do_zscore=False):\n",
    "    \"\"\"Load fMRI data from files and optionally z-normalize data\"\"\"\n",
    "    # Create a list to store data\n",
    "    data = None\n",
    "    for f in files:\n",
    "        nii = nibabel.load(f)\n",
    "        if data is None:\n",
    "            data = nii.get_data().T\n",
    "            if do_zscore:\n",
    "                data = zscore(data, axis=0)\n",
    "        else:\n",
    "            tmp = nii.get_data().T\n",
    "            if do_zscore:\n",
    "                tmp = zscore(tmp, axis=0)            \n",
    "            data = np.vstack([data, tmp])\n",
    "    return data\n",
    "\n",
    "# A better implementation\n",
    "def load_data_better(files, do_zscore=False):\n",
    "    \"\"\"Load fMRI data from files and optionally z-normalize data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list \n",
    "        List of file names (absolute paths)\n",
    "    do_zscore : bool\n",
    "        Flag that determines whether to zscore data in time or not\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data : array\n",
    "        fMRI data array, in (time, z, y, x) format\n",
    "    \"\"\"\n",
    "    # Create a list to store data\n",
    "    data = []\n",
    "    # Loop over files in list\n",
    "    for f in files:\n",
    "        nii = nibabel.load(f)\n",
    "        tmp = nii.get_data().T\n",
    "        # Optionally zscore each run independently\n",
    "        if do_zscore:\n",
    "            data = zscore(data, axis=0)\n",
    "        data.append(tmp)\n",
    "    # Concatenate full data\n",
    "    data = np.vstack(data)\n",
    "    return data\n",
    "\n",
    "# A nicer syntax\n",
    "def load_data(*files, do_zscore=False, dtype=np.float32):\n",
    "    \"\"\"Load fMRI data from files and optionally z-normalize data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : strings \n",
    "        Absolute path names for files to be loaded\n",
    "    do_zscore : bool\n",
    "        Flag that determines whether to zscore data in time or not\n",
    "    mask : boolean array\n",
    "        Selection mask that specifies which voxels to extract from 3D brain\n",
    "    dtype : numpy data type\n",
    "        Data type to which to convert the loaded data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : array\n",
    "        fMRI data array, in (time, z, y, x) format (if not masked) or in\n",
    "        (time, voxels) format (if masked)\n",
    "    \"\"\"\n",
    "    # Create a list to store data\n",
    "    data = []\n",
    "    # Loop over files in list\n",
    "    for f in files:\n",
    "        print(\"Loading {}...\".format(f))\n",
    "        nii = nibabel.load(f)\n",
    "        tmp = nii.get_data().T.astype(dtype)\n",
    "        # Optionally zscore each run independently\n",
    "        if do_zscore:\n",
    "            tmp = zscore(tmp, axis=0)\n",
    "        data.append(tmp)\n",
    "        del tmp\n",
    "    # Concatenate full data\n",
    "    data = np.vstack(data)\n",
    "    return data\n",
    "\n",
    "# The extra lazy way to load data (here as an example, not used below)\n",
    "def load_data_lazy(*runs, exp='categories', **kwargs):\n",
    "    \"\"\"Efficient wrapper for load_data\n",
    "    \n",
    "    Loads data for a given experiment, after specifying only run number\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    runs : integers {1,2,3}\n",
    "        Run number to load for a given experiment\n",
    "    exp : string\n",
    "        Experiment name\n",
    "    kwargs : keyword arguments\n",
    "        (passed to load_data)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data : array\n",
    "        fMRI data array, in (time, z, y, x) format (if not masked) or in\n",
    "        (time, voxels) format (if masked)\n",
    "    \n",
    "    \"\"\"\n",
    "    if exp=='categories':\n",
    "        files = [os.path.join(neurods.io.data_list['fmri'], exp, 's01_categories_%02d.nii.gz'%r) for r in runs]\n",
    "    elif exp=='motor':\n",
    "        files = [os.path.join(neurods.io.data_list['fmri'], exp, 's01_motorloc.nii.gz')]\n",
    "    return load_data(*files, **kwargs)\n",
    "\n",
    "# See also neurods.io.load_fmri_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Demonstration that the load function works well\n",
    "# Set this to True to run this cell. We skip it here, because it will use up \n",
    "# a lot of memory, and thus possibly cause errors in subsequent cells. \n",
    "# Load one to three files\n",
    "files = ['s01_categories_{:02d}.nii.gz'.format(r) for r in [1, 2, 3]]\n",
    "files = [os.path.join(neurods.io.data_list['fmri'], 'categories', f) for f in files]    \n",
    "for n in range(1, 4):\n",
    "    data = load_data(*files[:n], do_zscore=True)\n",
    "    print(\"Loaded {} files, data shape is:\".format(n), data.shape)\n",
    "    print(\"max={:0.3f}, min={:0.3f}\".format(np.nanmax(data), np.nanmin(data)))\n",
    "    print(\"\")\n",
    "    del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second part of the homework, we will use pycortex to explore the three different scans in the data directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `2.` (4 points) Data visualization with pycortex\n",
    "* [2 pt] Make a plot of the standard deviation of each voxel over time for data from two different experiments. Use the first run of the data we have been working with so far (`'/data/shared/cogneuro88/fMRI/categories/s01_categories_01.nii.gz'`), and the data located at `'/data/shared/cogneuro88/fMRI/motor/s01_motorloc.nii.gz'`. First compute the standard deviation over time. The result will be a 3D volume, with one value per voxel, for each data set. Then use pycortex to map this volume to the cortical surface for s01 for each data set. Don't worry about what was going on in each of these two experiments (we will discuss that next week); just know that the stimulus and the subject's behavior was very different for each of the two experiments. \n",
    "* [2 pt] Describe what you observe.  What does this tell you about the brain / the data? \n",
    "\n",
    "**Hint 1**: mind your color scales! in pycortex, the color scale is set at creation of a Volume object, using vmin and vmax, and the colormap is set using cmap:\n",
    "\n",
    "`data_volume = cortex.Volume(data, sub, xfm, vmin=blah, vmax=deblah, cmap=whatever)`\n",
    "\n",
    "`cmap` should be a string; the options for colormap names are shown in the drop-down menu of the webgl viewer. \n",
    "\n",
    "**Hint 2**: You can also use `cortex.webgl.show(data_volume)` to visualize data on a 3D view of the surface. This may help you answer part 2 of this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "# Note that neurods.io.data_list is a dictionary containing useful paths \n",
    "# that we will use repeatedly in class.\n",
    "cat_exp_data = os.path.join(neurods.io.data_list['fmri'], 'categories', 's01_categories_01.nii.gz')\n",
    "motor_exp_data = os.path.join(neurods.io.data_list['fmri'], 'motor', 's01_motorloc.nii.gz')\n",
    "data_cat = load_data(cat_exp_data, do_zscore=False)\n",
    "# Demostrate what we've done\n",
    "print(data_cat.shape)\n",
    "# Compute STD\n",
    "std_cat = data_cat.std(0) # STD along TIME axis (first, since data was transposed)\n",
    "data_mot = load_data(motor_exp_data, do_zscore=False)\n",
    "# Demostrate what we've done\n",
    "print(data_mot.shape)\n",
    "# Compute STD\n",
    "std_mot = data_mot.std(0) # STD along TIME axis (first, since data was transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub, xfm = 's01', 'catloc'\n",
    "# NOTE that vmax should not be 1500, as it was above; that is appropriate \n",
    "# for the raw data, but not for the standard deviation, which only goes up \n",
    "# to ~200, and then only for a few voxels. \n",
    "std_cat_vol = cortex.Volume(std_cat, sub, xfm, vmin=0, vmax=30, cmap='viridis')\n",
    "std_mot_vol = cortex.Volume(std_mot, sub, xfm, vmin=0, vmax=30, cmap='viridis') \n",
    "_ = cortex.quickflat.make_figure(std_cat_vol)\n",
    "# For clarity, not necessary for full points:\n",
    "_ = plt.title('Standard deviation of visual category experiment', fontsize=24)\n",
    "_ = cortex.quickflat.make_figure(std_mot_vol)\n",
    "# For clarity, not necessary for full points:\n",
    "_ = plt.title('Standard deviation of motor experiment', fontsize=24) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To see what the above maps look like in a 3D brain\n",
    "cortex.webgl.show(std_cat_vol)\n",
    "#cortex.webgl.show(std_mot_vol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "**Answer**\n",
    "\n",
    "(Much leniency was given here; if you said anything remotely sensible, you got the points). \n",
    "\n",
    "The maps of standard deviations over time for both experiments look somewhat similar. Both experiments have voxels with high standard deviations (high variability) in the frontal lobe and in the occipital lobe, near the very back of the brain (the occipital pole). High variability could be due to responses elicited in the experiment, or to noise in the signal that was measured. Since these experiments are very different, it is unlikely that the experiments would elicit large responses in the same locations in the brain. Thus, the regions that are highly variable in both experiments are likely to have high measurement noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
