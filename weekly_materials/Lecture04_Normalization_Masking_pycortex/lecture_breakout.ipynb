{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview \n",
    "\n",
    "In the first ~1/3 of this lecture, we will review homework, programming, and fMRI concepts\n",
    "\n",
    "In the second ~1/3 of this lecture, we will introduce data normalization and logical indexing\n",
    "\n",
    "In the last ~1/3 of this lecture we will introduce software to display fMRI data on a 3D representation of the cortical surface.\n",
    "\n",
    "# Goals\n",
    "* Understand the way pycortex represents a volumetric data set\n",
    "* Create pycortex Volume objects from 3D data, masked data, and time series data\n",
    "* Display data on the cortical surface\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating resources in your server home directory\n",
    "(Run the cells in this section once, then restart your kernel, reload the web page, and skip this section the next time through!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False: # set this to True if you still need to run this, but it should only be run once.\n",
    "    # Updating functions\n",
    "    import neurods\n",
    "    import cortex as cx\n",
    "    # Add figures to notebook\n",
    "    dropbox_link = 'https://www.dropbox.com/s/dkibicpvc13ng27/Archive.zip'\n",
    "    fname = 'figures/'\n",
    "    basedir = '~/cogneuro-connector/weekly_materials/Lecture04_Normalization_Masking_pycortex/'\n",
    "    neurods.io.download_file(dropbox_link, fname, basedir, zipfile=True)\n",
    "    # Update neurods package\n",
    "    neurods.io.update_neurods()\n",
    "    # Update pycortex configuration file\n",
    "    cx.config.set('basic', 'filestore', '/data/shared/cogneuro88/pycortex_store/')\n",
    "    with open(cx.options.usercfg, 'w') as fid:\n",
    "        cx.config.write(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1:  Writing reusable functions\n",
    "& misc. code / efficiency tips!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load some necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set plotting defaults\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created the following functions to make plots of slices of fMRI volumes. In some code libraries, these are called light table or mosaic plots, because in the (literally) dark old days of film photography, photographers used to lay out their film negatives on light tables in a format similar to this to see them.\n",
    "\n",
    "We will want to make plots like this many times throughout the course, so we would like to formalize these functions a little more to make them more readily reusable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_any_slice(volume, slice_number, dimension):\n",
    "    \"\"\"Given an integer and a 3D volume, this function returns the data of \n",
    "    that horizontal slice \"\"\" \n",
    "    if dimension == 0:\n",
    "        img = volume[slice_number, :, :]\n",
    "    elif dimension == 1:\n",
    "        img = volume[:, slice_number, :]\n",
    "    elif dimension == 2:\n",
    "        img = volume[:, :, slice_number]\n",
    "    return img\n",
    "\n",
    "def plot_any_slice_v2(volume, slice_number, dimension, cmap = 'viridis', vmin=0, vmax=2000,\n",
    "                     origin = 'lower', interpolation='nearest', aspect='equal'):\n",
    "    img = get_any_slice( volume, slice_number, dimension)\n",
    "    _ = plt.imshow(img, cmap = cmap, vmin= vmin, vmax = vmax, origin = origin, interpolation = interpolation,\n",
    "                  aspect = aspect)\n",
    "    _ = plt.axis('off')\n",
    "    \n",
    "def plot_all_slices(volume, slice_dimension, nrows, ncols , cmap = 'viridis', vmin=0, vmax=2000,\n",
    "                     origin = 'lower', interpolation='nearest', aspect='equal' ):\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    n_slices = volume.shape[slice_dimension]\n",
    "    for s in range(n_slices):\n",
    "        ax = fig.add_subplot(nrows, ncols, s+1)\n",
    "        plot_any_slice_v2(first_volume, s, slice_dimension, cmap = cmap, vmin= vmin, vmax = vmax, \n",
    "                          origin = origin, interpolation = interpolation,aspect = aspect)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will modify the final function to be more production-ready below. Follow along...\n",
    "\n",
    "* One major addition we need to make is a ***docstring***. See [here](https://github.com/numpy/numpy/blob/master/doc/HOWTO_DOCUMENT.rst.txt#docstring-standard) for a general description of writing docstrings according to the numpy format, and [here](https://github.com/numpy/numpy/blob/master/doc/example.py) for clear examples.\n",
    "* We will use the `**kwargs` syntax to pass keyword arguments from function to function\n",
    "* We will modify argument names to be more similar to arguments in similar functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** I forgot to mention this during class, but there is also a way to set global defaults for plots in matplotlib. Once you have called\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "you can call the following cell to set defaults for the `imshow()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.origin'] = 'lower'\n",
    "plt.rcParams['image.aspect'] = 'equal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "def get_any_slice(volume, slice_number, dimension):\n",
    "    \"\"\"Given an integer and a 3D volume, this function returns the data of \n",
    "    that horizontal slice \"\"\" \n",
    "    if dimension == 0:\n",
    "        img = volume[slice_number, :, :]\n",
    "    elif dimension == 1:\n",
    "        img = volume[:, slice_number, :]\n",
    "    elif dimension == 2:\n",
    "        img = volume[:, :, slice_number]\n",
    "    return img\n",
    "\n",
    "def slice_3d_array(volume, axis, nrows, ncols , vmin=0, vmax=2000, \n",
    "                   figsize=(8,8), slice_prefix=None, **kwargs):\n",
    "    \"\"\"Plot slices of 3D array along an arbitrary axis\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    volume : array\n",
    "        3D array to be plotted\n",
    "    axis : int\n",
    "        dimension to be sliced / plotted\n",
    "    nrows, ncols : int\n",
    "        number of rows / columns in plot\n",
    "    vmin, vmax : scalar\n",
    "        miniumum / maximum value for color scale all plots\n",
    "    figsize : tuple\n",
    "        (X, Y) size in inches for figure\n",
    "    slice_prefix : string or None\n",
    "        If provided as a string, this is a format string for titles of each\n",
    "        individual plot (titles will be `slice_prefix.format(slice_number)`)\n",
    "        if None, no titles are added\n",
    "    Other Parameters\n",
    "    ----------------\n",
    "    kwargs : named keyword arguments\n",
    "        keyword arguments are passed to imshow()\n",
    "    \n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize = figsize)\n",
    "    n_slices = volume.shape[axis]\n",
    "    for s in range(n_slices):\n",
    "        ax = fig.add_subplot(nrows, ncols, s+1)\n",
    "        img = get_any_slice(volume, s, axis)\n",
    "        ax.imshow(img, vmin = vmin, vmax = vmax, **kwargs)\n",
    "        if slice_prefix is not None:\n",
    "            ax.set_title(slice_prefix.format(s))\n",
    "        ax.set_axis_off()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can view the docstring we just wrote by calling:\n",
    "slice_3d_array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test the function with some random data:\n",
    "rdata = np.random.uniform(size=(30,100,100))\n",
    "# (Note that if you don't set vmax here, the plots look blank!)\n",
    "slice_3d_array(rdata, 0, 6, 5, vmax=1, figsize=(5,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be needing this function (or one very like it) throughout the semester, we have incorporated the function (with a few extra bells and whistles) into our `neurods` package. This is a useful workflow: figure out the rudiments of what you want from a function in notebooks or otherwise at the command line, incorporate it into a more permanent library, and continue to make changes to it until it performs its one function very well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import neurods package\n",
    "import neurods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show where the text files supporting this package are on this machine\n",
    "print(neurods.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show help (docstring) for the function\n",
    "neurods.viz.slice_3d_array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show full text of the function (note that there are a few differences between this and the \n",
    "# one we wrote in class above)\n",
    "neurods.viz.slice_3d_array??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make use of that function\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "_ = neurods.viz.slice_3d_array(rdata, axis=0, fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey 1!\n",
    "\n",
    "Asked about shapes of new data resulting from different ways to index into a data set. \n",
    "\n",
    "i.e., if a variable `data` is of shape (120, 25, 104, 104), what is the shape of: \n",
    "* `data[12]`\n",
    "* `data[:10, 0, :, :]`\n",
    "* `data[:, :1, :, :]`\n",
    "* `data.T[..., 12]`\n",
    "\n",
    "(if you missed your chance to answer the question in class, see if you can predict what shape each will be before creating and checking your answer!)\n",
    "\n",
    "You can check the answers by, e.g. :\n",
    "\n",
    "    data = np.random.rand(120, 25, 104, 104)\n",
    "    print(data[12].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "Today, we will load data from a common neuroimaging data format ([NIfTI](https://nifti.nimh.nih.gov/nifti-1/) format). If you find open source neuroimaging data online, it will most likely be in this format. To load this data, we need to use a neuroimaging code library called nibabel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nibabel\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where data for class will be stored (this directory will be updated with more data throughout the semester)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls /data/shared/cogneuro88/fMRI/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a nifti (nii) proxy object\n",
    "fbase = '/Users/mark/Dropbox/data8/' #'/data/shared/cogneuro88'\n",
    "fname = os.path.join(fbase,'fMRI/categories/s01_categories_01.nii.gz')\n",
    "nii = nibabel.load(fname)\n",
    "\n",
    "# This object stores the infomation *about* the fMRI data stored in the file. \n",
    "# This meta-data can be accessed via attributes of the `nii` object.\n",
    "print('nii.in_memory :', nii.in_memory)\n",
    "print('nii.shape :', nii.shape)\n",
    "print('voxel sizes :', nii.header.get_zooms())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also information stored about how the brain was oriented in space as it was scanned, but that is beyond the scope of what we will go into here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieve actual data as an array\n",
    "data = nii.get_data().T\n",
    "print('nii.in_memory : ', nii.in_memory)\n",
    "print('data shape : ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot a few voxels\n",
    "_ = plt.plot(data[:,22:, 45, 45])\n",
    "_ = plt.xlabel('Time (TRs)')\n",
    "_ = plt.ylabel('BOLD signal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW Recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot an image of the first 10 time points for all voxels in one horizontal slice\n",
    "slice_3d_array(data[:10,5], 0, 2, 5, slice_prefix='Time = {}', figsize=(10,4), vmax=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that VERY LITTLE appears to change across these images, because the differences in signal between voxels are greater than the differences across time! This makes visualizations of our data difficult / hard to interpret. Let's look at this a different way:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BREAKOUT SESSION\n",
    "Make an image plot of all the voxels in one horizontal slice. \n",
    "\n",
    "1. Select all time points for one horizontal slice\n",
    "2. Use np.reshape make a 2D array that is (time x voxels) \n",
    "3. Use `plt.imshow` to show that 2D array\n",
    "4. Make the plot pretty! (label axes, set an appropriate color scale, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember to check on a function's help before trying to use it!\n",
    "np.reshape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Also useful for clarifying the form of lesser-used keyword arguments...\n",
    "plt.imshow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "plt.figure(figsize=(10,4))\n",
    "horiz = data[:, 5].reshape(120, 100*100)\n",
    "plt.imshow(horiz, aspect='auto')\n",
    "plt.xlabel('Voxels')\n",
    "plt.ylabel('Time (TRs)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows clearly that the problem is that there's more variability across voxels than there is across time (Some voxels *always* show higher signal than others). This scaling issue complicates some kinds of visualization and analysis. To look at this issue in yet another way, let's look at histograms of the timecourses for two voxels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (New function in next cell - check to see what it does!)\n",
    "np.linspace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(250, 650, 31)\n",
    "voxel_a = data[:, 5, 50, 43]\n",
    "voxel_b = data[:, 5, 50, 53]\n",
    "_ = plt.hist(voxel_a, bins, label='Voxel A')\n",
    "_ = plt.hist(voxel_b, bins, label='Voxel B')\n",
    "plt.legend(frameon=False) # frameon=False -> New fanciness\n",
    "# Add labels! (this was the topic of survey 2)\n",
    "_ = plt.xlabel('Raw fMRI activity\\n(Arbitrary units)', fontsize=16)\n",
    "_ = plt.ylabel('Count (TRs for which\\nsignal fell into one bin)', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey 2!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous homework, we normalized data by setting the minimum of the data to 0 and the max to 1, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minmax_norm(data):\n",
    "    \"\"\"Normalize data to range of 0-1 by subtracting min, dividing by range\"\"\"\n",
    "    data_norm = (data-data.min()) / (data.max()-data.min())\n",
    "    return data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print((np.min(minmax_norm(voxel_a)), np.max(minmax_norm(voxel_b))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the results of normalizing the data this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins01 = np.linspace(0,1,31)\n",
    "voxel_a_n = minmax_norm(voxel_a)\n",
    "voxel_b_n = minmax_norm(voxel_b)\n",
    "_ = plt.hist(voxel_a_n, bins01, label='Voxel A')\n",
    "_ = plt.hist(voxel_b_n, bins01, label='Voxel B')\n",
    "_ = plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks sensible. However, a problem with this normalization method shows up when you have outlying values. What would happen if Voxel A, at one time point, had a (spuriously) very large value? Let's see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, an aside: a cautionary tale. Python memory is weird.\n",
    "a = np.arange(10)\n",
    "b = a\n",
    "b[3] = 63\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You can avoid changing a variable by using the copy package\n",
    "import copy\n",
    "a = np.arange(10)\n",
    "b = copy.copy(a)\n",
    "b[3] = 63\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a variable called voxel_a_wonky and add an outlier to it\n",
    "voxel_a_wonky = copy.copy(voxel_a)\n",
    "voxel_a_wonky[5] = voxel_a_wonky.max()*1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show what you did to the data\n",
    "plt.plot(voxel_a_wonky)\n",
    "_ = plt.xlabel('Time')\n",
    "_ = plt.ylabel('Raw fMRI Activity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See what that outlier does to histogram plots created after our first normalization method!\n",
    "_ = plt.hist(minmax_norm(voxel_a_wonky), bins01, label='Voxel A (w/ outlier)')\n",
    "#_ = plt.hist(minmax_norm(voxel_b), bins01, label='Voxel B') # uncomment this to show voxel_b\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not put the data from both voxels into a similar range, because the max value is not stable (it can change a lot depending on only one data point). In general, (linear) data normalization set you need to *center* it (by subtracting off some value) and to *scale* it (by dividing by some value or performing some nonlinear operation). \n",
    "A more robust, stable way to normalize data is to subtract the *mean* of the data instead of the min, and to divide by the *standard deviation* instead of the range. \n",
    "\n",
    "The *standard deviation* is a measure of the variability of the data, derived from the whole data set (rather than the two points - the min and the max - that we used before.)\n",
    "\n",
    "This process converts the data to *standard scores* or *z scores*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You can compute the standard deviation of voxel A and voxel B using \n",
    "print(np.std(voxel_a), ',', np.std(voxel_b))\n",
    "# or: \n",
    "print(voxel_a.std(), ',', voxel_b.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can look at the standard deviation of the data by slice\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "_ = neurods.viz.slice_3d_array(data.std(axis=0), axis=0, fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows the places in the brain where the signal was most variable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout session\n",
    "Perform normalization of Voxel A and Voxel B by (1) subtracting off the mean (**`array.mean()`** or **`np.mean(array)`**) and (2) dividing by the standard deviation (**`array.std()`** or **`np.std(array)`**)\n",
    "\n",
    "Then repeat the plots we created above (making histograms of the timecourses for Voxel A, with and without an outlier, and for Voxel B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "def znorm(data):\n",
    "    data_norm = (data-data.mean()) / data.std()\n",
    "    return data_norm\n",
    "\n",
    "# Note the bins! \n",
    "#bins = 21 # In the first histogram plot of data that you make for a given data set, \n",
    "          # you may not want to specify bins (in case you miss data outside the \n",
    "          # range of bins you specify)\n",
    "bins = np.linspace(-3,3,31)\n",
    "# alpha values make plot elements transparent \n",
    "# (0 = invisible, 0.5 = partly see-through, 1.0 = opaque)\n",
    "_ = plt.hist(znorm(voxel_a), bins, label='Voxel A', color='b', alpha=.5)\n",
    "_ = plt.hist(znorm(voxel_a_wonky), bins, label='Voxel A, w/ outlier', color='y', alpha=.5)\n",
    "#_ = plt.hist(znorm(voxel_b), bins01, label='Voxel B', color='r', alpha=0.5)\n",
    "_ = plt.legend(frameon=False)\n",
    "_ = plt.xlabel('Activity (z-normalized)')\n",
    "_ = plt.ylabel('Count (TRs)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "z normalization can be performed easily on multi-dimensional arrays using the `zscore` function in scipy.stats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "zscore?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_z = zscore(data, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can repeat a few of the plots we made above, to show that we now see more variation across time than across voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot time x voxels\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(data_z[:, 5].reshape(120, 100*100), aspect='auto', vmin=-3, vmax=3)\n",
    "plt.xlabel('Voxels')\n",
    "plt.ylabel('Time (TRs)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot \n",
    "slice_3d_array(data_z[:10,5], 0, 2, 5, figsize=(10,4), slice_prefix='T = {}', vmin=-3, vmax=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 3: (Skipped - we will do this next week!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onward to 3D data visualizations! \n",
    "\n",
    "We will use a python module called **`pycortex`** to show data in 3D on the brain. This module was developed here at UC Berkeley in the Gallant lab, mostly by James Gao, with help from Alex Huth, Mark Lescroart, and other lab members. The code is freely available online [here](https://github.com/gallantlab/pycortex), and a paper summarizing the code can be found [here](http://journal.frontiersin.org/article/10.3389/fninf.2015.00023/full). \n",
    "\n",
    "To map the functional data onto the cortex, pycortex requires at least two things:\n",
    "\n",
    "1. The cortical surface of the subject. \n",
    "    * pycortex stores cortical surface files (and several other files) for each subject in a reliably structured directory of files. Because of this reliable directory structure, all we need to provide to the code is a subject ID string, and the code will be able to find and load the relevant cortical surface files. \n",
    "2. The functional to anatomical aligmnent of this data to that cortical surface\n",
    "    * Alignment of functional data to anatomical data proceeds by an *affine transform*. How this transformation works is beyond the scope of this class, but you can look it up on [wikipedia](https://en.wikipedia.org/wiki/Affine_transformation) or in your favorite linear algebra textbook if you're curious. The practical upshot is that a 4x4 matrix of numbers is sufficient to store the 3 rotations (around the x, y, and z axes) and 3 the transformations (in the x, y and z dimensions) that will transform the functional data in space such that they are aligned with the anatomical data (with the cortical surface). In the pycortex code (and in other neuroimaging software), \"transform\" is abbreviated in variable names as `xfm`. Just as with the cortical surface, we only need to specify a name for a transform, and the code will know where to find the file that contains the affine transformation matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (1) subject (specifies the cortical surface of the brain)\n",
    "subject = 's01' \n",
    "# (2) transform = functional-to-anatomical alignment\n",
    "transform = 'catloc' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a volume\n",
    "data_volume = cortex.Volume(data[0], subject, transform) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click the link that this generates to see the webgl-based viewer. You can click and drag the brain around to view it from different angles. If you move the mouse up to the gray  top of the browser window, a menu will come down with more display options. If you move the mouse to the bottom of the browser window, there are sliders to adjust the amount of unfolding of the brain and other view parameters. There are also hotkeys you can use to inflate, flatten, and re-fold the brain in the main window (press \"f\" to flatten, \"i\" to inflate, and \"r\" to re-fold\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show the volume in a 3D brain (ooooh)\n",
    "cortex.webgl.show(data_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make an image plot of a flatmap of the cortex\n",
    "cortex.quickflat.make_figure(data_volume)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
