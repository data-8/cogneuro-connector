{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Overview\n",
    "In the last lab and in the homework, we saw how we can model the response of a voxel $v$ to one stimulus $i$ via the hemodynamic response function, and a weight $w$. To do this we assume that we know the shape of the hemodynamic response, and we assume a value for how well a voxel responds to a stimulus. \n",
    "\n",
    "In most experiments however, the experimenter is interested in multiple stimuli. They want to find the brain responses for these different stimuli and compare them. In this lecture, we will see how we can use regression and hypothesis testing to study hypotheses about how the brain responds to different stimuli. \n",
    "\n",
    "# Goals\n",
    "- Neuroscience concepts\n",
    "    - How to model and estimate voxel responses to different conditions\n",
    "    - Computing contrasts between conditions\n",
    "- Coding concepts\n",
    "    - Matrix multiplication and inversion \n",
    "- Datascience concepts\n",
    "    - Multiple regression\n",
    "    - Relating regression to ERPs\n",
    "    - Bootstrap tests for regression and p-values\n",
    "    - Multiple comparison correction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import neurods\n",
    "import numpy as np\n",
    "import cortex\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# Configure defaults for plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.aspect'] = 'auto'\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First let's talk about linear regression, and start to work with a simple problem. Let's say you walk into a grocery store, and you buy 3 oranges and 2 apples. You are told the price is 8\\$. You go another time, you buy 2 oranges and 5 apples, you pay 9\\$. How much do apples and oranges cost?\n",
    "\n",
    "This is a system of two equations with two unknown that you can solve and obtain an exact solution.\n",
    "\n",
    "However, imagine that the cashier doesn't tell you the exact price, but takes the correct price, and then depending on their mood, adds some \"noise\" to the price: you either pay a little less or a little more. This noise doesn't depend on how much your total is, but on other unrelated factors.\n",
    "\n",
    "Can you still estimate accurately the prices if you go twice to the store?\n",
    "\n",
    "What if you go 1000 times?\n",
    "\n",
    "Let's simulate this with a random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# these are the hidden parameters, we are not supposed to know them:\n",
    "apple_price = 0.9\n",
    "orange_price = 1.2\n",
    "pear_price = 1.5\n",
    "noise_variance = 5\n",
    "\n",
    "# sample X and Y:\n",
    "n = 1000\n",
    "X = np.round(np.random.uniform(low = 0, high = 10, size=[n,3])).astype(int)\n",
    "real_beta = np.array([apple_price, orange_price, pear_price]).reshape([3,1])\n",
    "Y = np.dot(X, real_beta) + np.random.normal(size =[n,1] )*noise_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can express the price in one visit j as:\n",
    "\n",
    "\\begin{align}\n",
    "y_j =  X_j W +\\epsilon_j\n",
    "\\end{align}\n",
    "\n",
    "Were the row $X_j = [x^a_j,x^o_j,x^p_j]$ corresponds to the counts $x^a_j,x^o_j,x^p_j$ of apples, oranges and pears bought on visit $j$, and $W = [w_a,w_o,w_p]$ corresponds to the prices of apples, oranges and pears respectively. \n",
    "\n",
    "We can write the entire visits as:\n",
    "\n",
    "\\begin{align}\n",
    "Y =  {\\bf X} W +\\epsilon\n",
    "\\end{align}\n",
    "\n",
    "where\n",
    "- $Y$ is n x 1\n",
    "- ${\\bf X}$ is n x d, here d = 3\n",
    "- ${\\beta}$ is d x 1\n",
    "- $\\epsilon$ is n x 1.\n",
    "\n",
    "Due to the noise, we cannot exactly recover $W$. However, we would like to find a solution $W$ that minimizes the following error as much as possible:\n",
    "\n",
    "\\begin{align}\n",
    "error = \\sum_{j = 1}^N (y_j - X_j W)^2 = ||Y - {\\bf X} W||_2^2\n",
    "\\end{align}\n",
    "\n",
    "This is the sum of squared errors. To minimize this equation with respect to $W$, we first find the derivative with respect to $\\beta$:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\delta \\ error}{\\delta W} &=& \\frac{\\delta ||Y - {\\bf X} W||_2^2}{\\delta W}\\\\\n",
    " &=& -2{\\bf X}^\\top (Y - {\\bf X} W)\\\\\n",
    "\\end{align}\n",
    "\n",
    "The minimum is achieved when the derivative is zero:\n",
    "\n",
    "\\begin{align}\n",
    "-2{\\bf X}^\\top (Y - {\\bf X} \\hat W) = 0\\\\\n",
    "{\\bf X}^\\top Y = {\\bf X}^\\top{\\bf X} \\hat W \\\\\n",
    "\\hat W = ({\\bf X}^\\top{\\bf X})^{-1}{\\bf X}^\\top Y\\\\\n",
    "\\end{align}\n",
    "\n",
    "This is the Ordinary Least Squares Solution. Now write it as a function, then use this function to recover the prices of the fruits, using the following cell:\n",
    "\n",
    "### BREAKOUT SESSION\n",
    "\n",
    "- Use the space below to implement the OLS function that returns the OLS solution\n",
    "- Use the function to compute the prices of the fruits, using the X and Y matrices already in your workspace\n",
    "- What are the estimated prices of apples, oranges and pears? (apple is the first coordinate of X, oranges is the second and pears is the third)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "def OLS(X,Y):\n",
    "### STUDENT ANSWER\n",
    "    return np.dot(inv(np.dot(X.T,X)),np.dot(X.T,Y))\n",
    "prices = OLS(X,Y)\n",
    "print(\"apple price: real {0} estimated {1}\".format(apple_price,prices[0,0]))\n",
    "print(\"orange price: real {0} estimated {1}\".format(orange_price,prices[1,0]))\n",
    "print(\"pear price: real {0} estimated {1}\".format(pear_price,prices[2,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Try to change the number of datapoints and the magnitude of the noise, what do you notice?\n",
    "\n",
    "## Intercept Term\n",
    "\n",
    "Many times, we are interested in modeling $y_j$ as:\n",
    "\n",
    "\\begin{align}\n",
    "y_j =  w_0 + w_1 x^1_j + w_2 x^2_j ... + w_3 x^d_j +\\epsilon_j\n",
    "\\end{align}\n",
    "\n",
    "this means there is a constant intercept term which is always contributed to the output $y_j$. In our store analogy, this could be for example an additional flat fare that is added by the cashier for each costumer. How can we integrate the intercept term in our framework?\n",
    "\n",
    "There is a simple way, notice how we can rewrite the above equation as:\n",
    "\n",
    "\\begin{align}\n",
    "y_j =  w_0 x^0_j+ w_1 x^1_j + w_2 x^2_j ... + w_3 x^d_j +\\epsilon_j\n",
    "\\end{align}\n",
    "\n",
    "where $x^0_j$ is always equal to 1. This can be done by creating a matrix $X'$ by adding an additional column to our matrix $X$ which is all ones. Let's try to estimate the intercept term in our fruit example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X2 = np.hstack([np.ones([n,1]),X])\n",
    "prices = OLS(X2,Y)\n",
    "print('intercept term is estimated to be {0}'.format(prices[0,0]))\n",
    "print(\"apple price: real {0} estimated {1}\".format(apple_price,prices[1,0]))\n",
    "print(\"orange price: real {0} estimated {1}\".format(orange_price,prices[2,0]))\n",
    "print(\"pear price: real {0} estimated {1}\".format(pear_price,prices[3,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The intercept term is estimated to be 0, which makes sense because we didn't specify an intercept term! Let's sample data another time and estimate the intercept again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "intercept_term = 2\n",
    "Y2 = np.dot(X, real_beta) + np.random.normal(size =[n,1] )*noise_variance + intercept_term\n",
    "\n",
    "prices = OLS(X2,Y2)\n",
    "print('intercept term is estimated to be {0}'.format(prices[0,0]))\n",
    "print(\"apple price: real {0} estimated {1}\".format(apple_price,prices[1,0]))\n",
    "print(\"orange price: real {0} estimated {1}\".format(orange_price,prices[2,0]))\n",
    "print(\"pear price: real {0} estimated {1}\".format(pear_price,prices[3,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "When we work with fMRI data, we usually remove the mean of each voxel in the begining of our analysis. This means we don't need to include the intercept term in our design matrix, because it's effectively equal to zero.\n",
    "\n",
    "# Modeling voxel responses\n",
    "\n",
    "Remember, we are using regression because we want to model different voxel responses to a set of stimuli. We learned how to take a stimulus time course and how to convolve it with the hemodynamic response. We then assumed that each voxel's activity was a linear combination of all the convolved time courses of the stimuli. We want to recover the parameters of the linear combination. Let's load some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "basedir = os.path.join(neurods.io.data_list['fmri'],'categories')\n",
    "design = np.load(os.path.join(basedir,'experiment_design.npz'))\n",
    "print('Experiment design variables: ', design.keys())\n",
    "conditions = design['conditions'].tolist()\n",
    "print('Conditions: ', conditions)\n",
    "design_run1 = design['run1']\n",
    "for i, (cond, label) in enumerate(zip(design_run1.T, conditions)):\n",
    "    plt.plot(cond+i+0.2*i, label=label, lw=2)\n",
    "plt.title('Condition labels')\n",
    "_ = plt.legend(frameon=False, bbox_to_anchor=(1.4, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We are going to use the neurods.io.load_fmri_data to load the data with zscoring. We will load the first two runs of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fmri_files1 = ['s01_categories_{:02d}.nii.gz'.format(run) for run in [1,2]]\n",
    "fmri_files1 = [os.path.join(neurods.io.data_list['fmri'], 'categories', f) for f in fmri_files1]\n",
    "\n",
    "sub, xfm = 's01', 'catloc'\n",
    "cortical_voxels = cortex.db.get_mask(sub, xfm, type='cortical')\n",
    "# fmri responses:\n",
    "Y = np.vstack( neurods.io.load_fmri_data(fmri_files1[i], mask=cortical_voxels, do_zscore=True, dtype=np.float32)\n",
    "              for i in [0,1])\n",
    "# stimuli:\n",
    "X = np.vstack([design[run] for run in ['run1','run2']])\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(Y)\n",
    "plt.title('Voxel responses')\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "for i, (cond, label) in enumerate(zip(X.T, conditions)):\n",
    "    plt.plot(cond+i+0.2*i, label=label, lw=2)\n",
    "plt.title('Condition labels')\n",
    "_ = plt.legend(frameon=False, bbox_to_anchor=(1.4, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We need to first build a design matrix that accounts for the hemodynamic response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from neurods.fmri import hrf as generate_hrf\n",
    "t_hrf, hrf_1 = generate_hrf(tr=2)\n",
    "n, d = X.shape\n",
    "\n",
    "conv_X = np.zeros_like(X)\n",
    "for i in range(d):\n",
    "    conv_X[:,i] = np.convolve(X[:,i], hrf_1)[:n]\n",
    "    \n",
    "for i, (cond, label) in enumerate(zip(conv_X.T, conditions)):\n",
    "    plt.plot(cond+i+0.2*i, label=label, lw=2)\n",
    "    \n",
    "plt.title('Condition labels')\n",
    "_ = plt.legend(frameon=False, bbox_to_anchor=(1.4, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We want to find the response of all the voxels in the brain to these 5 different conditions. Instead of a one dimensional output $Y$, we have a high dimensional output ${\\bf Y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For each voxel, we can write the linear model equation as:\n",
    "\n",
    "\\begin{align}\n",
    "y^{v}_j =  X_j W^v +\\epsilon_j^v\n",
    "\\end{align}\n",
    "\n",
    "and:\n",
    "\n",
    "\\begin{align}\n",
    "Y^{v} =  {\\bf X} W^v +\\epsilon^v\n",
    "\\end{align}\n",
    "\n",
    "Since this model exist for every function, we can write it as a multiple regression function:\n",
    "\\begin{align}\n",
    "{\\bf Y} =  {\\bf X} {\\bf W} +\\boldsymbol\\epsilon\n",
    "\\end{align}\n",
    "\n",
    "In the above:\n",
    "- ${\\bf Y}$ is n x nVoxels\n",
    "- ${\\bf X}$ is n x d\n",
    "- ${\\bf W}$ is d x nVoxels\n",
    "\n",
    "Let's try to minimize the sum of squared errors like before with respect to ${\\bf W}$, we first find the derivative:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\delta \\ error}{\\delta {\\bf W}} &=& \\frac{\\delta ||{\\bf Y} - {\\bf X} {\\bf W}||_2^2}{\\delta  {\\bf W}}\\\\\n",
    " &=& -2{\\bf X}^\\top ({\\bf Y} - {\\bf X} {\\bf W})\\\\\n",
    "\\end{align}\n",
    "\n",
    "The minimum is achieved when the derivative is zero:\n",
    "\n",
    "\\begin{align}\n",
    "-2{\\bf X}^\\top ( {\\bf Y} - {\\bf X}{\\bf W}) = 0\\\\\n",
    "{\\bf X}^\\top {\\bf Y} = {\\bf X}^\\top{\\bf X}  {\\bf W}\\\\\n",
    "{\\bf W} = ({\\bf X}^\\top{\\bf X})^{-1}{\\bf X}^\\top {\\bf Y}\\\\\n",
    "\\end{align}\n",
    "\n",
    "This solution is similar to the single dimensional output solution. The first term $({\\bf X}^\\top{\\bf X})^{-1}{\\bf X}^\\top$ is independent of the data. If we are estimating the parameters for one voxel, or for a large number, this term will be the same. \n",
    "\n",
    "Notice also that each voxel's parameters are estimated independently from each other: each column of ${\\bf W}$ corresponds to the parameters of one voxel $v$, and it is obtained by multipling the matrix $({\\bf X}^\\top{\\bf X})^{-1}{\\bf X}^\\top$ with the ${\\bf Y}$ column that corresponds to voxel $v$.\n",
    "\n",
    "Your OLS code for a single voxel should work for multiple outputs as well. Use it to estimate the weights for the 5 conditions for each voxel. Then, using cortex.quickflat.make_figure, make a flatmap plot of the parameters of each of the conditions across the brain.\n",
    "\n",
    "### Breakout session\n",
    "\n",
    "- Now, use the OLS function you implemented earlier to find the weight of the response of each voxel to each condition. \n",
    "- What should you use as input to the OLS function?\n",
    "- Print out the shape of the output of the OLS function. What does it correpond to?\n",
    "- Then, in a for loop, produce a flatmap of the magnitude of the weights for each condition. (use the commands below to help you plot them). Use the name of the conditions as title for your plot (they are all in the variable `condition`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# vol = cortex.Volume(some_vector, sub, xfm, mask = cortical_voxels, vmin = -1.5, vmax = 1.5)\n",
    "# __  = cortex.quickflat.make_figure(vol)\n",
    "# plt.suptitle('some str', fontsize = 30)\n",
    "\n",
    "### STUDENT ANSWER\n",
    "weights = OLS(conv_X, Y)\n",
    "print('shape of weights is {}'.format(weights.shape))\n",
    "# plt.imshow(weights)\n",
    "for idx, condition in enumerate(conditions):\n",
    "    vol = cortex.Volume(weights[idx], sub, xfm, mask = cortical_voxels,vmin = -1.5, vmax = 1.5)\n",
    "    __  = cortex.quickflat.make_figure(vol)\n",
    "    plt.suptitle(condition, fontsize = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Why do we use regression instead of block averages?\n",
    "- What happens when we have event related design? When the conditions overlap?\n",
    "\n",
    "SURVEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "From the flatmaps above, it seems like different regions of the brain are responsive to different stimuli. For example, we can try to estimate which parts of the brain respond more to faces than bodies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vol = cortex.Volume(weights[1] - weights[0], sub, xfm, mask = cortical_voxels,vmin = -1.5, vmax = 1.5)\n",
    "__  = cortex.quickflat.make_figure(vol)\n",
    "plt.suptitle('faces - bodies', fontsize = 30)\n",
    "cortex.webshow(vol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It seems there are effectively regions that are higher for faces than bodies. However, this is finite data from an experiment with a limited duration (effectively, this is only 8 minutes of stimuli). The amount of noise in fMRI data adds error to our estimation. How can we measure how certain we are of our estimates?\n",
    "\n",
    "One way to contruct a confidence interval for our estimates is to use a procedure called the bootstrap. Bootstraping refers to taking a large set of samples from your N data points. Each time, N points are sampled with replacement from the original N samples. The statistic of interest is computed using those N points. This is repeated a large number of times (e.g. 10000). Then, one can use the resulting set of statistics to build a confidence interval. \n",
    "\n",
    "Let's go back to the fruit price example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# these are the hidden parameters, we are not supposed to know them:\n",
    "apple_price = 0.9\n",
    "orange_price = 1.2\n",
    "pear_price = 1.5\n",
    "noise_variance = 5\n",
    "\n",
    "# sample X and Y:\n",
    "n = 1000\n",
    "XFruit = np.round(np.random.uniform(low = 0, high = 10, size=[n,3])).astype(int)\n",
    "real_beta = np.array([apple_price, orange_price, pear_price]).reshape([3,1])\n",
    "YFruit = np.dot(XFruit, real_beta) + np.random.normal(size =[n,1] )*noise_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prices = OLS(XFruit,YFruit)\n",
    "print(\"apple price: real {0} estimated {1}\".format(apple_price,prices[0,0]))\n",
    "print(\"orange price: real {0} estimated {1}\".format(orange_price,prices[1,0]))\n",
    "print(\"pear price: real {0} estimated {1}\".format(pear_price,prices[2,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, we sample with replacement 1000 rows from (XFruit,YFruit). We compute the prices for each fruit using those 1000 points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def randomize_OLS(X,Y):\n",
    "    n = X.shape[0]\n",
    "    sample_index = np.random.choice(n,n)\n",
    "    return OLS(X[sample_index], Y[sample_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Breakout session:\n",
    "\n",
    "- now, run the function randomize_OLS 2000 times, recording the answers in the array `prices_bootstrap` below\n",
    "- for each of the three prices, plot a separate histogram of the estimated weights for all the bootstrap samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prices_bootstrap = np.zeros((2000,3))\n",
    "### STUDENT ANSWER\n",
    "for i in np.arange(2000):\n",
    "    prices_bootstrap[i] = np.squeeze(randomize_OLS(XFruit,YFruit))\n",
    "\n",
    "for i in np.arange(3):\n",
    "    plt.figure()\n",
    "    plt.hist(prices_bootstrap[:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What if I am interested to know if an orange costs more than an apple? From the OLS weights I can see that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prices[1] - prices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "How can we construct a confidence interval for this?\n",
    "\n",
    "In the same way!\n",
    "\n",
    "Run a bootstrap test. At each iteration:\n",
    "- sample n points with replacement\n",
    "- compute your statistic of interest, here it's price of orange - price of apple\n",
    "At the end, contruct a confidence interval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "difference_bootstrap = np.zeros((2000,1))\n",
    "\n",
    "for i in np.arange(2000):\n",
    "    tmp = randomize_OLS(XFruit,YFruit)\n",
    "    difference_bootstrap[i] = tmp[1,0] - tmp[0,0]\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(difference_bootstrap[:,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can see how all the sampled differences are above zero. \n",
    "\n",
    "We can use this data to construct a 99% confidence interval of the difference between the prices of oranges and apples. From the histogram above, it is clear that this confidence will not contain zero. This data therefore suggests that the price of oranges is more than the price of apples.\n",
    "\n",
    "Let's construct that interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "confidence_interval_lower_bound = np.percentile(difference_bootstrap, 0.5)\n",
    "confidence_interval_upper_bound = np.percentile(difference_bootstrap, 99.5)\n",
    "print('with 99% confidence, the difference in price is between {} and {}.'.format(confidence_interval_lower_bound,\n",
    "                                                                                  confidence_interval_upper_bound))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's think of our faces vs. bodies contrast. Some of the voxels are more responsive to faces than to bodies and we would like to identify them. We already computed that contrast between the weights of faces and the weights of bodies. For every voxel in the brain, we want to run the same bootstrap test as above.\n",
    "\n",
    "We will use the same approach. However, different fMRI data points are not IID (independent and identically distributed) because of the slow dynamics leading to the signal. By sampling individual points, the dependencies between the consecutive time points will be broken, and therefore the estimated confidence intervals will not be characteristic of the true variance.\n",
    "\n",
    "Therefore the test we used above will not be adequate to use. We will use here a slightly modified test that samples blocks of data (5TRs) instead of individual TRs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def randomize_OLS_for_fMRI(X,Y):\n",
    "    n = X.shape[0]\n",
    "    n_blocks = int(n/5)\n",
    "    block_index = np.arange(n).reshape([n_blocks,-1])\n",
    "    sample_index = np.random.choice(n_blocks,n_blocks)\n",
    "    sample_index = block_index[sample_index].reshape([-1])\n",
    "    return OLS(X[sample_index], Y[sample_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_bootstrap = 100\n",
    "difference_bootstrap = np.zeros((n_bootstrap,Y.shape[1]))\n",
    "\n",
    "for i in np.arange(n_bootstrap):\n",
    "    tmp = randomize_OLS_for_fMRI(X,Y)\n",
    "    difference_bootstrap[i,:] = tmp[1,:] - tmp[0,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's plot on the brain the lower bound of the 99% confidence interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "confidence_interval_lower_bound = np.percentile(difference_bootstrap, 0.5, axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vol = cortex.Volume(confidence_interval_lower_bound, sub, xfm, mask = cortical_voxels, \n",
    "                    vmin = -np.abs(confidence_interval_lower_bound).max(),\n",
    "                    vmax = np.abs(confidence_interval_lower_bound).max())\n",
    "__  = cortex.quickflat.make_figure(vol)\n",
    "plt.suptitle('faces - bodies', fontsize = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.hist(confidence_interval_lower_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vol = cortex.Volume((confidence_interval_lower_bound>0)*1.0, sub, xfm, mask = cortical_voxels, vmin = -1,\n",
    "                   vmax = 1)\n",
    "__  = cortex.quickflat.make_figure(vol)\n",
    "plt.suptitle('faces - bodies', fontsize = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What do you notice? Why are there so many voxels all around the brain? What did we do here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://imgs.xkcd.com/comics/significant.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://imgs.xkcd.com/comics/significant.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The comic above illustrates the importance of multiple comparison correction. This problem is very important in fMRI. We will discuss it in the next lecture.\n",
    "\n",
    "Meanwhile, you can check out the blog post: https://blogs.scientificamerican.com/scicurious-brain/ignobel-prize-in-neuroscience-the-dead-salmon-study/\n",
    "\n",
    "This is about the following paper: Bennett et al. \"Neural Correlates of Interspecies Perspective Taking in the Post-Mortem Atlantic Salmon: An Argument For Proper Multiple Comparisons Correction\" Journal of Serendipitous and Unexpected Results, 2010.\n",
    "\n",
    "Bennett et al. were able to show that a group of voxels in a dead salmon were implicated in processing social cues from images. This study was designed to show the perils of failing to correct for multiple comparisons.\n",
    "\n",
    "\n",
    "#### Thiking about next week:\n",
    "\n",
    "We will explore these ideas more next week. \n",
    "\n",
    "We will also think about how we can use different designs:\n",
    "- what are problems about block designs?\n",
    "- what other ways do we want to study the brain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
