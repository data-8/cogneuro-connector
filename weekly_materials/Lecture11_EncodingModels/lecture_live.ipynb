{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Overview\n",
    "In the last lecture and lab, we went over how we can use multiple regression to estimate how much a voxel responds to each stimulus in an experiment, and how to use bootstrap tests and confidence intervals to determine if a specific condition activates a voxel more than another condition.\n",
    "\n",
    "# Goals\n",
    "We will first briefly go over the concept of confidence intervals and the multiple comparisons problem. \n",
    "\n",
    "In the second half of the lecture, we will talk about the regression models as predictive models. We can use regression models to predict the activity for each conditions. We will see in this lab how we can perform this prediction. We will also see how we can use complex stimulus that is not neatly categorized into conditions. Learning the brain responses to the different properties of the stimulus will allow us to build models that can predict the activity for new, unseen conditions.\n",
    "\n",
    "- Neuroscience concepts\n",
    "    - Building a predictive model of brain activity\n",
    "    - Using feature spaces to represent the properties of complex stimulus\n",
    "    - Modeling brain responses as a function of stimulus features\n",
    "- Coding concepts\n",
    "    - Implementing splitting data into testing and training sets\n",
    "- Datascience concepts\n",
    "    - Multiple comparisons problem\n",
    "    - Predicting held out data\n",
    "    - Testing and training sets\n",
    "    - Testing model performance (using correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import neurods\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel\n",
    "import cortex\n",
    "# Configure defaults for plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.aspect'] = 'auto'\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "%matplotlib inline\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Some functions that we defined last week\n",
    "from numpy.linalg import inv\n",
    "def OLS(X, Y):\n",
    "    return np.dot(inv(np.dot(X.T, X)), np.dot(X.T, Y))\n",
    "\n",
    "def randomize_OLS(X, Y):\n",
    "    n = X.shape[0]\n",
    "    sample_index = np.random.choice(n,n)\n",
    "    return OLS(X[sample_index], Y[sample_index])\n",
    "\n",
    "def randomize_OLS_for_fMRI(X, Y):\n",
    "    n = X.shape[0]\n",
    "    n_blocks = int(n/5)\n",
    "    block_index = np.arange(n).reshape([n_blocks, -1])\n",
    "    sample_index = np.random.choice(n_blocks, n_blocks)\n",
    "    sample_index = block_index[sample_index].reshape([-1])\n",
    "    return OLS(X[sample_index], Y[sample_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Modeling voxel responses (a recap from last week's lecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Load the same functional localizer data (two blocks of data 4 minutes each) from the past lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load functional localizer information\n",
    "basedir = os.path.join(neurods.io.data_list['fmri'],'categories')\n",
    "\n",
    "# Pycortex plotting information\n",
    "sub, xfm = 's01', 'catloc'\n",
    "cortical_voxels = cortex.db.get_mask(sub, xfm, type='cortical')\n",
    "\n",
    "# Load fMRI data\n",
    "fmri_files1 = ['s01_categories_{:02d}.nii.gz'.format(run) for run in [1,2]]\n",
    "fmri_files1 = [os.path.join(basedir, f) for f in fmri_files1]\n",
    "\n",
    "Y = np.vstack( neurods.io.load_fmri_data(fmri_files1[i], mask=cortical_voxels, do_zscore=True, dtype=np.float32)\n",
    "              for i in [0, 1])\n",
    "print('Voxel responses shape: {}'.format(Y.shape))\n",
    "\n",
    "# Plot fMRI responses\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(Y)\n",
    "plt.title('Voxel responses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Load the same stimuli matrix (design matrix) from the past lecture and convolve it with the hemodynamic response function to account for the slow response measured in our fMRI data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load stimuli (design matrix)\n",
    "design = np.load(os.path.join(basedir,'experiment_design.npz'))\n",
    "print('Experiment design variables: ', design.keys())\n",
    "conditions = design['conditions'].tolist()\n",
    "print('Conditions: ', conditions)\n",
    "\n",
    "X = np.vstack([design[run] for run in ['run1','run2']])\n",
    "print('Stimuli matrix (design matrix) shape: {}'.format(X.shape))\n",
    "\n",
    "# Convolve stimuli with the hemodynamic response function (HRF) (as in Lecture08, and Lecture10)\n",
    "from neurods.fmri import hrf as generate_hrf\n",
    "t_hrf, hrf_1 = generate_hrf(tr=2)\n",
    "n, d = X.shape\n",
    "conv_X = np.zeros_like(X)\n",
    "for i in range(d):\n",
    "    conv_X[:,i] = np.convolve(X[:,i], hrf_1)[:n]\n",
    "print('Convolved stimuli matrix (design matrix) shape: {}'.format(conv_X.shape))\n",
    "\n",
    "# Plot stimuli (design matrix)\n",
    "plt.figure(figsize=(10,4))\n",
    "for i, (cond, label) in enumerate(zip(X.T, conditions)):\n",
    "    plt.plot(cond+i+0.2*i, label=label, lw=2)\n",
    "plt.title('Condition labels')\n",
    "_ = plt.legend(frameon=False, bbox_to_anchor=(1.4, 1))\n",
    "\n",
    "# Plot stimuli (design matrix) convolved with HRF\n",
    "for i, (cond, label) in enumerate(zip(conv_X.T, conditions)):\n",
    "    plt.plot(cond+i+0.2*i, label=label+'_conv', lw=2)\n",
    "    \n",
    "plt.title('Condition labels')\n",
    "_ = plt.legend(frameon=False, bbox_to_anchor=(1.4, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Estimate the weights for all voxels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weights = OLS(conv_X, Y)\n",
    "print('shape of weights is {}'.format(weights.shape))\n",
    "faces_idx = conditions.index('faces')\n",
    "body_idx = conditions.index('body')\n",
    "\n",
    "vol = cortex.Volume(weights[faces_idx] - weights[body_idx], sub, xfm, mask = cortical_voxels,vmin = -1.5, vmax = 1.5)\n",
    "__  = cortex.quickflat.make_figure(vol)\n",
    "plt.suptitle('faces - bodies', fontsize = 30)\n",
    "cortex.webshow(vol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Contrast: faces - body and compute reliability of this difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_bootstrap = 100\n",
    "difference_bootstrap = np.zeros((n_bootstrap, Y.shape[1]))\n",
    "\n",
    "for i in np.arange(n_bootstrap):\n",
    "    tmp = randomize_OLS_for_fMRI(X, Y)\n",
    "    difference_bootstrap[i, :] = tmp[faces_idx, :] - tmp[body_idx, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's\n",
    "- compute the 95% confidence interval of the differences in one voxel (e.g. voxel with the index 2000)\n",
    "- plot the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(difference_bootstrap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot one voxel's difference bootstrap values as a histogram\n",
    "voxel_idx = 2000\n",
    "_ = plt.hist(difference_bootstrap[:, voxel_idx], 20)\n",
    "ci_low = np.percentile(difference_bootstrap[:, voxel_idx], 2.5, interpolation='midpoint')\n",
    "ci_up = np.percentile(difference_bootstrap[:, voxel_idx], 97.5, interpolation='midpoint')\n",
    "plt.plot((ci_low, ci_low), (0, 14), 'r--') \n",
    "plt.plot((ci_up, ci_up), (0, 14), 'r--')\n",
    "\n",
    "print(\"Voxel confidence interval: [{}, {}]\".format(ci_low, ci_up))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Interpretation:\n",
    "\n",
    "We are interested in voxel weight differences (faces - bodies) that are bigger than 0 and fall into the confidence interval. Voxels that are bigger than 0 are those where the weight estimate is bigger to faces than to bodies.\n",
    "\n",
    "- If the lower bound of the confidence interval (ci_low) is bigger than 0, i.e., the values that are in the confidence interval are bigger than 0, then we can say with 95% certainty for this voxel  $faces > bodies$.\n",
    "\n",
    "- If the upper bound of the confidence interval (ci_up) is smaller than 0, i.e., the values that are in the confidence interval are smaller than 0, then we can say with 95% certainty for this voxel $faces < bodies$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let's do this for all voxels:\n",
    "- compute the 95% confidence interval for the differences\n",
    "- for each voxel plot on the flatmap $faces > bodies$\n",
    "- for each voxel plot on the flatmap $faces < bodies$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compute the 95% confidence interval\n",
    "confidence_interval_lower_bound = np.percentile(difference_bootstrap, 2.5, axis=0)\n",
    "confidence_interval_upper_bound = np.percentile(difference_bootstrap, 97.5, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot faces < bodies\n",
    "vol = cortex.Volume((confidence_interval_upper_bound < 0)*1.0, sub, xfm,\n",
    "                    mask = cortical_voxels, vmin=-1, vmax=1, with_colorbar=False)\n",
    "__  = cortex.quickflat.make_figure(vol, with_colorbar=False)\n",
    "plt.suptitle('faces < bodies', fontsize = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot faces > bodies\n",
    "vol = cortex.Volume((confidence_interval_lower_bound > 0)*1.0, sub, xfm,\n",
    "                     mask=cortical_voxels, vmin=-1, vmax=1)\n",
    "__  = cortex.quickflat.make_figure(vol, with_colorbar=False)\n",
    "plt.suptitle('faces > bodies', fontsize = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Breakout session:\n",
    "\n",
    "- What did we plot here?\n",
    "- What do you notice? \n",
    "- Why are there so many voxels all around the brain? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url=\"https://imgs.xkcd.com/comics/significant.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The comic above illustrates the importance of **multiple comparison correction**. This problem is very important in fMRI. Multiple comparison problem is the problem that if you do a lot of different statistical tests (e.g. for each of the > 30 000 voxels, we test whether faces are more activated than bodies), at least some of the tests will be significant, even if they are not really significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## The dead salmon study and the multiple comparisons problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "An influential study by Bennett et al. (2010) showed that a group of voxels in a dead salmon were implicated in processing social cues from images, clearly some **false positives**, i.e., an effect is marked as real or significant even though it was not. This study was designed to show the perils of failing to correct for multiple comparisons.\n",
    "\n",
    "Here are some good blog posts about this study:\n",
    "http://neuroskeptic.blogspot.com/2009/09/fmri-gets-slap-in-face-with-dead-fish.html\n",
    "https://blogs.scientificamerican.com/scicurious-brain/ignobel-prize-in-neuroscience-the-dead-salmon-study/\n",
    "\n",
    "The orinigal study:\n",
    "\n",
    "Bennett et al. \"Neural Correlates of Interspecies Perspective Taking in the Post-Mortem Atlantic Salmon: An Argument For Proper Multiple Comparisons Correction\" Journal of Serendipitous and Unexpected Results, 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url=\"https://blogs.scientificamerican.com/scicurious-brain/files/2012/09/dead-salmon-fmri1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to correct for multiple comparisons and a big chunk of literature exists how to do multiple comparisons testing in fMRI. The most common methos used in fMRI are: Family Wise Error correction such as the Bonferroni correction, and the False Discovery Rate. The details of these methods fall beyond the scope of this lecture. **However, it is very important to do the appropriate multiple comparisons testing when conclusions about the reliability or significance of the results in fMRI are reported.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Predicting withheld data\n",
    "\n",
    "To understand whether the weights of a learned model are meaningful and not due to chance only is to predict a new, previously not used dataset. The idea is that if the weights we estimated are indicative of how the brain responds to the experimental conditions, then we can use them to predict the brain response for a new dataset. Here, we introduce concepts that are very important for the statistics and machine learning fields:\n",
    "\n",
    "- **Training dataset**: This is the part of the dataset you use to estimate your model. You can use this data as you wish. Due to **overfitting** you might want to be careful with how much of the variance of this data you want your model to predict.\n",
    "\n",
    "- **Test dataset**: This dataset should remain untouched until the very end of your analysis, where you only use it to report your results. You should never go back to your analysis and change any parameters based on the performance of your model on the test set.\n",
    "\n",
    "One of the big fallacies in the fMRI literature is that a lot of the studies use the same data to formulate the hypothesis (training a model) and report the involvement of a region (testing a model).\n",
    "\n",
    "However, you should be careful to **never** use the same data to model and to test your hypotheses! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "So far, we only used two blocks of our functional localizer data. We intentionally did not use the third run of our experiment. Now, it is time to use this third run to test the regression model performance of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load functional localizer information\n",
    "basedir = os.path.join(neurods.io.data_list['fmri'],'categories')\n",
    "\n",
    "# Pycortex plotting information\n",
    "sub, xfm = 's01', 'catloc'\n",
    "cortical_voxels = cortex.db.get_mask(sub, xfm, type='cortical')\n",
    "\n",
    "# Load fMRI data for the third run\n",
    "fmri_files2 = 's01_categories_03.nii.gz'\n",
    "fmri_files2 = os.path.join(basedir, fmri_files2)\n",
    "\n",
    "Y_test = neurods.io.load_fmri_data(fmri_files2, mask=cortical_voxels, do_zscore=True, dtype=np.float32)\n",
    "print('Voxel responses shape: {}'.format(Y_test.shape))\n",
    "\n",
    "# Plot fMRI responses\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(Y_test)\n",
    "plt.title('Voxel responses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load stimuli (design matrix)\n",
    "design = np.load(os.path.join(basedir,'experiment_design.npz'))\n",
    "print('Experiment design variables: ', design.keys())\n",
    "conditions = design['conditions'].tolist()\n",
    "print('Conditions: ', conditions)\n",
    "\n",
    "X_test = np.vstack([design[run] for run in ['run3']])\n",
    "\n",
    "# Convolve stimuli with the hemodynamic response function (HRF) (as in Lecture08, and Lecture10)\n",
    "from neurods.fmri import hrf as generate_hrf\n",
    "t_hrf, hrf_1 = generate_hrf(tr=2)\n",
    "n, d = X_test.shape\n",
    "conv_X_test = np.zeros_like(X_test)\n",
    "for i in range(d):\n",
    "    conv_X_test[:,i] = np.convolve(X_test[:,i], hrf_1)[:n]\n",
    "print('Convolved stimuli matrix (design matrix) shape: {}'.format(conv_X_test.shape))\n",
    "\n",
    "# Plot stimuli (design matrix)\n",
    "plt.figure(figsize=(10,4))\n",
    "for i, (cond, label) in enumerate(zip(X_test.T, conditions)):\n",
    "    plt.plot(cond+i+0.2*i, label=label, lw=2)\n",
    "plt.title('Condition labels')\n",
    "_ = plt.legend(frameon=False, bbox_to_anchor=(1.4, 1))\n",
    "\n",
    "# Plot stimuli (design matrix) convolved with HRF\n",
    "for i, (cond, label) in enumerate(zip(conv_X_test.T, conditions)):\n",
    "    plt.plot(cond+i+0.2*i, label=label+'_conv', lw=2)\n",
    "    \n",
    "plt.title('Condition labels')\n",
    "_ = plt.legend(frameon=False, bbox_to_anchor=(1.4, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Breakout Session\n",
    "Using the weights you have estimated before and the conv_X_test predict the activity ${\\bf \\hat Y_{test}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model performance: The correlation between the predicted and the real brain response\n",
    "\n",
    "Now we can use correlation to see whether the predicted brain response (${\\bf \\hat Y_{test}}$) and the actual brain response ($\\bf Y_{test}$) are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(Y_test.shape)\n",
    "print(Y_hat_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Breakout session:\n",
    "\n",
    "- Predict brain brain responses to $faces$ and $bodies$ separately\n",
    "- Using the compute_correlation function, compute the model performance\n",
    "- make a flatmap of the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_correlation(matrix_1, matrix_2):\n",
    "    matrix_1_norm  = zscore(matrix_1)\n",
    "    matrix_2_norm  = zscore(matrix_2)\n",
    "    corr = np.mean(matrix_1_norm*matrix_2_norm, axis=0)\n",
    "    return corr\n",
    "\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Complex Stimuli\n",
    "\n",
    "The approach we saw so far allows us to estimate and predict the response of each voxel to one of a few conditions. \n",
    "\n",
    "What if we are interested in a more complex stimuli than a few conditions only. For example, if we are interested in how the brain responses to a variety of word meanings when we speak, read, or listen to words? It would take an extremely long time to test every possible word one by one.\n",
    "\n",
    "Another approach is therefore to image the brain activity while the subject sees a large number of different stimuli that vary along multiple dimensions. The idea is to cover the space of variability so that the contribution of each feature of the stimulus can be recovered from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will use freely available data from the Mitchell et al. 2008 Science paper: https://www.cs.cmu.edu/afs/cs/project/theo-73/www/science2008/data.html\n",
    "\n",
    "The experiment actually consist in subjects looking at words/line drawings that are presented in isolation.\n",
    "\n",
    "In this dataset, a stimulus was presented every 10 seconds, and the activity between 4 and 8 seconds after onset was averaged, resulting in one brain image for every stimulus presentation. Each stimulus was repeated 6 times, and the repetitions of all the stimuli was averaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url=\"http://www.cs.cmu.edu/~lwehbe/files/science.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "NOTE: KERNEL RESTART TO SAVE MEMORY!\n",
    "\n",
    "#### Load functions into the workspace again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import neurods\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel\n",
    "import cortex\n",
    "# Configure defaults for plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.aspect'] = 'auto'\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "%matplotlib inline\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Some functions that we defined last week\n",
    "from numpy.linalg import inv\n",
    "def OLS(X,Y):\n",
    "    return np.dot(inv(np.dot(X.T,X)),np.dot(X.T,Y))\n",
    "\n",
    "def randomize_OLS(X,Y):\n",
    "    n = X.shape[0]\n",
    "    sample_index = np.random.choice(n,n)\n",
    "    return OLS(X[sample_index], Y[sample_index])\n",
    "\n",
    "def randomize_OLS_for_fMRI(X,Y):\n",
    "    n = X.shape[0]\n",
    "    n_blocks = int(n/5)\n",
    "    block_index = np.arange(n).reshape([n_blocks,-1])\n",
    "    sample_index = np.random.choice(n_blocks,n_blocks)\n",
    "    sample_index = block_index[sample_index].reshape([-1])\n",
    "    return OLS(X[sample_index], Y[sample_index])\n",
    "\n",
    "def compute_correlation(matrix_1, matrix_2):\n",
    "    matrix_1_norm  = zscore(matrix_1)\n",
    "    matrix_2_norm  = zscore(matrix_2)\n",
    "    corr = np.mean(matrix_1_norm*matrix_2_norm, axis=0)\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load the mask\n",
    "basedir = os.path.join(neurods.io.data_list['fmri'], 'word_picture')\n",
    "filename = os.path.join(basedir,'s03_mask.nii')\n",
    "mask = neurods.io.load_fmri_data(filename, do_zscore=False)\n",
    "mask = (mask==1)\n",
    "\n",
    "# Load the fMRI data\n",
    "basedir = os.path.join(neurods.io.data_list['fmri'],'word_picture')\n",
    "filename = os.path.join(basedir,'s03.nii.gz')\n",
    "data = neurods.io.load_fmri_data(filename, do_zscore=True, mask=mask)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Here we load the 60 words that comprise our stimuli\n",
    "feature_data = np.load(os.path.join(basedir, 'features.npz'))\n",
    "words = feature_data['words']\n",
    "\n",
    "print(\"Here are the stimulus words: \\n\")\n",
    "print (\" - \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_num = 1 # change the word number\n",
    "\n",
    "sample_image = np.zeros(mask.shape)\n",
    "sample_image[mask==True] = data[word_num]\n",
    "h = cortex.mosaic(sample_image)\n",
    "plt.colorbar();\n",
    "\n",
    "plt.title(words[word_num], size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### How is the design matrix constructed in this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This dataset already accounts for the delay of the hemodynamic response. Therefore we do **not** need to convolve our design matrix. We will see here how we can construct a design matrix appropriate for such an experiment.\n",
    "\n",
    "How can we represent the activity for word that do not belong into clear conditions? \n",
    "\n",
    "We could try to make each item to be a condition. Ending up with 60 conditions. We see each word only once. How would that help us? We would be able to compute a contrast map between \"horse\" and \"table\", but that would not tell us much about why these differences occur. Also, learning a response per word will not allow us to know what the activity will be like for new words, such as \"goat\", \"pen\" etc.\n",
    "\n",
    "However, new words have some features in common with the set of items in this experiment (the 60 conditions) . What if we could learn the responses to specific properties of words (e.g. whether or not they are animate, whether or not they are edible etc.). Then we could predict the activity of a new word as a combination of the activities associated with its properties. For example, we can learn how the brain responds to objects that are manmade, inanimate, made of wood and that are used as tools, and we can estimate the brain response of the word \"pen\" as the combination of these responses.\n",
    "\n",
    "We will do this using multivariate regression that we learned in the last lecture.\n",
    "\n",
    "First, we need an annotation of the properties (e.g. animacy, manmade, tool, etc.) of these words. From looking at the list of words, it's clear that there are many properties that different sets of words share.\n",
    "\n",
    "We have access to a set of 218 questions for which every word has been labeled by multiple users on Amazon Mechanical Turk (Sudre et al., Neuroimage, 2012). These questions were designed to represent the semantic properties of these objects. Additionally, 11 features describing the visual properties of the line drawings are also provided.\n",
    "\n",
    "The scale of the features is 1-5 with,\n",
    " - 1 being a 100% not having a given property (e.g. not animate), and \n",
    " - 5 being 100% yes of having a property (e.g. animate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "feature_names = feature_data['feature_names']\n",
    "features = feature_data['features']\n",
    "print(\"We have {0} features that describe the stimulus.\\n\".format(len(feature_names)))\n",
    "print(feature_names[:11])\n",
    "\n",
    "print(\"The features matrix therefore has {0} rows and {1}.\\n\".format(len(words), len(feature_names)))\n",
    "\n",
    "\n",
    "feature_i = 10\n",
    "print(\"FEATURE NUMBER {0}\".format(feature_i))\n",
    "print(feature_names[feature_i])\n",
    "for i in range(20):\n",
    "    print(words[i], features[i, feature_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print (\"Features 1 to 218\\n\")\n",
    "for i in range(15):\n",
    "    print(feature_names[i])\n",
    "print (\"...\")\n",
    "\n",
    "print (\"\\n\\nFeatures 219 to 229\\n\")\n",
    "for i in range(218, 229):\n",
    "    print(feature_names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's only stick to the visual features for simplicity for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "features = features[:, 218:]\n",
    "feature_names = feature_names[218:]\n",
    "\n",
    "print (\"New features size is {0}\".format(features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### What makes a \"word\" in our dataset?\n",
    "\n",
    "Every word is characterized by:\n",
    "\n",
    "-  a vector of visual properties. For example for the \"apartment\" stimulus, Word length has a score of 4, the count of white pixels has a score of 4 etc., and\n",
    "\n",
    "-  a 3D brain image. This is basically a set of 21764 number. Each dimension corresponds to a voxel location. We can therefore think of the brain image as a vector. \n",
    "\n",
    "See below how \"apartment\" is represented:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word_i = list(words).index('apartment')\n",
    "print (\"\\n Word = {0}\\n\\n Features = \\n {1}\".format(words[word_i], features[word_i], size=20))\n",
    "vol = cortex.Volume(data[word_i],'MNI','atlas336', mask=mask)\n",
    "fig = cortex.quickflat.make_figure(vol)\n",
    "plt.suptitle(words[word_i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Breakout session\n",
    "\n",
    "Let's checkout other words: Plot the words 'eye', 'foot', 'cat', 'dog'\n",
    "\n",
    "What can you say about the features and the corresponding brain responses in the flatmaps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We have a matrix of 60 words x 12 features, and a matrix of 60 words x 21764 voxels. Let's focus on one voxel. We ultimately want to predict that voxel activity as a function of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Select one randomly chosen voxel\n",
    "random_index = 1549\n",
    "vox = np.reshape(data[:, random_index], [60, 1])\n",
    "show_mat = [features.T , vox.T]\n",
    "\n",
    "print(\"Size of features: {}\".format(show_mat[0].shape))\n",
    "print(\"Size of one voxel's fMRI response/data: {}\".format(show_mat[1].shape))\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 12))\n",
    "for cnt, ax in enumerate(axes.flat):\n",
    "    im = ax.matshow(show_mat[cnt].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## BUILDING A PREDICTIVE MODEL\n",
    "\n",
    "### IT IS VERY IMPORTANT NOT TO USE TEST DATA IN TRAINING!!\n",
    "\n",
    "To judge if a model has learned to predict brain activity outside, we need test it on data it has not seen in training. \n",
    "\n",
    "Imagine you have a small dataset with voxel responses to features, and some of the voxels have some noise that is correlated to one of the features. The probability of such an event becomes smaller as the dataset size increases, but at low sample sizes there is a good chance of finding spurious correlations. \n",
    "\n",
    "Such a correlation actually allows you to build a model that predicts brain activity from the features, but only in that dataset, since the noise is independent of the data and will not repeat in the same way in other datasets. However, for the voxels that show a real and strong enough response to the features, you will be able to learn a model that predicts brain activity from the features, and that model should generalize to new data.\n",
    "\n",
    "This is why we always test a model on held out data that was not used in training. This allows us to judge whether the model is really predicting neural activity and not just fitted to noise in the sample.\n",
    "\n",
    "Here we separate for you the words into a test and a train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Test_index = [0, 1, 2, 3, 4, 6, 7, 8, 10, 13, 20, 23]\n",
    "Train_index = list(set(range(60)) - set(Test_index))\n",
    "\n",
    "Train_X = zscore(features[Train_index, :])\n",
    "Train_Y = zscore(data[Train_index, :])\n",
    "print (\"Shape of training features: {0}, shape of training fMRI data: {1}\".format(Train_X.shape, Train_Y.shape))\n",
    "\n",
    "Test_X = zscore(features[Test_index, :])\n",
    "Test_Y = zscore(data[Test_index, :])\n",
    "print (\"Shape of testing features: {0}, shape of testing fMRI data: {1}\".format(Test_X.shape, Test_Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Weight estimation and data prediction\n",
    "\n",
    "We want to learn a function that predicts the activity for any word in terms of its features. \n",
    "\n",
    "\n",
    "#### Breakout session\n",
    "- Use the OLS function to estimate the brain response to the various features for every voxel.\n",
    "- Use the estimated weights to predict the activity for the held-out words, using Test_X.\n",
    "- Use the compute_correlation function to compute the correlation of your predicted activity and the real activity Test_Y\n",
    "- Plot a flatmap of the prediction performance. Which regions are well predicted, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cor = compute_correlation(Test_Y, Pred_Y)\n",
    "# vol = cortex.Volume(cor, 'MNI', 'atlas336', mask=mask, vmin=0, vmax=0.6, cmap='viridis')\n",
    "# fig = cortex.quickflat.make_figure(vol, height=500)\n",
    "# plt.title(\"prediction performance with visual features\", fontsize=20)\n",
    "\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
