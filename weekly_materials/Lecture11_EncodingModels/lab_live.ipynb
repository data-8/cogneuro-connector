{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Overview\n",
    "\n",
    "In the lecture, we saw how we can use regression to predict brain activity of a withheld dataset. We learned to split the data into two distinct sets: a training and a testing dataset.\n",
    "\n",
    "- **Training dataset**: This is the part of the dataset you use to estimate your model. You can use this data as you wish. Due to **overfitting** you might want to be careful with how much of the variance of this data you want your model to predict.\n",
    "\n",
    "- **Test dataset**: This dataset should remain untouched until the very end of your analysis, where you only use it to report your results. You should never go back to your analysis and change any parameters based on the performance of your model on the test set.\n",
    "\n",
    "We selected **two** of the **three** functional localizer runs as our **training dataset** and one separate run as our **testing dataset**. We did the following steps,\n",
    "\n",
    "- estimated **model weights** ($W$) using *ordinary least squares* (`OLS` function) and the training dataset,\n",
    "- used these estimated model weights to **predict** the withheld testing dataset ($\\hat{Y}_{test}$)\n",
    "- computed **model performance** (the correlatin between the predicted ($\\hat{Y}_{test}$ and actual fMRI data $Y_{test}$) as a measure of regression model performance\n",
    "- visualized the model performance (i.e, correlation coefficients) on the cortical surface to see which parts of the brain are well predicted by our model.\n",
    "\n",
    "In this homework, we will use this predictive modeling approach. The predictions on one withheld dataset (the testing run) can sometimes be noisy as well. Hence, here we want to extend the prediction procedure that we learned in the lecture. The method we will implement in this lab is called **cross validation**. This method helps us to have a more reliable understanding of how well our model predicts the fMRI data than only using a fixed testing run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import neurods\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel\n",
    "import cortex\n",
    "# Configure defaults for plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.aspect'] = 'auto'\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "%matplotlib inline\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Some functions that we defined in the past weeks\n",
    "from numpy.linalg import inv\n",
    "def OLS(X, Y):\n",
    "    return np.dot(inv(np.dot(X.T, X)), np.dot(X.T, Y))\n",
    "\n",
    "def randomize_OLS(X, Y):\n",
    "    n = X.shape[0]\n",
    "    sample_index = np.random.choice(n,n)\n",
    "    return OLS(X[sample_index], Y[sample_index])\n",
    "\n",
    "def randomize_OLS_for_fMRI(X, Y):\n",
    "    n = X.shape[0]\n",
    "    n_blocks = int(n/5)\n",
    "    block_index = np.arange(n).reshape([n_blocks, -1])\n",
    "    sample_index = np.random.choice(n_blocks, n_blocks)\n",
    "    sample_index = block_index[sample_index].reshape([-1])\n",
    "    return OLS(X[sample_index], Y[sample_index])\n",
    "\n",
    "def compute_correlation(matrix_1, matrix_2):\n",
    "    matrix_1_norm  = zscore(matrix_1)\n",
    "    matrix_2_norm  = zscore(matrix_2)\n",
    "    corr = np.mean(matrix_1_norm*matrix_2_norm, axis=0)\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load functional localizer information\n",
    "basedir = os.path.join(neurods.io.data_list['fmri'],'categories')\n",
    "\n",
    "# Pycortex plotting information\n",
    "sub, xfm = 's01', 'catloc'\n",
    "cortical_voxels = cortex.db.get_mask(sub, xfm, type='cortical')\n",
    "\n",
    "# Load MRI data files\n",
    "fmri_files = ['s01_categories_{:02d}.nii.gz'.format(run) for run in [1, 2, 3]]\n",
    "fmri_files = [os.path.join(basedir, f) for f in fmri_files]\n",
    "print('FMRI files:')\n",
    "print(fmri_files)\n",
    "print('\\n')\n",
    "\n",
    "Y = [neurods.io.load_fmri_data(fmri_files[i], mask=cortical_voxels,\n",
    "                              do_zscore=True, dtype=np.float32)\n",
    "              for i in [0, 1, 2]]\n",
    "print('Voxel responses shape: {}'.format(len(Y)))\n",
    "\n",
    "# Design matrix\n",
    "design = np.load(os.path.join(basedir,'experiment_design.npz'))\n",
    "print('Experiment design variables: ', design.keys())\n",
    "print('\\n')\n",
    "conditions = design['conditions'].tolist()\n",
    "print('Conditions: ', conditions)\n",
    "\n",
    "X = [design[run] for run in ['run1', 'run2', 'run3']]\n",
    "print('Stimuli matrix (design matrix) shape: {}'.format(len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the shapes of the fMRI and stimuli data\n",
    "print([y.shape for y in Y])\n",
    "print([x.shape for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### [10 points] 1. Implement cross validation\n",
    "\n",
    "#### (a) [6 points]  We would like you to iterate through the number of runs. At each iteration: \n",
    " - Leave one fMRI run (and the corresponding run in the design matrix) as the testing dataset. \n",
    " - Estimate the regression model weights on the other runs (the training runs).\n",
    " - Use these weights to predict fMRI activity for the withheld testing run.\n",
    " - Compute the model performance.\n",
    " - Save the model_performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HINTs:**\n",
    " - Use the np.vstack function (as we did in the lecture) to stack more than one run together for training.\n",
    " - Remember to convolve the design matrix with the HRF to account for the hemodynamic response delay.\n",
    " - You probably use the similar plots (to plot the training and testing datasets) and check the sizes of your matrices as in the lecture to make sure that you split your data correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) [2 points] Once you have a functioning implementation, convert this into a function. The docstring of this function should look like below:\n",
    "\n",
    "```\n",
    "def prediction_CV(Y, X):\n",
    "  \"\"\"\n",
    "  Parameters\n",
    "  ---------\n",
    "  Y : A list of fMRI data. Each list entry is an fMRI run.\n",
    "  X : A list of stimulus data (design matrix). Each list entry is a stimulus run.\n",
    "  \n",
    "  Returns\n",
    "  -------\n",
    "  cv_model_performance : Correlation coefficients for each cross validation step and voxel. \n",
    "                         This should be a list with each list element having number of voxels.\n",
    "  \n",
    "  \"\"\"\n",
    "```\n",
    "\n",
    "Use this function to run your cross validation results and visualize the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) [2 points] Plot the average model performance values onto the cortical flatmap. What can you conclude?\n",
    " - c1. Plot first the model performance map from each cross validation step separately. Describe what you notice when you compare these different maps.\n",
    " - c2. Plot the average of the three cross validation steps. Describe what you notice when you compare this map to the previous maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
