{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import imp\n",
    "import neurods\n",
    "# Add figures to notebook\n",
    "os.symlink('/home/shared/cogneuro-connector/data/Week07_IntroFMRI_RawData/figures/','figures')\n",
    "# Update neurods package\n",
    "neurods.io.update_neurods()\n",
    "imp.reload(neurods.io)\n",
    "neurods.io.update_neurods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that the neurods output above loads version 0.2 of neurods for the second call of `update_neurods()`. Restart your kernel after running the above cells and reload this page in your browser. Skip the cells above after you have run them once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "## Introduction to functional magnetic resonance imaging (fMRI) - Part 2\n",
    "\n",
    "In this session, we will continue working on the material from last week and learn about normalization and masking data.\n",
    "In the second part of the class we will work with a visualization tool called [pycortex](http://gallantlab.org/pycortex/docs/).\n",
    "\n",
    "# Goals for today\n",
    "\n",
    "We will go over some important concepts of data manipulation and visualization in fMRI, including: \n",
    "\n",
    "* Normalize a timeseries\n",
    "* Masking / unmasking of fMRI data\n",
    "\n",
    "By the end, we will have written functions to:\n",
    "\n",
    "* Mask and unmask an array\n",
    "* Normalize a timeseries\n",
    "\n",
    "\n",
    "## Short fMRI recap\n",
    "\n",
    "Things to remember:\n",
    "\n",
    " - The functional signal we measure with fMRI is *not* an electrical neural signal (as in EEG, ECoG, or electrophysiology). It is a magnetic signal related to the properties of brain tissue, and it is dominated by blood flow. \n",
    " - Blood flow is related to neural activity. \n",
    "     - Neural firing is metabolically demanding. \n",
    "     - Once region of the brain becomes active (once the neurons start firing), metabolism in that region is high and the neurons in that region need glucose. \n",
    "         - Glucose is not stored in the brain and needs to be transported to the active region whenever energy is needed. \n",
    "         - Glucose transported in red blood cells initiates a complex process to increase blood flow to the electrically active area bringing more oxygen into the region. \n",
    "         - When activity is high in a region oxygen gets stripped off of hemoglobin molecules in red blood cells(thereby changing the magnetic properties of hemoglobin, creating a deoxyhemoglobin). \n",
    "  - There are several ways to measure functional responses with MRI, and the specific one that we work with is the Blood Oxygenation Level Dependent Response, or the BOLD response. \n",
    "\n",
    "<img src=\"figures/deoxyhemoglobin.png\" style=\"height: 400px;\">\n",
    "\n",
    "\n",
    "## FMRI activity in time\n",
    "\n",
    "Once a neural event is triggered by a stimulus presentation the vascular system needs to respond to the need for glucose and oxygen in that specific brain area. This can take up to 1-2 seconds. Hence the hemodynamic response lags the triggered event by 1-2 seconds, which peaks around 5 seconds after the stimulus onset.\n",
    "\n",
    "<img src=\"figures/lagged_activity.png\" style=\"height: 400px;\">\n",
    "\n",
    "## Storing fMRI data for data analysis\n",
    "\n",
    "We store fMRI data as a matrix. This means that each volume (a timepoint) in the experiment will correspond to a row in the matrix, and each voxel will correspond to a column in that matrix. For this reason, we need to make sure the criteria we use to move each 3D image to a matrix row is preserved and this operation is inverted. Let's look at an example.\n",
    "\n",
    "<img src=\"figures/fmri_dimensions.png\" style=\"height: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nibabel\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt  # for visualization\n",
    "\n",
    "# Set defaults for matplotlib plotting in the notebook\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "plt.rcParams['image.aspect'] = 'auto'\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we will load one run (also referred to as a scan) worth of fMRI data that was stored as a nifti file format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a nifti (nii) proxy object\n",
    "fname = '/home/shared/cogneuro-connector/data/fmri/categories/sub01_categories1_1.nii.gz'\n",
    "nii = nibabel.load(fname) \n",
    "\n",
    "# This object stores the infomation *about* the fMRI data stored in the file. \n",
    "# This meta-data can be accessed via attributes of the `nii` object.\n",
    "print('nii.in_memory : ', nii.in_memory)\n",
    "print('nii.shape : ', nii.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimensions of the data are (X, Y, Z, T) (T is time, in TRs). Thus, there are 120 volumes (120 time points). Each volume has 30 horizontal or transverse slices with 100 x 100 pixels.\n",
    "\n",
    "<img src=\"figures/slices.png\" style=\"height: 200px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieve actual data as an array\n",
    "data = nii.get_data()\n",
    "print('nii.in_memory : ', nii.in_memory)\n",
    "print('data shape : ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transpose data\n",
    "data = data.T\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can select one volume like this: \n",
    "first_volume = data[0, :, :, :]\n",
    "\n",
    "# Or like this: \n",
    "alt_first_volume1 = data[0, ...]\n",
    "\n",
    "# Or like this: \n",
    "alt_first_volume2 = data[0]\n",
    "\n",
    "# These are all the same1\n",
    "assert np.all(first_volume==alt_first_volume1)\n",
    "assert np.all(first_volume==alt_first_volume2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(first_volume.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all horizontal slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to make a plot with all of the horizontal slices, so we can see one entire 3D volume at once. For this, we will use the `subplot()` function in matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "n_slices = 30\n",
    "nrows, ncols = 5, 6\n",
    "for s in range(n_slices):\n",
    "    ax = fig.add_subplot(nrows, ncols, s+1)\n",
    "    slice_horizontal = first_volume[s,:,:]\n",
    "    plt.imshow(slice_horizontal)\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a function that plots the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_horizontal_slices(vol, **kwargs):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    nslices = vol.shape[0]\n",
    "    subplot_size = np.ceil(np.sqrt(nslices))\n",
    "    for s in range(nslices):\n",
    "        ax = fig.add_subplot(subplot_size, subplot_size, s+1) \n",
    "        slice_horizontal = vol[s,:,:]\n",
    "        plt.imshow(slice_horizontal, **kwargs)\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking\n",
    "\n",
    "You may have noticed in the figure above that many of the voxels do not overlap with the brain (or more specifically the gray matter in the cortex) at all. Actually, let's try to plot some of those voxels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(data[:,0,0,0], label='Edges of volume, 1')\n",
    "plt.plot(data[:,1,1,1], label='Edges of volume, 2')\n",
    "plt.plot(data[:,-1,-1,-1], label='Edges of volume, 3')\n",
    "\n",
    "# A middle brain voxel\n",
    "plt.plot(data[:,10,34,34], label='Mid brain')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The edge-of-scan voxels are clearly not in the brain, however, they show some variance due to noise. It is the practice in fMRI to mask out, or zero out these voxels.\n",
    "\n",
    "A mask is a 3D binary array that is derived from the high resolution anatomical scan of the subject. The mask indicates, for every voxel in the 30 x 100 x 100 matrix, which ones should be ignored and which should be kept. Let's load and look at a voxel mask for this subject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load a stored mask for this subject\n",
    "fname = '/home/shared/cogneuro-connector/data/fmri/categories/s01_category_mask_cortical.npz'\n",
    "mask = np.load(fname)['mask']\n",
    "print('Mask shape: ', mask.shape)\n",
    "print(mask[10,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot one fo the slices below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask_horizontal = mask[15,:,:]\n",
    "plt.imshow(mask_horizontal, origin='upper', cmap='gray')\n",
    "_ = plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the mask clearly indicates which voxels should be kept. \n",
    "\n",
    "### Breakout session: \n",
    "> Let's look at the 3D structure. Use the function we defined above to plot the entire 3D mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how now we have a mask that indicates which voxels we should keep and which we should exclude.\n",
    "\n",
    "We can use the mask to set the tiny values outside the brain, and the values in the middle of the brain (in subcortical stuctures) to zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's plot the horizonral slices for the first volume\n",
    "plot_horizontal_slices(first_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masked_vol_0 = first_volume * mask\n",
    "\n",
    "# Now plot masked_vol_0:\n",
    "plot_horizontal_slices(masked_vol_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the voxels outside the cortex (including in the middle of the brain) are zeroed out now! Let's apply this mask to the entire dataset now and zero out the same voxels in each volume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First create an array with zeros\n",
    "print(data.shape)\n",
    "masked_data = np.zeros_like(data)\n",
    "\n",
    "# NOTE: np.zeros_like is similar to creating an array using np.zeros. We can check this by:\n",
    "assert np.all(np.zeros(data.shape)==np.zeros_like(data)) \n",
    "\n",
    "# Not run through the entire data set and mask each volume\n",
    "for i in range(data.shape[0]):\n",
    "    masked_data[i,:,:,:] = data[i,:,:,:] * mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick example for list comprehension\n",
    "\n",
    "We can replace the above for loop using list comprehension.\n",
    "\n",
    "In general, list comprehension can be used to tranform a list to another list. During this process in the new list elements of the old list can be modified. List comprehensions can be used to replace many lines of code to a more compact one line. Every list comprehension can be written as a for loop. The opposite is not necessarly true.\n",
    "\n",
    "We can basically use the same masking operation from the cell above and replace it by list comprehension. Let's see first how list comprehension works in a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.arange(5)\n",
    "print('Input list: {}'.format(x))\n",
    "\n",
    "# Let's create a for loop that squares each element in this list\n",
    "# Afterwards, do the same using list comprehension \n",
    "# Compare the resulting arrays\n",
    "\n",
    "### TEACHER INFO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use list comprehension to create the masked_data in a neat way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take individual volumes from data along the first dimension, and multiplies them by the mask\n",
    "masked_data_v1 = [d*mask for d in data]  \n",
    "print('masked_data_v1 is a {0} of size {1}'.format(type(masked_data_v1), len(masked_data_v1)))\n",
    "print('each element is a {0} of size {1}'.format(type(masked_data_v1[0]), masked_data_v1[0].shape))\n",
    "print('Type: {}, Shape: {}'.format(type(masked_data_v1), np.shape(masked_data_v1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to combine them into an array, this is done as follows, and results in a 4 dimensional array. This stacks the data such as the first dimension is the one that is defined by the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masked_data_v2 = np.array([d*mask for d in data])\n",
    "\n",
    "print('masked_data_v2 is a {0} of size {1}'.format(type(masked_data_v2), masked_data_v2.shape))\n",
    "print('each element is a {0} of size {1}'.format(type(masked_data_v2[0]), masked_data_v2[0].shape))\n",
    "print('Type: {}, Shape: {}'.format(type(masked_data_v2), np.shape(masked_data_v2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout session:\n",
    "\n",
    "> Now try plotting other volumes from masked_data_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logical indexing on the data array\n",
    "You can see that there are many voxels that do not contain interesting information. Instead of storing each volume as a 3D array, we can instead take only the voxels that are in the mask.\n",
    "\n",
    "We can use logical indexing to do this. Logical indexing can be used on any array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "idx = np.array([True, False, True, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(a[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# More examples: 2D\n",
    "a = np.arange(20).reshape(5,4)\n",
    "print(a)\n",
    "idx = np.array([False, True, False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(a[:, idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_volume = data[0]\n",
    "print('shape of first_volume is {}'.format(first_volume.shape))\n",
    "\n",
    "first_volume_masked = first_volume[mask==True]  # we can omit ==True, because mask is already a boolean array\n",
    "print('shape of first_volume_masked is {}'.format(first_volume_masked.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(first_volume_masked.flatten(), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compress the entire matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masked_data_v3 = data[:, mask]\n",
    "\n",
    "print('masked_data_v3 is a {0} of size {1}'.format(type(masked_data_v3), masked_data_v3.shape))\n",
    "print('each element is a {0} of size {1}'.format(type(masked_data_v3[0]), masked_data_v3[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we make another histogram of the masked (collapsed) data, we can see that we have a more interesting range of values left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(masked_data_v3.flatten(), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily go back and forth between the two formats, we need to have the mask and the 2D matrix to produce the 4D matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unmasked_data = np.zeros(data.shape)\n",
    "unmasked_data[:, mask] = masked_data_v3 \n",
    "\n",
    "print('unmasked_data is a {0} of size {1}'.format(type(unmasked_data), unmasked_data.shape))\n",
    "print('each element is a {0} of size {1}'.format(type(unmasked_data[0]), unmasked_data[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(unmasked_data.flatten(), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Time series\n",
    "\n",
    "Remember that one of these volumes is acquired at every time unit. The time unit here is 2.0045 seconds. Let's look at one slice at different time points. Now because masked_data_v3 only has cortical voxels, we can plot any of its dimension knowing that we are looking at gray matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masked_data_v3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout session: \n",
    "> Try to plot the activity in time for different voxels. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### TEACHER INFO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot four different voxels time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "TR = 2.0045\n",
    "n_points = 100\n",
    "points = range(0, n_points)\n",
    "time_points = np.array(points)*TR\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(time_points, masked_data_v3[:n_points, 4].T)\n",
    "plt.plot(time_points, masked_data_v3[:n_points, 10].T)\n",
    "plt.plot(time_points, masked_data_v3[:n_points, 100].T)\n",
    "plt.plot(time_points, masked_data_v3[:n_points, 1000].T)\n",
    "\n",
    "_ = plt.xlabel(\"Time (s)\")\n",
    "_ = plt.ylabel(\"fMRI activity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each voxels seems to have a different baseline! (You might have suspected this based on the image plots or the histogram plots above, too).\n",
    "\n",
    "Let's plot one slice at different time points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "z_slice = 10\n",
    "for s in range(15):\n",
    "    ax = fig.add_subplot(5, 5, s+1)\n",
    "    slice_horizontal = data[s, z_slice, :, :]\n",
    "    slice_horizontal[~mask[z_slice, : , :]] = 0\n",
    "    plt.imshow(slice_horizontal)\n",
    "    plt.title('TR #{n}'.format(n=s+1))\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "ax.imshow(masked_data_v3, aspect='auto')\n",
    "# Set the axis labels using the `setp` method.\n",
    "# http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.setp\n",
    "plt.setp(ax, xlabel='Voxels', ylabel='Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the activity at each voxel (zscore across time)\n",
    "\n",
    "You can see the same effect in the time plots as well as in the mosaic plots: some voxels have a different baseline than others. \n",
    "\n",
    "We need to normalize the activity of each voxel in time to be able to see local fluctuations in the signal. This normalization is also called *z-score* or *standard score*.\n",
    "\n",
    "1. We will first take the mean and standard deviation across time for each cortical voxel.\n",
    "2. For each voxel, we will substract the mean from each time point.\n",
    "3. For eacl voxel, we will divide each time point by the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(masked_data_v3.shape)\n",
    "data_norm = masked_data_v3 - masked_data_v3.mean(axis = 0)\n",
    "data_norm = data_norm / data_norm.std(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the time course:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Same random voxels\n",
    "plt.plot(time_points, data_norm[:n_points, 4].T)\n",
    "plt.plot(time_points, data_norm[:n_points, 10].T)\n",
    "plt.plot(time_points, data_norm[:n_points, 100].T)\n",
    "plt.plot(time_points, data_norm[:n_points, 1000].T)\n",
    "\n",
    "_ = plt.xlabel(\"Time (s)\")\n",
    "_ = plt.ylabel(\"fMRI activity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "ax.imshow(data_norm, aspect='auto') \n",
    "plt.setp(ax, xlabel='Voxels', ylabel='Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "And plot the volumes in time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_norm_unmasked = np.zeros_like(data)\n",
    "data_norm_unmasked[:,mask] = data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "for s in range(15):\n",
    "    ax = fig.add_subplot(5,5,s+1)\n",
    "    slice_horizontal = data_norm_unmasked[s,10,:,:]\n",
    "    slice_horizontal[~mask[10,:,:]] = 0\n",
    "    plt.imshow(slice_horizontal, vmin=-3, vmax=3) # don't forget vmin / vmax!\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
