{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "\n",
    "\n",
    "## Introduction to functional magnetic resonance imaging (fMRI)\n",
    "\n",
    "In this session, we will learn about fMRI data properties by loading, manipulating and visualizing it.\n",
    "\n",
    "# Goals for today\n",
    "\n",
    "We will go over some important concepts of data manipulation and visualization in fMRI, including: \n",
    "\n",
    "* Displaying a data (functional volumes) as an image (`plt.imshow()`)\n",
    "* Selecting an appropriate colormap for data visualization\n",
    "* Displaying a 3D array as a mosaic or contact sheet of images\n",
    "* Plotting timecourses of fMRI data\n",
    "* Masking / unmasking of fMRI data\n",
    "\n",
    "By the end, we will have written functions to:\n",
    "\n",
    "* Display a 3D array as a mosaic of images\n",
    "* Unmask an array\n",
    "* Normalize a timeseries\n",
    "\n",
    "## Short overview of fMRI \n",
    "\n",
    "Functional Magnetic Resonance Imaging, or fMRI, is a measure of brain activity over time. FMRI data is acquired using a special pulse sequence designed to measure changes in the magnetic properties of the blood flow using the Magnetic Resonance Imaging (MRI) scanner.\n",
    "\n",
    "<img src=\"/home/shared/cogneuro-connector/data/Week07_IntroFMRI_RawData/figures/mri_scanner.png\" style=\"height: 400px;\">\n",
    "\n",
    "The functional signal we measure with fMRI is *not* an electrical neural signal (as in EEG, ECoG, or electrophysiology). It is a magnetic signal related to the properties of brain tissue, and it is dominated by blood flow. Blood flow is related to neural activity, because firing neurons need oxygen. The process of firing involves letting electrically charged ions into a cell and actively pumping them back out again, which is metabolically demanding. So once a region of the brain becomes active (once the neurons start firing), metabolism in that region is high, oxygen gets stripped off of hemoglobin molecules in red blood cells in the area (thereby changing the magnetic properties of hemoglobin, creating a deoxyhemoglobin). This initiates a complex process to increase blood flow to the electrically active area. \n",
    "\n",
    "<img src=\"/home/shared/cogneuro-connector/data/Week07_IntroFMRI_RawData/figures/deoxyhemoglobin.png\" style=\"height: 400px;\">\n",
    "\n",
    "\n",
    "The specific mechanisms that lead from neural activity to changes in blood flow are (a) not well understood, and (b) beyond the scope of this class. For now, just know that there are several ways to measure functional responses with MRI, and the specific one that we work with is the Blood Oxygenation Level Dependent Response, or the BOLD response. \n",
    "\n",
    "### fMRI has high spatial but low temporal resolution\n",
    "\n",
    "We have belabored this here a little because this complexity should always be a source of humility for anyone working with fMRI or trying to interpret fMRI results. It is an **indirect, slow measure** - and these considerations strongly constrain the kinds of experiments you can do with fMRI and the conclusions you can draw from those experiments.\n",
    "\n",
    "An important practical upshot of this for our purposes is that the signal we measure changes much more slowly than the signal we measure in EEG or ECoG. Responses emerge over seconds, not milliseconds.\n",
    "\n",
    "<img src=\"/home/shared/cogneuro-connector/data/Week07_IntroFMRI_RawData/figures/imaging_modalities.png\" style=\"height: 400px;\">\n",
    "\n",
    "                                      Sejnowski et al., Nature Neurosci., 2014\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "One fMRI image (fMRI volume) is acquired for a given unit of time called a repetition time (TR). A TR is typically 1-2 seconds *(usually 1.0, 1.5, or 2.0 seconds)*. Every image records the activity in the brain at a given point in time. The following image shows a single volume of fMRI data (one two-second snapshot of brain activity).\n",
    "\n",
    "<img src=\"/home/shared/cogneuro-connector/data/Week07_IntroFMRI_RawData/figures/fig1.png\" style=\"height: 400px;\">\n",
    "\n",
    "The dimensions of the brain volume measured by fMRI can vary. Each individual fMRI measurement unit is called a *voxel*, which is short for volumetric pixel. The voxels in this data are about 2.4 x 2.4 x 4.0 mm (X x Y x Z) in size. \n",
    "\n",
    "### FMRI activity in time\n",
    "\n",
    "Once a neural event is triggered by a stimulus presentation the vascular system needs to respond to the need for glucose and oxygen in that specific brain area. This can take up to 1-2 seconds. Hence the hemodynamic response lags the triggered event by 1-2 seconds, which peaks around 5 seconds after the stimulus onset.\n",
    "\n",
    "<img src=\"/home/shared/cogneuro-connector/data/Week07_IntroFMRI_RawData/figures/lagged_activity.png\" style=\"height: 400px;\">\n",
    "\n",
    "### Example fMRI experiments \n",
    "\n",
    "#### Viewing natural images \n",
    "\n",
    "<img src=\"/home/shared/cogneuro-connector/data/Week07_IntroFMRI_RawData/figures/fmri_example_experiment.png\" style=\"height: 400px;\">\n",
    "\n",
    "#### Fusiform Face Area (FFA)\n",
    "\n",
    "<img src=\"/home/shared/cogneuro-connector/data/Week07_IntroFMRI_RawData/figures/ffa.png\" style=\"height: 400px;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### TEACHER INFO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FMRI as a *mapping* technique\n",
    "The scanning volume for the data we will use here consists of 30 transverse slices (i.e. Z is between 0 and 29). Transverse slices are horizontal, i.e., approximately parallel to the plane of the eyes and ears. Each slice corresponds to a 2D image of 100 x 100 voxels.\n",
    "\n",
    "We can measure fMRI responses across the whole brain. Therefore fMRI can be seen as a *mapping* technique. In order to make brain maps, we have to be able to match measured voxel responses to the participant's brain anatomy. Using a different type of MRI sequence, we can collect a **structural scan** (also called **anatomical scan**), and obtain a high resolution image of a participant's brain. Here is an example:\n",
    "\n",
    "<img src=\"/home/shared/cogneuro-connector/data/Week07_IntroFMRI_RawData/figures/MPRAGE_wcortex.png\">\n",
    "\n",
    "Most MRI measures activity in the cerebral cortex, or the outer layer of the brain. Using automated reconstruction software (and some manual editing), it's possible to build a 3D representation of the shape of the subject's cerebral cortex:\n",
    "\n",
    "<img src=\"/home/shared/cogneuro-connector/data/Week07_IntroFMRI_RawData/figures/cortex_3views.png\">\n",
    "\n",
    "\n",
    "In further lectures, we will learn how to overlay functional data onto the high resolution cortical representation for each individual the subject, so that we can make sense of the data.\n",
    "\n",
    "NOTE: pycortex demo.\n",
    "\n",
    "\n",
    "## Storing fMRI data for data analysis\n",
    "\n",
    "We store fMRI data as a matrix. This means that each volume (a timepoint) in the experiment will correspond to a row in the matrix, and each voxel will correspond to a column in that matrix. For this reason, we need to make sure the criteria we use to move each 3D image to a matrix row is preserved and this operation is inverted. Let's look at an example.\n",
    "\n",
    "<img src=\"/home/shared/cogneuro-connector/data/Week07_IntroFMRI_RawData/figures/fmri_dimensions.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fMRI data is stored in a variety of formats. The medical imaging community has a standardized image format called Digital Imaging and Communications in Medicine (DICOM) to handle and store raw medical imaging data. When data is collected using the MRI scanner each volume is stored in a DICOM file that contains both a header and the image data. The DICOM header stores useful information about the participant's name, pulse sequence, the type of scan, image dimensions, etc. (Another popular medical imaging format is the Analyze format, where the image and header file are stored separately.) You can read about these file formats [here](http://people.cas.sc.edu/rorden/dicom/index.html).\n",
    "\n",
    "Before we start analyzing the data we convert the raw DICOM files into the commonly used Neuroimaging Informatics Technology Initiative (nifti) file format. Files stored in this format usually have the extension .nii or .nii.gz. \n",
    "\n",
    "We will use the `nibabel` python module to load data that is stored such data formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nibabel\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt  # for visualization\n",
    "\n",
    "# Set defaults for matplotlib plotting in the notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we will load one run (also referred to as a scan) worth of fMRI data that was stored as a nifti file format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a nifti (nii) proxy object\n",
    "#fname = '../../data/fMRI/categories/sub01_categories1_1.nii.gz'\n",
    "fname = '/home/shared/cogneuro-connector/data/fmri/categories/sub01_categories1_1.nii.gz'\n",
    "nii = nibabel.load(fname) \n",
    "\n",
    "# This object stores the infomation *about* the fMRI data stored in the file. \n",
    "# This meta-data can be accessed via attributes of the `nii` object.\n",
    "print('nii.in_memory : ', nii.in_memory)\n",
    "print('nii.shape : ', nii.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieve actual data as an array\n",
    "data = nii.get_data()\n",
    "print('nii.in_memory : ', nii.in_memory)\n",
    "print('data shape : ', data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimensions of the data are (X, Y, Z, T) (T is time, in TRs). Thus, there are 120 volumes (120 time points). Each volume has 30 horizontal or transverse slices with 100 x 100 pixels.\n",
    "\n",
    "<img src=\"/home/shared/cogneuro-connector/data/Week07_IntroFMRI_RawData/figures/slices.png\" style=\"height: 200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transpose data\n",
    "\n",
    "When we work with functional images it is in general more convenient (for reasons like averaging over time, transfering data to a standard units, etc.) to have the data in T, Z, Y, X format. This is the opposite of the conventions you've seen so far for EEG / ECoG data. \n",
    "\n",
    "When we worked with EEG/ECoG data in the first half of the class, time was the *last* axis; here, time is the *first* axis. The reasons for this convention will become more obvious as we go, and we see how this convention makes for convenient syntax and shortcuts. \n",
    "\n",
    "Hence, we will use the `transpose` function  of the numpy package (or `.T` method of numpy arrays) to make this dimensional switch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transpose the data\n",
    "dataT = np.transpose(data)\n",
    "\n",
    "# Or, equivalently\n",
    "dataT_ = data.T\n",
    "\n",
    "print(\"dataT shape :\", dataT.shape)\n",
    "print(\"dataT_ shape : \", dataT_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### assert function\n",
    "You can check whether to variables are the same using the `assert` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = 2 \n",
    "b = 1\n",
    "assert a==b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also append an error message. This message will be printed if the two are not equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert a==b, 'these two are not equal!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout session: Explore the function transpose\n",
    "\n",
    "> Now test whether dataT and dataT_ are the same using assert\n",
    "\n",
    "> What does transpose do to a 2D array? To an array > 2D? How could you figure this out? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Are dataT and dataT_ the same?\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pause for exploration of transpose\n",
    "# First create some 2D array\n",
    "x = np.array([np.arange(5), np.arange(5)+10])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transpose the array\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check out the function \"flatten\"\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.arange(20)\n",
    "print(a)\n",
    "\n",
    "# Now reshape the array a into a 4x5 dimensional array\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data\n",
    "\n",
    "For fMRI, the functions we will use to explore the data are in general more basic than the functions we used in the first part of the class. We will not use a single module like MNE to make standard plots; we will construct our own!\n",
    "\n",
    "This is a little more work, but is very generalizable to other kinds of analyses, and if you get good at it you can make exactly the plot of your data that you want.\n",
    "\n",
    "One of the first questions about a data set (after its size) that you should explore is \n",
    "\n",
    "    \"What is the scale (min/max) of the data?\". \n",
    "\n",
    "Afterwards you may be interested to know its mean, standard deviation, and how in general the data looks like and make a histogram plot of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keep data transposed\n",
    "data = dataT\n",
    "\n",
    "del dataT, dataT_\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find out the scale of the data\n",
    "print(np.min(data), ', ', np.max(data)) \n",
    "\n",
    "# Find out its mean\n",
    "print(np.mean(data))\n",
    "\n",
    "# Find out its mean\n",
    "print(np.std(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a histogram of the data\n",
    "print(data.shape)\n",
    "print(data.flatten()[:10])\n",
    "_ = plt.hist(data.flatten(), bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout session:\n",
    "\n",
    "> - What does this tell you about the data? \n",
    "\n",
    "> - What are the axes on this plot? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the timecourse of a single voxel\n",
    "Now we can plot the timecourse for one voxel somewhere in the middle of the brain (e.g. at Z=10, Y=34, X=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = plt.plot(data[:, 10, 34, 34])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout session:\n",
    "> - Save all transverse slices for a sagittal and coronal axis (you can choose any number), in a variable called `transverse``\n",
    "\n",
    "> - Make a plot for all transverse slices (different voxels are plotted in the same figure). Label the axis. What does this plot tell us?\n",
    "\n",
    "> - Transpose the transverse variable and plot. Label the axis accordingly. What does this plot tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have 30,000 measurements to plot like this. So we *could* make a plot like the eeg representations that we had, but those were pretty busy even with 60 lines. So, instead, we will view our data as images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying data as an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will get a broader view of the first volume of our data. The (T, Z, Y, X) dimension ordering that we have for the data makes it easy to select volumes (time snapshots of brain activity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some ways to select volumes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can select one volume like this: \n",
    "first_volume = data[0, :, :, :]\n",
    "\n",
    "# Or like this: \n",
    "alt_first_volume1 = data[0, ...]\n",
    "\n",
    "# Or like this: \n",
    "alt_first_volume2 = data[0]\n",
    "\n",
    "# These are all the same1\n",
    "assert np.all(first_volume==alt_first_volume1)\n",
    "assert np.all(first_volume==alt_first_volume2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the horizontal slice\n",
    "Let's look at an example of a horizontal slice from the first volume. This can be done by selecting one of the slices as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Z=15 is halfway through the volume we have scanned\n",
    "slice_horizontal = first_volume[15,:,:]\n",
    "\n",
    "# You can set the image origin [0,0] to be in the upper left corner\n",
    "# by using origin='upper'\n",
    "plt.figure()\n",
    "im = plt.imshow(slice_horizontal, origin='upper') \n",
    "_ = plt.colorbar(im)\n",
    "\n",
    "# Alternative:\n",
    "plt.figure()\n",
    "im = plt.imshow(slice_horizontal[::-1]) \n",
    "_ = plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout session:\n",
    "> - Plot other slices to see how the shape of the brain is different\n",
    "> - Change the properties of the figure. Explore the keyword arguments for imshow, see what each does! (hints: show axes, change colormap, what about vmin and vmax values, set those)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to blog post about colormaps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TEACHER INFO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout session:\n",
    "> Write a small helper function that takes a slice number as an input returns the data (2D array) of that slice\n",
    "> Plot this image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout session: Visualizing sagittal and coronal views\n",
    "We can also slice the brain on different axis to obtain sagittal and coronal slices. \n",
    "\n",
    "> Try to plot these below. We have not told you which dimension corresponds to slicing the brain in a sagittal or coronal view. You should try the different axes and find it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select a sagittal slice and plot\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Select a coronal slice and plot\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing matplotlib default parameters\n",
    "\n",
    "You can set the default colormap, default interpolation or many other parameters in `matplotlib.rcParams`.\n",
    "\n",
    "For example to set all the colormaps in this `ipython` session to the colormap 'viridis' we can use the following line:\n",
    "    * `matplotlib.rcParams['image.cmap'] = 'viridis'` # or whatever your favorite map is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['image.cmap'] = 'viridis' # or whatever your favorite map is e.g. 'gray', 'hot'\n",
    "matplotlib.rcParams['image.interpolation'] = 'nearest'\n",
    "# matplotlib.rcParams['image.aspect'] = 'auto'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "An alternative way to change a figure's properties is to create a dictionary of keywords that can be used as a  keyword argument to the `imshow` function.\n",
    "\n",
    "This has the advantage of not setting the default parameters. Yet, we can easily change a number of parameters in the `imshow` function by just passing the keywords dictionary to the `imhsow` function. The following cell is demonstrating this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im_kws = dict(aspect='auto', vmin=0, vmax=2000, cmap='hot', interpolation='nearest') \n",
    "plt.imshow(first_volume[:,  30, :], **im_kws)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all horizontal slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to make a plot with all of the horizontal slices, so we can see one entire 3D volume at once. For this, we will use the `subplot()` function in matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "n_slices = 30\n",
    "nrows, ncols = 5, 6\n",
    "for s in range(n_slices):\n",
    "    ax = fig.add_subplot(nrows, ncols, s+1)\n",
    "    slice_horizontal = first_volume[s,:,:]\n",
    "    plt.imshow(slice_horizontal)\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a function that plots the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_horizontal_slices(vol, **kwargs):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    nslices = vol.shape[0]\n",
    "    subplot_size = np.ceil(np.sqrt(nslices))\n",
    "    for s in range(nslices):\n",
    "        ax = fig.add_subplot(subplot_size, subplot_size, s+1) \n",
    "        slice_horizontal = vol[s,:,:]\n",
    "        plt.imshow(slice_horizontal, **kwargs)\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout session:\n",
    "> Call the above function (plot_horizontal_slices), and try out different plotting arguments (e.g. change the colormap, change the interpolation, etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking\n",
    "\n",
    "You may have noticed in the figure above that many of the voxels do not overlap with the brain (or more specifically the gray matter in the cortex) at all. Actually, let's try to plot some of those voxels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(data[:,0,0,0], label='Edges of volume, 1')\n",
    "plt.plot(data[:,1,1,1], label='Edges of volume, 2')\n",
    "plt.plot(data[:,-1,-1,-1], label='Edges of volume, 3')\n",
    "\n",
    "# A middle brain voxel\n",
    "plt.plot(data[:,10,34,34], label='Mid brain')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The edge-of-scan voxels are clearly not in the brain, however, they show some variance due to noise. It is the practice in fMRI to mask out, or zero out these voxels.\n",
    "\n",
    "A mask is a 3D binary array that is derived from the high resolution anatomical scan of the subject. The mask indicates, for every voxel in the 30 x 100 x 100 matrix, which ones should be ignored and which should be kept. Let's load and look at a voxel mask for this subject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load a stored mask for this subject\n",
    "#fname = '../../data/fMRI/categories/s01_category_mask_cortical.npz'\n",
    "fname = '/home/shared/cogneuro-connector/data/fmri/categories/s01_category_mask_cortical.npz'\n",
    "mask = np.load(fname)['mask']\n",
    "print('Mask shape: ', mask.shape)\n",
    "print(mask[10,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot one fo the slices below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask_horizontal = mask[15,:,:]\n",
    "plt.imshow(mask_horizontal, origin='upper', cmap='gray')\n",
    "_ = plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the mask clearly indicates which voxels should be kept. \n",
    "\n",
    "### Breakout session: \n",
    "> Let's look at the 3D structure. Use the function we defined above to plot the entire 3D mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how now we have a mask that indicates which voxels we should keep and which we should exclude.\n",
    "\n",
    "We can use the mask to set the tiny values outside the brain, and the values in the middle of the brain (in subcortical stuctures) to zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's plot the horizonral slices for the first volume\n",
    "plot_horizontal_slices(first_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masked_vol_0 = first_volume * mask\n",
    "\n",
    "# Now plot masked_vol_0:\n",
    "plot_horizontal_slices(masked_vol_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the voxels outside the cortex (including in the middle of the brain) are zeroed out now! Let's apply this mask to the entire dataset now and zero out the same voxels in each volume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First create an array with zeros\n",
    "print(data.shape)\n",
    "masked_data = np.zeros_like(data)\n",
    "\n",
    "# NOTE: np.zeros_like is similar to creating an array using np.zeros. We can check this by:\n",
    "assert np.all(np.zeros(data.shape)==np.zeros_like(data)) \n",
    "\n",
    "# Not run through the entire data set and mask each volume\n",
    "for i in range(data.shape[0]):\n",
    "    masked_data[i,:,:,:] = data[i,:,:,:] * mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick example for list comprehension\n",
    "\n",
    "We can replace the above foor loop using list comprehension.\n",
    "\n",
    "In general, list comprehension can be used to tranform a list to another list. During this process in the new list elements of the old list can be modified. List comprehensions can be used to replace many lines of code to a more compact one line. Every list comprehension can be written as a for loop. The opposite is not necessarly true.\n",
    "\n",
    "We can basically use the same masking operation from the cell above and replace it by list comprehension. Let's see first how list comprehension works in a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.arange(5)\n",
    "print('Input list: {}'.format(x))\n",
    "\n",
    "# Let's create a for loop that squares each element in this list\n",
    "# Afterwards, do the same using list comprehension \n",
    "# Compare the resulting arrays\n",
    "\n",
    "### TEACHER INFO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use list comprehension to create the masked_data in a neat way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take individual volumes from data along the first dimension, and multiplies them by the mask\n",
    "masked_data_v1 = [d*mask for d in data]  \n",
    "print('masked_data_v1 is a {0} of size {1}'.format(type(masked_data_v1), len(masked_data_v1)))\n",
    "print('each element is a {0} of size {1}'.format(type(masked_data_v1[0]), masked_data_v1[0].shape))\n",
    "print('Type: {}, Shape: {}'.format(type(masked_data_v1), np.shape(masked_data_v1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to combine them into an array, this is done as follows, and results in a 4 dimensional array. This stacks the data such as the first dimension is the one that is defined by the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masked_data_v2 = np.array([d*mask for d in data])\n",
    "\n",
    "print('masked_data_v2 is a {0} of size {1}'.format(type(masked_data_v2), masked_data_v2.shape))\n",
    "print('each element is a {0} of size {1}'.format(type(masked_data_v2[0]), masked_data_v2[0].shape))\n",
    "print('Type: {}, Shape: {}'.format(type(masked_data_v2), np.shape(masked_data_v2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout session:\n",
    "\n",
    "> Now try plotting other volumes from masked_data_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logical indexing on the data array\n",
    "You can see that there are many voxels that do not contain interesting information. Instead of storing each volume as a 3D array, we can instead take only the voxels that are in the mask.\n",
    "\n",
    "We can use logical indexing to do this. Logical indexing can be used on any array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "idx = np.array([True, False, True, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(a[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# More examples: 2D\n",
    "a = np.arange(20).reshape(5,4)\n",
    "print(a)\n",
    "idx = np.array([False, True, False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(a[:, idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_volume = data[0]\n",
    "print('shape of first_volume is {}'.format(first_volume.shape))\n",
    "\n",
    "first_volume_masked = first_volume[mask==True]  # we can omit ==True, because mask is already a boolean array\n",
    "print('shape of first_volume_masked is {}'.format(first_volume_masked.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(first_volume_masked.flatten(), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compress the entire matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masked_data_v3 = data[:, mask]\n",
    "\n",
    "print('masked_data_v3 is a {0} of size {1}'.format(type(masked_data_v3), masked_data_v3.shape))\n",
    "print('each element is a {0} of size {1}'.format(type(masked_data_v3[0]), masked_data_v3[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we make another histogram of the masked (collapsed) data, we can see that we have a more interesting range of values left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(masked_data_v3.flatten(), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily go back and forth between the two formats, we need to have the mask and the 2D matrix to produce the 4D matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unmasked_data = np.zeros(data.shape)\n",
    "unmasked_data[:, mask] = masked_data_v3 \n",
    "\n",
    "print('unmasked_data is a {0} of size {1}'.format(type(unmasked_data), unmasked_data.shape))\n",
    "print('each element is a {0} of size {1}'.format(type(unmasked_data[0]), unmasked_data[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(unmasked_data.flatten(), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Time series\n",
    "\n",
    "Remember that one of these volumes is acquired at every time unit. The time unit here is 2.0045 seconds. Let's look at one slice at different time points. Now because masked_data_v3 only has cortical voxels, we can plot any of its dimension knowing that we are looking at gray matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masked_data_v3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout session: \n",
    "> Try to plot the activity in time for different voxels. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### TEACHER INFO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot four different voxels time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(time_points, masked_data_v3[:n_points, 4].T)\n",
    "plt.plot(time_points, masked_data_v3[:n_points, 10].T)\n",
    "plt.plot(time_points, masked_data_v3[:n_points, 100].T)\n",
    "plt.plot(time_points, masked_data_v3[:n_points, 1000].T)\n",
    "\n",
    "_ = plt.xlabel(\"Time (s)\")\n",
    "_ = plt.ylabel(\"fMRI activity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The voxels seem to have a different baseline! (You might have suspected this based on the image plots or the histogram plots above, too).\n",
    "\n",
    "Let's plot one slice at different time points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "z_slice = 10\n",
    "for s in range(15):\n",
    "    ax = fig.add_subplot(5, 5, s+1)\n",
    "    slice_horizontal = data[s, z_slice, :, :]\n",
    "    slice_horizontal[~mask[z_slice, : , :]] = 0\n",
    "    plt.imshow(slice_horizontal)\n",
    "    plt.title('TR #{n}'.format(n=s+1))\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "ax.imshow(masked_data_v3, aspect='auto')\n",
    "# Set the axis labels using the `setp` method.\n",
    "# http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.setp\n",
    "plt.setp(ax, xlabel='Voxels', ylabel='Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the activity at each voxel (zscore across time)\n",
    "\n",
    "You can see the same effect in the time plots as well as in the mosaic plots: some voxels have a different baseline than others. \n",
    "\n",
    "We need to normalize the activity of each voxel in time to be able to see local fluctuations in the signal. This normalization is also called *z-score* or *standard score*.\n",
    "\n",
    "1. We will first take the mean and standard deviation across time for each cortical voxel.\n",
    "2. For each voxel, we will substract the mean from each time point.\n",
    "3. For eacl voxel, we will divide each time point by the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(masked_data_v3.shape)\n",
    "data_norm = masked_data_v3 - masked_data_v3.mean(axis = 0)\n",
    "data_norm = data_norm / data_norm.std(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the time course:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "TR = 2.0045\n",
    "points = range(0,100)\n",
    "time_points = np.array(points)*TR\n",
    "\n",
    "plt.plot(time_points, data_norm[:n_points, 4].T)\n",
    "plt.plot(time_points, data_norm[:n_points, 10].T)\n",
    "plt.plot(time_points, data_norm[:n_points, 100].T)\n",
    "plt.plot(time_points, data_norm[:n_points, 1000].T)\n",
    "\n",
    "_ = plt.xlabel(\"Time (s)\")\n",
    "_ = plt.ylabel(\"fMRI activity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "ax.imshow(data_norm, aspect='auto') \n",
    "plt.setp(ax, xlabel='Voxels', ylabel='Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "And plot the volumes in time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_norm_unmasked = np.zeros_like(data)\n",
    "data_norm_unmasked[:,mask] = data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "for s in range(15):\n",
    "    ax = fig.add_subplot(5,5,s+1)\n",
    "    slice_horizontal = data_norm_unmasked[s,10,:,:]\n",
    "    slice_horizontal[~mask[10,:,:]] = 0\n",
    "    plt.imshow(slice_horizontal, vmin=-3, vmax=3) # don't forget vmin / vmax!\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
