{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first part of the exam, you will answer general questions about fMRI analysis. \n",
    "\n",
    "# Part 1 - General questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Imports (4 points)\n",
    "All semester long, we have been importing many of the same packages. Here, on the line of each import, add a comment that describes what that specific tool is for. Limit your comments/descriptions to one line each, and do NOT let them run off the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os # ? [add description here!]\n",
    "import cortex # ? [add description here!]\n",
    "import neurods # ? [add description here!]\n",
    "# NOTE: this next is imported separately because of a quirk in the way we wrote neurods. \n",
    "import neurods.stats # [no answer needed here]\n",
    "import numpy as np # ? [add description here!]\n",
    "import matplotlib.pyplot as plt # ? [add description here!]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Just finish setting up)\n",
    "Don't forget to actually run the cell above, too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure defaults for plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.aspect'] = 'auto'\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Masks (6 points total)\n",
    "\n",
    "#### 1.2a Cortical masks (3 points total)\n",
    "In fMRI analysis, it is common to use *masks* to select particular sets of voxels in the brain. Most often in class, we have used masks to select *cortical* voxels, using a mask generated by pycortex called `'cortical'`. There are other options for how we might select voxels in or around the cortex. Here, we will explore two other masks in addition to the `'cortical'` mask.\n",
    "\n",
    "We will load and visualize three different masks for the subject we will analyze in the experiment below. Load each of these masks using pycortex. \n",
    "\n",
    "For all three masks, the subject will be 's02', and the experiment/transform will be 'reading'. The names of the masks will be `'cortical'`, `'thin'`, and `'thick'`. (`'thin'` and `'thick'` are loaded in the same way as the `'cortical'` mask.) \n",
    "\n",
    "* Visualize each of these masks in 2D slices using the appropriate function in neurods. (2 points)\n",
    "* Why would you use the 'thin' mask instead of the 'cortical' mask? Why would you use the 'thick' mask?  (1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define subject and functional-to-anatomical transform for this experiment\n",
    "sub = 's02'\n",
    "xfm = 'reading' \n",
    "# Load masks\n",
    "#mask_cortical = # ?\n",
    "#mask_thin = # ? \n",
    "#mask_thick = # ? \n",
    "\n",
    "# Visualize masks \n",
    "# ??\n",
    "\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why would you use the thin / thick mask instead of the cortical mask? \n",
    "\n",
    "`### STUDENT ANSWER`\n",
    "\n",
    "[type answer in this cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2b ROI masks (3 points)\n",
    "A common practice in fMRI is to use a mask to select voxels in a particular region of interest (an area smaller than the whole cortex). Load the following mask, and answer the following questions about it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download mask\n",
    "if not os.path.exists('mni_mask_final.npz'):\n",
    "    neurods.io.download_file('https://drive.google.com/file/d/0B_iniuUpMJoGTkx4Y0NTUHgzTUk', \n",
    "                            'mni_mask_final.npz',\n",
    "                            root_destination='./')\n",
    "roi_mask = np.load('mni_mask_final.npz')['mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mask is in the space of the MNI brain (the average template brain that we used in lectures 11 and 12). Thus, for pycortex purposes, the subject is `'MNI'` and the transform is `'atlas336'`. \n",
    "\n",
    "* How many voxels are in this mask? (1 point)\n",
    "* Visualize this mask on the surface of the MNI brain. (1 point)\n",
    "* Where is this mask located? (Please describe the location in appropriate neuroscientific terms!) (1 point)\n",
    "\n",
    "[hint: for the last part, if you have trouble visualizing where the mask is in 3D based on a cortical flatmap, you can use pycortex to show this mask in a a different way]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 HRF (4 points)\n",
    "\n",
    "Please explain in a few sentences: \n",
    "\n",
    "* What does HRF stand for? (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`### STUDENT ANSWER`\n",
    "\n",
    "[type answer in this cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Describe the shape of the HRF. Use words, but be quantitative. (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`### STUDENT ANSWER`\n",
    "\n",
    "[type answer in this cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How is the HRF generally used in fMRI analysis? (1 point)\n",
    "\n",
    "(Avoid technical terms if you can - explain this to a non-specialist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`### STUDENT ANSWER`\n",
    "\n",
    "[type answer in this cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Name one way in which the HRF constrains the kinds of experiments that can be done using fMRI. (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`### STUDENT ANSWER`\n",
    "\n",
    "[type answer in this cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Bootstrapping (6 points)\n",
    "\n",
    "Please explain in few sentences:\n",
    "\n",
    "* What is the purpose of a bootstrap analysis? (For example, why would you compute a bootstrap estimate of a regression weight?) (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`### STUDENT ANSWER`\n",
    "\n",
    "[type answer in this cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How would you compute a bootstrap estimate of a difference between two regression weights? (explain in words [no code!])  (1.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`### STUDENT ANSWER`\n",
    "\n",
    "[type answer in this cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How would you compute a bootstrap estimate of model prediction accuracy? (explain in words [no code!]) (1.5 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`### STUDENT ANSWER`\n",
    "\n",
    "[type answer in this cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bootstrap estimates of a statistical quantity result in a distribution of values for that quantity. How can such distributions be used draw a conclusion about the reliability or accuracy of fMRI results? (please give a specific example of a quantity and a conclusion that could be drawn given a hypothetical outcome of a bootstrap analysis) (1 point)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`### STUDENT ANSWER`\n",
    "\n",
    "[type answer in this cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For the second part of the exam, you will analyze the following experiment. \n",
    "\n",
    "# Part 2 - Naturalistic reading experiment\n",
    "\n",
    "In this experiment, subjects read multiple stories in the scanner. The stories were presented one word at a time, with the words appearing at the rate of natural speech. Each word was presented at the center of the screen by itself, for a few hundred milliseconds. So in every TR, subjects read about 4 to 15 words. \n",
    "\n",
    "For these words, one can extract multiple features. For example, some of the features can relate to the semantic properties of the words shown. We will not deal with such features today. We will look at only one type of features for these words: The letters that compose the words. Our feature space is a 26 dimensional space in which each dimension corresponds to a letter in the alphabet. At every TR, we count how many times each letter occured. \n",
    "\n",
    "For example, if during one TR the subject reads:\n",
    "\n",
    "\"it \n",
    "\n",
    "was \n",
    "\n",
    "the \n",
    "\n",
    "first \n",
    "\n",
    "time \n",
    "\n",
    "I \n",
    "\n",
    "saw\n",
    "\n",
    "something\n",
    "\n",
    "so\"\n",
    "\n",
    "...then, for that TR, the feature channel corresponding to the letter \"s\" will have a count of 5, the feature corresponding to \"t\" will have 5, the feature corresponding to \"a\" will have 2, the feature corresponding to \"e\" will have 3, etc. E.g.:\n",
    "\n",
    "| a        |    ...       | e  | ...      | s          | t  | ... | z|\n",
    "| ------------- |:-------------:| -----:|:-------------:| -----:|:-------------:|:-------------:| ---|\n",
    "| 2     |  ... | 3 | ...  |5 | 5 | ...| 0|\n",
    "\n",
    "\n",
    "We would like to learn a model that predicts the activity in the brain as a function of the letters that are read by the subject. Letters are used across words of all meanings, so you can see how this letter model captures low level properties rather than high level meaning. Thus it may be a good model for brain mechanisms related to processing letters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Loading data (3 points)\n",
    "\n",
    "* Load the 'thin' mask for subject 2 (1 point)\n",
    "* Load the data, zscore, and mask it using the relevant function(s) in `neurods`. Load the first two runs of the experiment (`\"s02_reading_03.nii.gz\"` and `\"s02_reading_03.nii.gz\"`) into a variable called `Y_train`. (`Y_train` should be a single array of the two data sets concatenated in the time dimension). Load the last run of the experiment (`\"s02_reading_03.nii.gz\"`) into a variable called `Y_test`. These two variables will serve as training and testing data for our model. (1 point)\n",
    "* Create the experiment design matrix (here, a feature space that quantifies the letters being read by the subject). You will create one design matrix for the training data (`X_train`) and one for the testing data (`X_train`). The `design` variable loaded below contains separate design matrices for each run; your job is to split up/concatenate these matrices so that `X_train` and `X_test` match with `Y_train` and `Y_test`. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define experiment directory\n",
    "basedir = os.path.join(neurods.io.data_list['fmri'],'reading')\n",
    "\n",
    "# Get 'thin' mask for s02\n",
    "sub, xfm = 's02', 'reading'\n",
    "# mask = # ?\n",
    "\n",
    "# Load fMRI data\n",
    "nruns = 2\n",
    "fmri_files_train = ['s02_reading_{:02d}.nii.gz'.format(run) for run in range(nruns)]\n",
    "fmri_files_train = [os.path.join(basedir, f) for f in fmri_files_train]\n",
    "fmri_files_test = os.path.join(basedir, 's02_reading_03.nii.gz')\n",
    "#Y_train = # ?\n",
    "#Y_test = # ? \n",
    "\n",
    "# Load the design matrix (the letter model feature space, your X variable)\n",
    "design = np.load(os.path.join(basedir, 'features.npz'))\n",
    "#X_train = # ?\n",
    "#X_test = # ?\n",
    "\n",
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you can't figure out how to load the data above, restart your kernel, re-run the import cells above, and then run the following cell so that you can still continue with the exam. Obviously, this also provides a way to check whether your answer above is in the correct form - your answer to part 2.1 will be graded on the correctness of how you loaded the data. \n",
    "\n",
    "Also: ***fair warning!*** If you try to load *BOTH* the variables in the next cell *and* your own version of the same variables, you may run into memory limits (here or maybe in subsequent steps). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load correct versions of variables\n",
    "if False: # Switch this line to True if necessary\n",
    "    if not os.path.exists('exp_data_file.npz'):\n",
    "        neurods.io.download_file('https://drive.google.com/file/d/0B_iniuUpMJoGam9vNGFyR21IbE0', \n",
    "                                 'exp_data_file.npz', \n",
    "                                 root_destination='./')\n",
    "    tmp = np.load('exp_data_file.npz')\n",
    "    X_train = tmp['X_train']\n",
    "    X_test = tmp['X_test']\n",
    "    Y_train = tmp['Y_train']\n",
    "    Y_test = tmp['Y_test']\n",
    "    del tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing X_train and X_test (3 points)\n",
    "\n",
    "- Print the shape of the **`X_train`** and **`X_test`** arrays\n",
    "- Use `plt.imshow` to show both matrices (Make sure you make it clear which is which in the plots!)\n",
    "- Label the columns (`plt.xlabel`) and rows (`plt.ylabel`) of the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize design matrices\n",
    "\n",
    "Run the following cells to normalize the feature matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "X_train = zscore(X_train, axis=0)\n",
    "X_test = zscore(X_test, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Y_train and Y_test (2 points)\n",
    "\n",
    "- print the shape of the Y_train and Y_test function\n",
    "- DO **NOT** USE imshow here because you might run into memory issues.\n",
    "- what does the column and row of each of Y_train and Y_test correspond to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Convolution of the design matrix with the HRF (4 points)\n",
    "\n",
    "The TR here is 2 seconds. \n",
    "\n",
    "- Use the function in the package `neurods` to generate an appropriate hrf for this experiment. (1 point)\n",
    "- Plot the hrf. Label the axes in the plot! (1 point)\n",
    "- Use the np.convolve function to obtain conv_X_train. (Remember to trim the matrix properly). (1 point)\n",
    "- Use plt.imshow to plot conv_X_train. Label the axes in the plot! (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Estimating brain responses to features in each voxel (3 points)\n",
    "\n",
    "Here, we will use linear regression to estimate the brain response to each feature in each voxel. \n",
    "\n",
    "- Use the OLS function estimate regression weights for all voxels. (1 point)\n",
    "- Print the shape of the weight matrix. (1 point)\n",
    "- What do the rows and columns of the weight matrix correspond to? (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.4 Predicting training data (3 points)\n",
    "\n",
    "We will first predict the training data, and see how well the predicted data correlates with the real data.\n",
    "\n",
    "- compute Y_train_hat using the weights matrix and conv_X_train. (1 point) \n",
    "- use neurods.stats.compute_correlations below to compute the correlation of Y_train_hat and Y_train (1 point)\n",
    "- make a flatmap of the correlation value over the brain. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.5 Predicting test data (4 points)\n",
    "\n",
    "We will first predict the held out data, and see how well the predicted data correlates with the real held out data.\n",
    "\n",
    "- ATTENTION: you cannot use the matrix X_test to compute Y_test_hat. Remember, the weights you estimated are a function of the convolved design matrix. You need to use the hrf function above and np.convolve to obtain conv_X_test. And you need to trim it appropriately. (1 point)\n",
    "- compute Y_test_hat using the weights matrix and conv_X_test. (1 point)\n",
    "- use `neurods.stats.compute_correlations` below to compute the correlation of `Y_test_hat` and `Y_test` (1 point)\n",
    "- make a flatmap of the correlation value over the brain. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6a Interpretation (3 points)\n",
    "\n",
    "- Which regions appear to be predicted by letters the subject sees on the screen? (Use neuroscientifically appropriate terms!) Does that make sense? (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`### STUDENT ANSWER`\n",
    "\n",
    "[type answer in this cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6b Visualizations to aid interpretation (3 points)\n",
    "* Make a histogram of the predictions of the training set data. (Label axes!) (1 point)\n",
    "* Make a histogram of the predictions of the test set data. (Label axes!) (1 point)\n",
    "* Make a scatter plot of training set prediction accuracy vs test set prediction accuracy (each dot will be one voxel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Big picture interpretation  (2 points)\n",
    "What is the difference between predicting the training data and predicting the testing data?\n",
    "(How do the predictions differ? Why do you think that is the case?) (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`### STUDENT ANSWER`\n",
    "\n",
    "[type answer in this cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Extra credit  \n",
    "---\n",
    "Pick and choose among these questions (or answer them all) - there is a maximum of 5 points of extra credit possible. (that is, you will only get 5 points of extra credit even if you answer all of the questions perfectly.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe another feature space you might construct to model brain responses in this experiment! (2 points)\n",
    "For this question, assume you have access to the full list of words that the subject read at each point in time. Describe (1) what the hypothesis is, (2) how you would go about making the feature space (what would you label / compute about the words for each TR?), and (3) what you might expect to find / why this would be an interesting hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`### STUDENT ANSWER`\n",
    "\n",
    "[type answer in this cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a close look at the experimental design (2 points)\n",
    "In which run were the most total letters read by the subject? In which experiment were there the most letters per TR? (note that the runs were not all the same length!) (1 points)\n",
    "\n",
    "How might this information matter / influence on the interpretation of the experiment? (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a mask (a 3D array) that selects the 400 best-predicted voxels in the brain.  (2 points)\n",
    "\n",
    "Do this for the best-predicted voxels in the training set and in the test set.\n",
    "\n",
    "Make a flatmap for each of the masks to compare them.\n",
    "\n",
    "Are they the same voxels? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation (3 points)\n",
    "\n",
    "In the main part of the exam we trained on 2 runs of data and predicted a held-out test set. Instead, here, we want to use cross-validation to measure the performance on the training data only. \n",
    "\n",
    "* Implement cross-validation:\n",
    " - For each fold, hold out one-fourth of the total training data. \n",
    " - Use the remaining 3/4 of the data to compute the weights for the letter model.\n",
    " - Compute the correlation between the predicted activity for the held-out run and the real activity.\n",
    "* Compute the average correlation across all held-out folds and plot it on a flatmap.\n",
    "\n",
    "* Does this method produce the same results as what we did in 3.4? i.e. is it the same as fitting the model on the entire training data and then predicting the training data? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "timetravel": {
   "allowedContentTypes": [
    "text/plain"
   ],
   "enabled": false,
   "version": "1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
