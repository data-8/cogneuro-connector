{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview \n",
    "\n",
    "Today's class will have two parts: \n",
    "\n",
    "First, we will review the homework, and describe ways to limit the amount of memory used in loading large data sets. \n",
    "\n",
    "Second, we will describe the structure of the experiment that produced the data we have been analyzing, and we will compute averages of activity around the time of specific experimental events. \n",
    "\n",
    "\n",
    "# Goals\n",
    "* Understand ways to reduce the amount of memory used when loading data\n",
    "* Understand *masking* data with logical indices\n",
    "* Estimate the average response to an experimental event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating resources in your server home directory\n",
    "(Run the cells in this section once, then restart your kernel, reload the web page, and skip this section the next time through!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Updating functions\n",
    "import neurods\n",
    "# Update neurods package\n",
    "neurods.io.update_neurods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory management and masking\n",
    "A big difficulty in last week's homework - and in data science in general - is how to deal with large data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load some necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel\n",
    "import neurods\n",
    "import cortex\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set plotting defaults\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set matplotlib defaults!\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.origin'] = 'lower'\n",
    "plt.rcParams['image.aspect'] = 'equal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python digression: Floating point vs integer numbers\n",
    "\n",
    "`numpy` stores numbers in several different formats: numbers can be stored as boolean values (True or False); as integers (0, 1, 2...) or as floating-point numbers (2.3256..., 3.63212..., etc). This is a common aspect of all programming languages that deal with images or numbers. Different formats for numbers use different amounts of memory. For data types that allow decimals (e.g. numpy's float32 and float64), the more decimal places that are stored for each number in an array, the more memory the array takes up. \n",
    "\n",
    "Thus, converting to a less-precise format (np.float32) can save memory, if precision is not critically important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.float64(np.pi))\n",
    "print(np.float32(np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r64 = np.random.rand(30,100,100)\n",
    "r32 = r64.astype(np.float32)\n",
    "print('data type of `r64` is: ', r64.dtype)\n",
    "print('data type of `r32` is: ', r32.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW Recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# An OK implementation of load_data:\n",
    "from scipy.stats import zscore\n",
    "def load_data_ok(files, do_zscore=False):\n",
    "    \"\"\"Load fMRI data from files and optionally z-normalize data\"\"\"\n",
    "    # Create a list to store data\n",
    "    data = None\n",
    "    for f in files:\n",
    "        nii = nibabel.load(f)\n",
    "        if data is None:\n",
    "            data = nii.get_data().T\n",
    "            if do_zscore:\n",
    "                data = zscore(data, axis=0)\n",
    "        else:\n",
    "            tmp = nii.get_data().T\n",
    "            if do_zscore:\n",
    "                tmp = zscore(tmp, axis=0)            \n",
    "            data = np.vstack([data, tmp])\n",
    "    return data\n",
    "\n",
    "# A better implementation\n",
    "def load_data_better(files, do_zscore=False):\n",
    "    \"\"\"Load fMRI data from files and optionally z-normalize data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list \n",
    "        List of file names (absolute paths)\n",
    "    do_zscore : bool\n",
    "        Flag that determines whether to zscore data in time or not\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data : array\n",
    "        fMRI data array, in (time, z, y, x) format\n",
    "    \"\"\"\n",
    "    # Create a list to store data\n",
    "    data = []\n",
    "    # Loop over files in list\n",
    "    for f in files:\n",
    "        nii = nibabel.load(f)\n",
    "        tmp = nii.get_data().T\n",
    "        # Optionally zscore each run independently\n",
    "        if do_zscore:\n",
    "            data = zscore(data, axis=0)\n",
    "        data.append(tmp)\n",
    "    # Concatenate full data\n",
    "    data = np.vstack(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls /Users/mark/Dropbox/data8/fMRI/motor/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOVE ME\n",
    "\n",
    "\n",
    "Consequently, it is common to display the results of statistical analyses of fMRI data on inflated and flattened representations of the cerebral cortex. Such cortical surface maps provide a way to examine all cortical fMRI data at once, with the anatomical location of the functional data made clear. \n",
    "\n",
    "The cortical surface must be computationally extracted from high spatial resolution anatomical MRI scans, and often manually edited (*NOTE: Manual editing to create a good corical surface can take days or weeks of effort! This data is not free!*)\n",
    "\n",
    "<img src=\"figures/MPRAGE.png\" align='left' style=\"height: 200px;\">\n",
    "\n",
    "<img src=\"figures/MPRAGE_wcortex.png\" align='left' style=\"height: 200px;\">\n",
    "\n",
    "<img src=\"figures/cortex_3views.png\" align='left' style=\"height: 200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Masking\n",
    "\n",
    "As we have discussed, not all of the data in our 4D array is equally interesting to us. We are interested in the fMRI data collected IN the brain (vs outside it), and more specifically in the data collected from the cerebral cortex (the outermost layer of the brain). \n",
    "\n",
    "Here, we will show you how to extract (a) the data in the brain, and (b) the data in the cerebral cortex from the whole array. \n",
    "\n",
    "Remember our histogram of values for data, which show a ton of voxels with zero values (from outside the brain):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specify files\n",
    "files = ['s01_categories_{:02d}.nii.gz'.format(r) for r in [1, 2, 3]]\n",
    "files = [os.path.join(neurods.io.data_list['fmri'], 'categories', f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data for only one file\n",
    "data = load_data(files[0], do_zscore=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(0,2000,31)\n",
    "_ = plt.hist(data.flatten(), bins)\n",
    "plt.xlabel('Raw fMRI Activity')\n",
    "plt.ylabel('TRs (count)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So: how can we extract the data that is only from the region of the scan that contains the brain? We could try to write down an index for each data point in the data that contains a brain voxel (e.g. [25, 33, 33], [25, 33, 34]), but you can see how such a list would get quite long (tens of thousands) and would be difficult to construct. \n",
    "\n",
    "One simple way to find data that is in or near the brain is to threshold the data to find only the voxels where the signal is greater than zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here, consider only the first volume\n",
    "brain_voxels = data[0] > 0\n",
    "print(brain_voxels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What is this thing we have just created?\n",
    "print('dtype of `brain_voxels`: ', brain_voxels.dtype)\n",
    "print('Sum of of `brain_voxels`: ', brain_voxels.sum())\n",
    "print('Mean of of `brain_voxels`: ', brain_voxels.mean())\n",
    "print('Shape of `brain_voxels`: ', brain_voxels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout session\n",
    "1. Discuss what each of the values above indicate about the `brain_voxels` array.\n",
    "2. What happens if you change the cell above to be brain_voxels = data[0] > X, where X is greater than zero? (What should the threshold [X] for selecting brain voxels be?)\n",
    "3. While playing with the threshold value, display the `brain_voxels` variable in some sensible way. What does the array LOOK like for different thresholds (values of X)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an array of True/False values (a boolean array). This array can be directly used to INDEX our data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Logical indices are fun!\n",
    "a = np.arange(10)\n",
    "idx = np.array([True, False, True, False, True, False, True, False, True, False])\n",
    "a[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This works in multiple dimensions, too!\n",
    "a = np.arange(20).reshape(2,10)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(a[:,idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# or even for brain data!\n",
    "brain_data = data[:, brain_voxels]\n",
    "print(brain_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BREAKOUT SESSION\n",
    "Make a histogram of `brain_data`. Z-score it, and plot it as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Student answer\n",
    "plt.hist(brain_data.flatten(), bins)\n",
    "plt.xlabel('Raw BOLD response')\n",
    "plt.ylabel('TRs (count)')\n",
    "plt.figure()\n",
    "plt.imshow(zscore(brain_data, axis=0), aspect='auto')\n",
    "plt.xlabel(\"Voxels\")\n",
    "plt.ylabel(\"Time (TRs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Undo masking action?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking with pycortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just like specifying a volume, pycortex needs a subject and a transform to retrieve a mask\n",
    "# for a particular data set.\n",
    "cortical_voxels = cortex.db.get_mask('s01', 'catloc', type='cortical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display the same information as the brain mask above\n",
    "print(cortical_voxels.dtype)\n",
    "print(cortical_voxels.shape)\n",
    "print(cortical_voxels.sum())\n",
    "print(cortical_voxels.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot \n",
    "fig1 = plt.figure(figsize=(6,5))\n",
    "_ = neurods.viz.slice_3d_array(cortical_voxels, axis=0, fig=fig1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### TEACHER INFO\n",
    "fig2 = plt.figure(figsize=(10,3))\n",
    "_ = neurods.viz.slice_3d_array(cortical_voxels, axis=1, fig=fig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cortical_data = data[:, cortical_voxels]\n",
    "print(cortical_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load description of experiment \n",
    "The experiment we have been working with is a *localizer* experiment. It is designed to find areas of the brain that respond to particular visual categories of objects: faces, bodies, and places. It also reveals areas that respond more to objects than to scrambled versions of the same objects. This experiment is a simple replication of past work, and is commonly done as a first step to locate (or localize) a region of interest for further analysis in a subsequent experiment.\n",
    "\n",
    "For the localizer experiment, images from each category were presented in a block design. This means that images from the one category were shown one after another for a \"block\" of 20 seconds (10 TRs), followed by images from another category for a block of 20 seconds, and so on.\n",
    "\n",
    "<img src=\"figures/CategoryLocalizerDesign.001.png\" style=\"height: 400px;\">\n",
    "\n",
    "To analyze the data from this experiment at all, we need to know when the blocks for each category (faces, bodies, places, objects, and scrambled objects) began and ended. This information is stored in a *design matrix*, which we load below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import neurods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basedir = os.path.join(neurods.io.data_list['fmri'], 'categories')\n",
    "design = np.load(os.path.join(basedir, 'experiment_design.npz'))\n",
    "print('Experiment design variables: ', sorted(design.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conditions = design['conditions'].tolist()\n",
    "print('Conditions: ', conditions)\n",
    "design_run1 = design['run1']\n",
    "print('Design shape: ', design_run1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's often useful to show a design matrix as an image:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = plt.imshow(design_run1.T, aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout session\n",
    "> What are the dimensions here? Label the axes on the figure above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event-related averages\n",
    "In an experiment, we are always interested in the relationship between the stimulus and brain responses. The simplest way to visualize the relationship is to examine what happened to brain responses every time that a stimulus came on. Thus, we will now create *averages* of responses after a particular type of stimulus came on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, use np.nonzero to find condition onsets for the first condition\n",
    "_, on_times = np.nonzero([design_run1[:,0]])\n",
    "print(on_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout session\n",
    "> Convert `on_times` to onsets! (i.e., the specific time that the stimulus came on)\n",
    "\n",
    "> Select 10 time points after each time the stimulus came on, and save them in a list\n",
    "\n",
    "> Average each set of points together! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a movie of the temporal average in pycortex!\n",
    "sub, xfm = 's01', 'catloc'\n",
    "cond1_vol = cortex.Volume(data_avg_cond1, sub, xfm, vmin=-3, vmax=3, cmap='RdBu_r')\n",
    "cx.webgl.show(cond1_vol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
