{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview \n",
    "\n",
    "Today's class will have two parts: \n",
    "\n",
    "First, we will review the homework, and describe ways to limit the amount of memory used in loading large data sets. \n",
    "\n",
    "Second, we will describe the structure of the experiment that produced the data we have been analyzing, and we will compute averages of activity around the time of specific experimental events. \n",
    "\n",
    "\n",
    "# Goals\n",
    "* Understand ways to reduce the amount of memory used when loading data\n",
    "* Understand *masking* data with logical indices\n",
    "* Estimate the average response to an experimental event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating resources in your server home directory\n",
    "(Run the cells in this section once, then restart your kernel, reload the web page, and skip this section the next time through!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False: # You should not need to run this again if you ran it in class; if you were not in class, set this to True\n",
    "    # Updating functions\n",
    "    import neurods\n",
    "    # Update neurods package\n",
    "    neurods.io.update_neurods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cp ../Lecture04_Normalization_Masking_pycortex/figures ./ # uncomment this to run this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE! Added in breakout notebook:** Run this to get the other image into the notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import neurods\n",
    "if not os.path.exists('figures/CategoryLocalizerDesign.001.png'):\n",
    "    url = 'https://www.dropbox.com/s/sk9rbqdgyu6wf33/CategoryLocalizerDesign.001.png'\n",
    "    fpath = 'figures/'\n",
    "    neurods.io.download_file(url, 'CategoryLocalizerDesign.001.png', root_destination=fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory management and masking\n",
    "A big difficulty in last week's homework - and in data science in general - is how to deal with large data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load some necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel\n",
    "import neurods\n",
    "import cortex\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set plotting defaults\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set matplotlib defaults!\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.origin'] = 'lower'\n",
    "plt.rcParams['image.aspect'] = 'equal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python digression: Floating point vs integer numbers\n",
    "\n",
    "`numpy` stores numbers in several different formats: numbers can be stored as boolean values (True or False); as integers (0, 1, 2...) or as floating-point numbers (2.3256..., 3.63212..., etc). This is a common aspect of all programming languages that deal with images or numbers. Different formats for numbers use different amounts of memory. For data types that allow decimals (e.g. numpy's float32 and float64), the more decimal places that are stored for each number in an array, the more memory the array takes up. \n",
    "\n",
    "Thus, converting to a less-precise format (np.float32) can save memory, if precision is not critically important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.float64(np.pi))\n",
    "print(np.float32(np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r64 = np.random.rand(30,100,100)\n",
    "r32 = r64.astype(np.float32)\n",
    "print('data type of `r64` is: ', r64.dtype)\n",
    "print('data type of `r32` is: ', r32.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW Recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# An OK implementation of load_data:\n",
    "from scipy.stats import zscore\n",
    "def load_data_ok(files, do_zscore=False):\n",
    "    \"\"\"Load fMRI data from files and optionally z-normalize data\"\"\"\n",
    "    # Create a list to store data\n",
    "    data = None\n",
    "    for f in files:\n",
    "        nii = nibabel.load(f)\n",
    "        if data is None:\n",
    "            data = nii.get_data().T\n",
    "            if do_zscore:\n",
    "                data = zscore(data, axis=0)\n",
    "        else:\n",
    "            tmp = nii.get_data().T\n",
    "            if do_zscore:\n",
    "                tmp = zscore(tmp, axis=0)            \n",
    "            data = np.vstack([data, tmp])\n",
    "    return data\n",
    "\n",
    "# A better implementation\n",
    "def load_data_better(files, do_zscore=False):\n",
    "    \"\"\"Load fMRI data from files and optionally z-normalize data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list \n",
    "        List of file names (absolute paths)\n",
    "    do_zscore : bool\n",
    "        Flag that determines whether to zscore data in time or not\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data : array\n",
    "        fMRI data array, in (time, z, y, x) format\n",
    "    \"\"\"\n",
    "    # Create a list to store data\n",
    "    data = []\n",
    "    # Loop over files in list\n",
    "    for f in files:\n",
    "        nii = nibabel.load(f)\n",
    "        tmp = nii.get_data().T\n",
    "        # Optionally zscore each run independently\n",
    "        if do_zscore:\n",
    "            data = zscore(data, axis=0)\n",
    "        data.append(tmp)\n",
    "    # Concatenate full data\n",
    "    data = np.vstack(data)\n",
    "    return data\n",
    "\n",
    "# The implementation we will use for this notebook\n",
    "def load_data(*files, do_zscore=False, mask=None, dtype=np.float32):\n",
    "    \"\"\"Load fMRI data from files and optionally z-normalize data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    files : strings \n",
    "        Absolute path names for files to be loaded\n",
    "    do_zscore : bool\n",
    "        Flag that determines whether to zscore data in time or not\n",
    "    mask : boolean array\n",
    "        Selection mask that specifies which voxels to extract from 3D brain\n",
    "    dtype : numpy data type\n",
    "        Data type to which to convert the loaded data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : array\n",
    "        fMRI data array, in (time, z, y, x) format (if not masked) or in\n",
    "        (time, voxels) format (if masked)\n",
    "    \"\"\"\n",
    "    # Create a list to store data\n",
    "    data = []\n",
    "    # Loop over files in list\n",
    "    for f in files:\n",
    "        print(\"Loading {}...\".format(f))\n",
    "        nii = nibabel.load(f)\n",
    "        tmp = nii.get_data().T.astype(dtype)\n",
    "        # Optionally mask data\n",
    "        if mask is not None:\n",
    "            tmp = tmp[:, mask]\n",
    "        # Optionally zscore each run independently\n",
    "        if do_zscore:\n",
    "            tmp = zscore(tmp, axis=0)\n",
    "        data.append(tmp)\n",
    "        del tmp\n",
    "    # Concatenate full data\n",
    "    data = np.vstack(data)\n",
    "    return data\n",
    "\n",
    "# The extra lazy way to load data (here as an example, not used below)\n",
    "def load_data_lazy(*runs, exp='categories', **kwargs):\n",
    "    \"\"\"Efficient wrapper for load_data\n",
    "    \n",
    "    Loads data for a given experiment, after specifying only run number\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    runs : integers {1,2,3}\n",
    "        Run number to load for a given experiment\n",
    "    exp : string\n",
    "        Experiment name\n",
    "    kwargs : keyword arguments\n",
    "        (passed to load_data)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data : array\n",
    "        fMRI data array, in (time, z, y, x) format (if not masked) or in\n",
    "        (time, voxels) format (if masked)\n",
    "    \n",
    "    \"\"\"\n",
    "    if exp=='categories':\n",
    "        files = [os.path.join(neurods.io.data_list['fmri'], exp, 's01_categories_%02d.nii.gz'%r) for r in runs]\n",
    "    elif exp=='motor':\n",
    "        files = [os.path.join(neurods.io.data_list['fmri'], exp, 's01_motorloc.nii.gz')]\n",
    "    return load_data(*files, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Demonstration that the load function works well\n",
    "# Set this to True to run this cell. We skip it here, because it will use up \n",
    "# a lot of memory, and thus possibly cause errors in subsequent cells. \n",
    "if False:\n",
    "    # Load one to three files\n",
    "    for n in range(1, 4):\n",
    "        data = load_data(*files[:n], do_zscore=True)\n",
    "        print(\"Loaded {} files, shape is:\".format(n), data.shape)\n",
    "        print(\"max={:0.3f}, min={:0.3f}\".format(np.nanmax(data), np.nanmin(data)))\n",
    "        print(\"\")\n",
    "        del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Masking\n",
    "\n",
    "As we have discussed, not all of the data in our 4D array is equally interesting to us. We are interested in the fMRI data collected IN the brain (vs outside it), and more specifically in the data collected from the cerebral cortex (the outermost layer of the brain). \n",
    "\n",
    "Here, we will show you how to extract (a) the data in the brain, and (b) the data in the cerebral cortex from the whole array. \n",
    "\n",
    "Remember our histogram of values for data, which show a ton of voxels with zero values (from outside the brain):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specify files\n",
    "files = ['s01_categories_{:02d}.nii.gz'.format(r) for r in [1, 2, 3]]\n",
    "files = [os.path.join(neurods.io.data_list['fmri'], 'categories', f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data for only one file\n",
    "data = load_data(files[0], do_zscore=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(0,2000,31)\n",
    "_ = plt.hist(data.flatten(), bins)\n",
    "plt.xlabel('Raw fMRI Activity')\n",
    "plt.ylabel('TRs (count)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So: how can we extract the data that is only from the region of the scan that contains the brain? We could try to write down an index for each data point in the data that contains a brain voxel (e.g. [25, 33, 33], [25, 33, 34]), but you can see how such a list would get quite long (tens of thousands) and would be difficult to construct. \n",
    "\n",
    "One simple way to find data that is in or near the brain is to threshold the data to find only the voxels where the signal is greater than zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here, consider only the first volume\n",
    "brain_voxels = data[0] > 250\n",
    "#print(brain_voxels) # Just displays a bunch of Trues and Falses in a big array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What is this thing we have just created?\n",
    "print('dtype of `brain_voxels`: ', brain_voxels.dtype) # Data type\n",
    "print('Sum of of `brain_voxels`: ', brain_voxels.sum()) # Number of voxels selected\n",
    "print('Mean of of `brain_voxels`: ', brain_voxels.mean()) # Proportion of voxels selected\n",
    "print('Shape of `brain_voxels`: ', brain_voxels.shape) # Shape of array "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout session\n",
    "1. Discuss what each of the values above indicate about the `brain_voxels` array.\n",
    "2. What happens if you change the cell above to be brain_voxels = data[0] > X, where X is greater than zero? (What should the threshold [X] for selecting brain voxels be?)\n",
    "3. While playing with the threshold value, display the `brain_voxels` variable in some sensible way. What does the array LOOK like for different thresholds (values of X)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** Setting the threshold higher excludes more and more low-signal voxels outside the brain (see next plot). Every voxel that is YELLOW in the following images is a True value, i.e. a voxel that will be selected by the mask that has been computed for a given threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "fig, ax = plt.subplots(1,4, figsize=(8, 2))\n",
    "for ax, threshold in zip(ax, [0, 10, 50, 250]):\n",
    "    # Create selection mask (all voxels with a signal greater than `threshold`)\n",
    "    brain_voxels = data[0] > threshold \n",
    "    # Choose a transverse slice of the brain to show\n",
    "    brain_slice = brain_voxels[15]\n",
    "    # Show the image!\n",
    "    im = ax.imshow(brain_slice)\n",
    "    ax.set_title('Threshold={}'.format(threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the whole mask using neurods.viz.slice_3d_array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,5))\n",
    "_ = neurods.viz.slice_3d_array(brain_voxels, axis=0, fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an array of True/False values (a boolean array). This array can be directly used to INDEX our data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Logical indices are fun!\n",
    "a = np.arange(10)\n",
    "idx = np.array([True, False, True, False, True, False, True, False, True, False])\n",
    "a[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This works in multiple dimensions, too!\n",
    "a = np.arange(20).reshape(2,10)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(a[:,idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# or even for brain data!\n",
    "brain_data = data[:, brain_voxels]\n",
    "print(brain_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This mask selects 64,789 voxels in the brain, and excludes the voxels outside the brain! The following plots show the array that we have now created:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BREAKOUT SESSION\n",
    "Make a histogram of `brain_data`. Z-score it, and plot it as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Student answer\n",
    "plt.hist(brain_data.flatten(), bins)\n",
    "plt.xlabel('Raw BOLD response')\n",
    "plt.ylabel('TRs (count)')\n",
    "plt.figure()\n",
    "plt.imshow(zscore(brain_data, axis=0), aspect='auto')\n",
    "plt.xlabel(\"Voxels\")\n",
    "plt.ylabel(\"Time (TRs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This lower plot shows all the data that we are interested in. \n",
    "\n",
    "A question was asked in class about whether we have now lost all information about where, for example, voxel # 23456 (indexed across the x axis of the plot) occurred in the brain. We have not lost that information, because we still have the mask! We can re-create a 3D array at any time to put our data back into a 3-D (z, y, x) or 4-D (time, z, y, x) array, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_brain = np.zeros(brain_voxels.shape)\n",
    "# Put the first TR worth of data back into the original brain volume shape:\n",
    "new_brain[brain_voxels] = brain_data[0]\n",
    "\n",
    "# Show what we have via slice_3d_array:\n",
    "_ = neurods.viz.slice_3d_array(new_brain, axis=0)\n",
    "# Compare this to the original first volume of the data:\n",
    "_ = neurods.viz.slice_3d_array(data[0], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very similar! But if you look closely at the lower plot, there are some low values for some voxels outside the brain. In the upper plot, everything outside the brain is exactly zero. Pycortex can re-constitute masked data in the same way when you create `cortex.Volume` objects (See below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If you provide a mask to cortex.Volume, it will re-constitue a 3D array from a 2D array\n",
    "v_masked = cortex.Volume(brain_data[0], 's01', 'catloc', mask=brain_voxels, vmin=0, vmax=2000)\n",
    "v_orig = cortex.Volume(data[0], 's01', 'catloc', vmin=0, vmax=2000)\n",
    "# Here's another fancy trick pycortex can do: You can plot two different data sets if you pass webgl.show()\n",
    "# a dict instead of a single pycortex Volume object:\n",
    "to_show = {'Masked & reconstituted data' : v_masked,\n",
    "           'Original data' : v_orig}\n",
    "cortex.webgl.show(to_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can flip between data sets in pycortex's web view by pressing `+` and `-`, or by using the drop-down menu at the top of the screen. Note that the two data sets look nearly identical (except for a few voxels that were cut out of the brain by the mask, near the occipital pole and in the temporal lobe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking with pycortex\n",
    "pycortex is the software that we use to map our 3-D or 4-D data onto the cortical surface. Pycortex can also be used to select voxels that are specifically located within a small distance from the cortical surface. This obviates the need for specifying an arbitrary threshold (above, we specified 250 - but why not 251? Why not 249 or 200?) - it provides a principled way to say which data you are interested in (data for voxels that fall within the cerebral cortex). \n",
    "\n",
    "To select voxels, we use the `cortex.db.get_mask` function. Just like cortex.Volume, this function requires two pieces of information. The first piece of information is the specific subject for whom we want to select the cortical surface (different subjects' brains are different!) - here, we specify `'s01'` (subject 1). The second piece of information is the transform (all the rotations, stretches, scaling, and left/right/up/down movements necessary to align the functional data to the anatomical data and thus to the cortical surface). Note that the subject's head may be in slightly different positions within the scanner for each different experiment - this is why we need to specify a transform, to say specifically WHERE the data was collected relative to the anatomical scan for a given subject for a given experiment. Here, `'catloc'` refers to the fact that this specific experiment is a *category localizer* experiment (see below for what that means!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fancy syntax for setting two variables:\n",
    "sub, xfm = 's01', 'catloc'\n",
    "# `sub` specifies a subject and `xfm` specifies a stored transform\n",
    "cortical_voxels = cortex.db.get_mask(sub, xfm, type='cortical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display the same information for this mask as we did for the brain mask above\n",
    "print(\"Mask data type:\", cortical_voxels.dtype) \n",
    "print(\"Mask shape:\", cortical_voxels.shape)\n",
    "print(\"Number of voxels in mask:\", cortical_voxels.sum())\n",
    "print(\"Proportion of voxels in mask: {:0.2f}\".format(cortical_voxels.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot horizontal slices of `cortical_voxels` mask\n",
    "fig1 = plt.figure(figsize=(6,5))\n",
    "_ = neurods.viz.slice_3d_array(cortical_voxels, axis=0, fig=fig1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Alternative plot of mask (sagittal slices)\n",
    "fig2 = plt.figure(figsize=(10,3))\n",
    "_ = neurods.viz.slice_3d_array(cortical_voxels, axis=1, fig=fig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cortical_data = data[:, cortical_voxels]\n",
    "print(cortical_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how much smaller (in MB) `cortical_data` is compared to `data`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this mask reduces the data size even more - down to ~12% of its original size! This will allow us to load more data and thus (eventually) to do more robust analyses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load description of experiment \n",
    "The experiment we have been working with is a *localizer* experiment. It is designed to find areas of the brain that respond to particular visual categories of objects: faces, bodies, and places. It also reveals areas that respond more to objects than to scrambled versions of the same objects. This experiment is a simple replication of past work, and is commonly done as a first step to locate (or localize) a region of interest for further analysis in a subsequent experiment.\n",
    "\n",
    "For the localizer experiment, images from each category were presented in a block design. This means that images from the one category were shown one after another for a \"block\" of 20 seconds (10 TRs), followed by images from another category for a block of 20 seconds, and so on.\n",
    "\n",
    "<img src=\"figures/CategoryLocalizerDesign.001.png\" style=\"height: 400px;\">\n",
    "\n",
    "To analyze the data from this experiment at all, we need to know when the blocks for each category (faces, bodies, places, objects, and scrambled objects) began and ended. This information is stored in a *design matrix*, which we load below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basedir = os.path.join(neurods.io.data_list['fmri'], 'categories')\n",
    "design = np.load(os.path.join(basedir, 'experiment_design.npz'))\n",
    "print('Experiment design variables: ', sorted(design.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conditions = design['conditions'].tolist()\n",
    "print('Conditions: ', conditions)\n",
    "design_run1 = design['run1']\n",
    "print('Design shape: ', design_run1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's often useful to show a design matrix as an image. In the image below, the yellow values indicate which time indices contained each condition!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = plt.imshow(design_run1.T, aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout session\n",
    "> What are the dimensions here? Label the axes on the figure above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Essentials:\n",
    "_ = plt.imshow(design_run1.T, aspect='auto')\n",
    "_ = plt.xlabel('Time (TRs)')\n",
    "_ = plt.ylabel('Condition')\n",
    "# Tick labels (useful!):\n",
    "_ = plt.xticks(range(0, 120, 10))\n",
    "_ = plt.yticks(range(5), conditions)\n",
    "# Some fanciness for an extra pretty plot:\n",
    "_ = plt.grid(axis='x', color='white')\n",
    "_ = plt.hlines(np.arange(0.5, 4.5), 0, 120, colors='w', alpha=0.5, linestyles=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event-related averages\n",
    "In an experiment, we are always interested in the relationship between the stimulus and brain responses. The simplest way to visualize the relationship is to examine what happened to brain responses every time that a stimulus came on. Thus, we will now create *averages* of responses after a particular type of stimulus came on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For the following analyses, we will average z-scored data\n",
    "dataz = load_data(*files[:1], do_zscore=True, dtype=np.float32)\n",
    "cortical_dataz = dataz[:, cortical_voxels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, use np.nonzero to find condition onsets for the first condition\n",
    "on_times = np.nonzero(design_run1[:,0])\n",
    "print(on_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python note**: The parentheses around the output here indicate that `on_times` is a tuple; we don't want the array to be inside a tuple, we just want it to be an array. Here are a few ways to make sure `on_times` is an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Easiest: Explicitly select the first element of the tuple\n",
    "on_times = np.nonzero(design_run1[:,0])\n",
    "on_times = on_times[0]\n",
    "print(on_times) # (note that all these print commands will give you the same array)\n",
    "\n",
    "# Do the same thing in one line:\n",
    "on_times = np.nonzero(design_run1[:,0])[0]\n",
    "print(on_times)\n",
    "\n",
    "# Fancy syntax:\n",
    "on_times, = np.nonzero(design_run1[:,0])\n",
    "print(on_times)\n",
    "\n",
    "# (this fancy syntax is the same as setting multiple variables from a tuple, like this:)\n",
    "a, b = (1, 2)\n",
    "print(\"Two-tuple (a,b) values are equal to:\")\n",
    "print(a)\n",
    "print(b)\n",
    "# ... but more like this:\n",
    "a, = (3, )\n",
    "print(\"one-long tuple, first value is:\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout session\n",
    "> Convert `on_times` to onsets! (i.e., the specific time that the stimulus came on)\n",
    "\n",
    "> Select 10 time points after each time the stimulus came on, and save them in a list\n",
    "\n",
    "> Average each set of points together! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### STUDENT ANSWER\n",
    "\n",
    "## Logic:\n",
    "# Find all the indices for which the condition was on/present\n",
    "on_times, = np.nonzero(design_run1[:,0])\n",
    "print('Stimulus was on at indices:')\n",
    "print(on_times)\n",
    "# Add a null value at the beginning of the array to make sure we capture the first onset of the condition\n",
    "on_times_add = np.hstack([-1, on_times])\n",
    "# Find indices that are at the START of blocks - where the next index is more than 1 TR away\n",
    "diff_indices = np.diff(on_times_add) > 1\n",
    "print('These indices (among `on_times`) are the onsets:')\n",
    "print(diff_indices)\n",
    "# Select those times!\n",
    "print(\"These are the condition onsets:\")\n",
    "print(on_times[diff_indices])\n",
    "\n",
    "# Formalize this all in a function:\n",
    "def get_onsets(cond):\n",
    "    \"\"\"Convert a set of indicators for when a condition is on to onset indices for that condition\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cond : array\n",
    "        An array of 1s and 0s (or a boolean array of Trues and Falses), indicating which time indices of\n",
    "        an experimental timecourse were part of a single given condition\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    onset_times : array\n",
    "        onset time indices for `cond`\n",
    "    \"\"\"\n",
    "    # (Note fancy syntax from above to pull out first element of a tuple)\n",
    "    on_times, = np.nonzero(cond)\n",
    "    # Choose \n",
    "    keepers = np.diff(np.hstack([-1, on_times]))>1\n",
    "    onset_times = on_times[keepers]\n",
    "    return onset_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get onset times for condition 1\n",
    "onset_times = get_onsets(design_run1[:, 0])\n",
    "cond_data = []\n",
    "for ot in onset_times:\n",
    "    # Select 10 time points starting from each condition onset (onset to onset + 10)\n",
    "    cond_data.append(cortical_dataz[ot:ot+10])\n",
    "# Compute the mean of all the repeats of condition 1\n",
    "all_cond1 = np.array(cond_data)\n",
    "print(all_cond1.shape)\n",
    "data_avg_cond1 = all_cond1.mean(0)\n",
    "print(data_avg_cond1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leaves us with 10 time points for each voxel. This is our event-related average! We will plot this in pycortex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a movie of the temporal average in pycortex!\n",
    "sub, xfm = 's01', 'catloc'\n",
    "cond1_vol = cortex.Volume(data_avg_cond1, sub, xfm, vmin=-3, vmax=3, cmap='RdBu_r')\n",
    "cortex.webgl.show(cond1_vol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is a movie - you can scroll through time with the pop-up menu at the bottom of the screen to see how the response to this condition evolves over time."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
